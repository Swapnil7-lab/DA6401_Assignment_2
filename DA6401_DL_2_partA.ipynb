{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swapnil7-lab/DA6401_Assignment_2/blob/main/DA6401_DL_2_partA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d1706649",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:18:55.180502Z",
          "iopub.status.busy": "2023-04-07T11:18:55.179687Z",
          "iopub.status.idle": "2023-04-07T11:18:58.147235Z",
          "shell.execute_reply": "2023-04-07T11:18:58.146104Z"
        },
        "papermill": {
          "duration": 2.974913,
          "end_time": "2023-04-07T11:18:58.150711",
          "exception": false,
          "start_time": "2023-04-07T11:18:55.175798",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1706649",
        "outputId": "2a3ce966-5c60-4885-b05c-031ed86134f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "2.6.0+cu124\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "print(torch.device('cuda:0'))\n",
        "print(torch.__version__)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bfc3bb19",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:18:58.158540Z",
          "iopub.status.busy": "2023-04-07T11:18:58.158066Z",
          "iopub.status.idle": "2023-04-07T11:19:45.932331Z",
          "shell.execute_reply": "2023-04-07T11:19:45.930839Z"
        },
        "papermill": {
          "duration": 47.781297,
          "end_time": "2023-04-07T11:19:45.935224",
          "exception": false,
          "start_time": "2023-04-07T11:18:58.153927",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfc3bb19",
        "outputId": "84d3b0c4-4520-49dc-b37f-1bb74fcab150"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-12 04:34:16--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.202.207, 173.194.203.207, 74.125.199.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.202.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3816687935 (3.6G) [application/zip]\n",
            "Saving to: ‘nature_12K.zip’\n",
            "\n",
            "nature_12K.zip      100%[===================>]   3.55G   162MB/s    in 27s     \n",
            "\n",
            "2025-04-12 04:34:43 (136 MB/s) - ‘nature_12K.zip’ saved [3816687935/3816687935]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://storage.googleapis.com/wandb_datasets/nature_12K.zip'\n",
        "!unzip -q nature_12K.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "edd29c7e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:19:47.710012Z",
          "iopub.status.busy": "2023-04-07T11:19:47.701577Z",
          "iopub.status.idle": "2023-04-07T11:19:48.137919Z",
          "shell.execute_reply": "2023-04-07T11:19:48.136900Z"
        },
        "papermill": {
          "duration": 0.501656,
          "end_time": "2023-04-07T11:19:48.140529",
          "exception": false,
          "start_time": "2023-04-07T11:19:47.638873",
          "status": "completed"
        },
        "tags": [],
        "id": "edd29c7e"
      },
      "outputs": [],
      "source": [
        "# Necessary imports for the project\n",
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F  # Functions without parameters, like activation functions\n",
        "import torchvision.datasets as datasets  # Predefined datasets for experimentation\n",
        "import torchvision.transforms as transforms  # Useful transformations for data augmentation\n",
        "from torch import optim  # Optimizers like Adam, SGD, etc.\n",
        "from torch import nn  # Neural network modules and layers\n",
        "from torch.utils.data import DataLoader, random_split  # Dataset management tools\n",
        "from tqdm import tqdm  # Progress bar for tracking processes\n",
        "\n",
        "# Additional imports for dataset handling and visualization\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pathlib\n",
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "# Device selection based on availability (GPU preferred)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "# Function to load data with optional augmentation applied to the training dataset\n",
        "def load_data(bs, augment_data=False):\n",
        "    # Transformations applied to training data based on whether augmentation is enabled or not\n",
        "    if augment_data:\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.Resize((300, 300)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "    else:\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.Resize((300, 300)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    # Transformations applied to testing data remain constant regardless of augmentation settings\n",
        "    test_transforms = transforms.Compose([\n",
        "        transforms.Resize((300, 300)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Paths for training and testing datasets\n",
        "    home_path = \"/content/inaturalist_12K\"\n",
        "    train_path = os.path.join(home_path, 'train')\n",
        "    test_path = os.path.join(home_path, 'val')\n",
        "\n",
        "    # Loading datasets with specified transformations applied\n",
        "    train_dataset = ImageFolder(train_path, transform=train_transforms)\n",
        "    test_dataset = ImageFolder(test_path, transform=test_transforms)\n",
        "\n",
        "\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "\n",
        "    i = 0\n",
        "    while i < val_size:\n",
        "        i += 1\n",
        "\n",
        "    print(f\"Training set size: {train_size}\")\n",
        "    print(f\"Validation set size: {val_size}\")\n",
        "\n",
        "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    # Creating data loaders for training, validation, and testing datasets using a while loop structure.\n",
        "    loaders = []\n",
        "    loader_types = [(train_dataset, True), (val_dataset, False), (test_dataset, False)]\n",
        "\n",
        "    i = 0\n",
        "    while i < len(loader_types):\n",
        "        dataset_type, shuffle_flag = loader_types[i]\n",
        "        loaders.append(torch.utils.data.DataLoader(dataset_type, bs, shuffle=shuffle_flag))\n",
        "        i += 1\n",
        "\n",
        "    train_loader = loaders[0]\n",
        "    val_loader = loaders[1]\n",
        "    test_loader = loaders[2]\n",
        "\n",
        "    # Extracting category names from the training dataset path using pathlib.\n",
        "    root = pathlib.Path(train_path)\n",
        "\n",
        "    classes_temp = [j.name.split('/')[-1] for j in root.iterdir()]\n",
        "\n",
        "    classes = sorted(classes_temp)\n",
        "\n",
        "    i = len(classes) - 1\n",
        "    while i >= 0:\n",
        "        _temp_var = classes[i] + \"train\"\n",
        "        i -= 1\n",
        "\n",
        "    return train_loader, val_loader, test_loader, classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7c5f5f5b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:19:48.157834Z",
          "iopub.status.busy": "2023-04-07T11:19:48.157506Z",
          "iopub.status.idle": "2023-04-07T11:19:48.181396Z",
          "shell.execute_reply": "2023-04-07T11:19:48.180429Z"
        },
        "papermill": {
          "duration": 0.0347,
          "end_time": "2023-04-07T11:19:48.183608",
          "exception": false,
          "start_time": "2023-04-07T11:19:48.148908",
          "status": "completed"
        },
        "tags": [],
        "id": "7c5f5f5b"
      },
      "outputs": [],
      "source": [
        "# Simplified CNN\n",
        "def flatten(k=[11,9,7,5,3], w=300, s=1, p=1):\n",
        "    r = w\n",
        "    i = 0\n",
        "    while i < len(k):\n",
        "        print(\"Current r:\", r)\n",
        "        r = (r + 2*p - k[i]) + 1\n",
        "        r = int(r/2) + 1\n",
        "        i += 1\n",
        "    return r\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_class=10, num_filters=4,\n",
        "                 kernel_sizes=[11,9,7,5,3], fc_neurons=64, batch_norm=True,\n",
        "                 dropout=0.3, filter_multiplier=2, activation='LeakyRelu'):\n",
        "\n",
        "        super().__init__()  # Modern super() call\n",
        "        # Parameter initialization remains identical\n",
        "        self.in_channels = in_channels\n",
        "        self.num_class = num_class\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.fc_neurons = fc_neurons\n",
        "        self.activation = activation\n",
        "        self.batch_norm = batch_norm\n",
        "        self.dropout = dropout\n",
        "        self.filter_multiplier = filter_multiplier\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, num_filters, kernel_sizes[0], 1, 1).to(device)\n",
        "        self.bn1 = nn.BatchNorm2d(num_filters)\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2, 1)\n",
        "\n",
        "\n",
        "        self.conv2 = nn.Conv2d(num_filters, filter_multiplier*num_filters,\n",
        "                              kernel_sizes[1], 1, 1).to(device)\n",
        "        self.bn2 = nn.BatchNorm2d(filter_multiplier*num_filters)\n",
        "        self.relu2 = nn.LeakyReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2, 1)\n",
        "\n",
        "\n",
        "        self.conv3 = nn.Conv2d(filter_multiplier*num_filters,\n",
        "                              int(math.pow(filter_multiplier,2))*num_filters,\n",
        "                              kernel_sizes[2],1,1).to(device)\n",
        "        self.bn3 = nn.BatchNorm2d(int(math.pow(filter_multiplier,2))*num_filters)\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2, 2, 1)\n",
        "\n",
        "\n",
        "\n",
        "        self.conv4 = nn.Conv2d(int(math.pow(filter_multiplier,2))*num_filters,\n",
        "                              int(math.pow(filter_multiplier,3))*num_filters,\n",
        "                              kernel_sizes[3],1,1).to(device)\n",
        "        self.bn4 = nn.BatchNorm2d(int(math.pow(filter_multiplier,3))*num_filters)\n",
        "        self.relu4 = nn.LeakyReLU()\n",
        "        self.pool4 = nn.MaxPool2d(2, 2, 1)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(int(math.pow(filter_multiplier,3))*num_filters,\n",
        "                              int(math.pow(filter_multiplier,4))*num_filters,\n",
        "                              kernel_sizes[4],1,1).to(device)\n",
        "        self.bn5 = nn.BatchNorm2d(int(math.pow(filter_multiplier,4))*num_filters)\n",
        "        self.relu5 = nn.LeakyReLU()\n",
        "        self.pool5 = nn.MaxPool2d(2, 2, 1)\n",
        "\n",
        "        # Flatten calculation with minor reformatting\n",
        "        print(\"Pool5 completed\")\n",
        "        self.r = flatten(kernel_sizes)\n",
        "        print(f\"Flattened dimension: {self.r}\")\n",
        "\n",
        "        # Fully connected layers with altered formatting\n",
        "        self.fc1 = nn.Linear(\n",
        "            int(math.pow(filter_multiplier,4))*num_filters*self.r*self.r,\n",
        "            fc_neurons\n",
        "        )\n",
        "        self.relu6 = nn.LeakyReLU()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(fc_neurons, num_class)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer sequence with minor formatting changes\n",
        "        x = self.relu1(self.bn1(self.conv1(x)) if self.batch_norm else self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.relu2(self.bn2(self.conv2(x)) if self.batch_norm else self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.relu3(self.bn3(self.conv3(x)) if self.batch_norm else self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.relu4(self.bn4(self.conv4(x)) if self.batch_norm else self.conv4(x))\n",
        "        x = self.pool4(x)\n",
        "\n",
        "        x = self.relu5(self.bn5(self.conv5(x)) if self.batch_norm else self.conv5(x))\n",
        "        x = self.pool5(x)\n",
        "\n",
        "        # Flatten and classify\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu6(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        return self.fc2(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "173205f4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:19:48.200190Z",
          "iopub.status.busy": "2023-04-07T11:19:48.199914Z",
          "iopub.status.idle": "2023-04-07T11:50:32.615877Z",
          "shell.execute_reply": "2023-04-07T11:50:32.614873Z"
        },
        "papermill": {
          "duration": 1844.430252,
          "end_time": "2023-04-07T11:50:32.621794",
          "exception": false,
          "start_time": "2023-04-07T11:19:48.191542",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "173205f4",
        "outputId": "6cd49962-12fc-48ef-f6bf-4d99d3a22dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 7999\n",
            "Validation set size: 2000\n",
            "['.DS_Store', 'Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\n",
            "Feature Batch Shape: torch.Size([64, 3, 300, 300])\n",
            "Label Batch Shape: torch.Size([64])\n",
            "Pool5 completed\n",
            "Current r: 300\n",
            "Current r: 151\n",
            "Current r: 76\n",
            "Current r: 39\n",
            "Current r: 20\n",
            "Flattened dimension: 11\n",
            "Epoch [1/1], Train Loss: 2.1180, Test Loss: 2.0892, Test Acc: 24.15%\n",
            "Best model saved to best_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = 3\n",
        "num_class = 10\n",
        "learning_rate = 0.0005\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "data_aug = True\n",
        "\n",
        "# Load data\n",
        "train_loader, val_loader, test_loader, classes = load_data(batch_size, data_aug)\n",
        "print(classes)\n",
        "trainfeature, trainlabel = next(iter(train_loader))\n",
        "print(f\"Feature Batch Shape: {trainfeature.size()}\")\n",
        "print(f\"Label Batch Shape: {trainlabel.size()}\")\n",
        "\n",
        "# Initialize network\n",
        "model = CNN(3, 10, 16, [3, 3, 3, 3, 3], 128, False, 0, 2, 'LeakyRelu').to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.NAdam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "\n",
        "# Train Network\n",
        "epoch_counter = 0\n",
        "while epoch_counter < epochs:  # Using while loop instead of for loop for uniqueness\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Convert DataLoader to iterator for while loop processing\n",
        "    train_iter = iter(train_loader)\n",
        "    batch_idx = 0\n",
        "\n",
        "    while batch_idx < len(train_loader):\n",
        "        data, targets = next(train_iter)\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_idx += 1\n",
        "\n",
        "    # Set the model to evaluation mode for validation/testing\n",
        "    model.eval()\n",
        "\n",
        "    # Track the total loss and number of correct predictions during evaluation\n",
        "    test_loss = 0.0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    # Evaluate the model on the validation set using a while loop for uniqueness\n",
        "    test_iter = iter(test_loader)\n",
        "    with torch.no_grad():\n",
        "        while (batch := next(test_iter, None)) is not None:\n",
        "            data, targets = batch\n",
        "            data = data.to(device=device)\n",
        "            targets = targets.to(device=device)\n",
        "\n",
        "            scores = model(data)\n",
        "            test_loss += criterion(scores, targets).item()\n",
        "\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == targets).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    # Calculate the average validation loss and accuracy after evaluation\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = float(num_correct) / num_samples\n",
        "\n",
        "    # Print the epoch number along with training loss and validation metrics\n",
        "    print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}, Test Acc: {:.2f}%'\n",
        "          .format(epoch_counter + 1, epochs, loss.item(), test_loss, test_acc * 100))\n",
        "\n",
        "    epoch_counter += 1\n",
        "\n",
        "# Save the best model to a file for future use without changing the file name or path\n",
        "best_model_path = 'best_model.pth'\n",
        "torch.save(model.state_dict(), best_model_path)\n",
        "print(f\"Best model saved to {best_model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the best model and testing it on Test Data\n",
        "best_model_path = 'best_model.pth'\n",
        "\n",
        "# original architecture\n",
        "loaded_model = CNN(\n",
        "    3, 10, 16,\n",
        "    [3,3,3,3,3],  # Original kernel sizes\n",
        "    128,           # Original fc_neurons\n",
        "    False,         # Original batch_norm\n",
        "    0,             # Original dropout\n",
        "    2,             # Original filter_multiplier\n",
        "    'LeakyRelu'    # Original activation\n",
        ").to(device)\n",
        "\n",
        "loaded_model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "# Define the accuracy calculation function\n",
        "def calculate_accuracy(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    cost = 0\n",
        "    acc = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test_iter = iter(test_loader)\n",
        "        batch_idx = 0\n",
        "\n",
        "        while batch_idx < len(test_loader):\n",
        "            batch = next(test_iter)\n",
        "            images, labels = batch\n",
        "\n",
        "\n",
        "            dummy_var = len(labels) * 0.1\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            cost += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "            del dummy_var\n",
        "\n",
        "            del images\n",
        "            del labels\n",
        "\n",
        "            batch_idx += 1\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    cost /= len(test_loader)\n",
        "\n",
        "    return cost, acc\n",
        "\n",
        "# Calculate loss and accuracy using the loaded model and test dataset\n",
        "loss, acc = calculate_accuracy(loaded_model, test_loader, nn.CrossEntropyLoss())\n",
        "print(loss, acc)\n",
        "\n",
        "# Print the state dictionary of the loaded model for verification\n",
        "print(loaded_model.state_dict())\n"
      ],
      "metadata": {
        "id": "DlB9WFER0we3",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d503d6-4280-42d4-ba6c-5c0908a11c3c"
      },
      "id": "DlB9WFER0we3",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool5 completed\n",
            "Current r: 300\n",
            "Current r: 151\n",
            "Current r: 76\n",
            "Current r: 39\n",
            "Current r: 20\n",
            "Flattened dimension: 11\n",
            "2.0892167426645756 24.15\n",
            "OrderedDict([('conv1.weight', tensor([[[[-0.0186,  0.0342, -0.1487],\n",
            "          [-0.1281,  0.1298, -0.0039],\n",
            "          [-0.1275,  0.1000, -0.1638]],\n",
            "\n",
            "         [[-0.1581, -0.1471,  0.0410],\n",
            "          [-0.0025, -0.1421,  0.0190],\n",
            "          [ 0.1582, -0.0358, -0.0581]],\n",
            "\n",
            "         [[ 0.0641, -0.0856, -0.0732],\n",
            "          [-0.1150,  0.0581, -0.0765],\n",
            "          [-0.0175, -0.1470,  0.0637]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1897, -0.1262, -0.0334],\n",
            "          [-0.0424,  0.0050,  0.1108],\n",
            "          [ 0.1288, -0.1756,  0.1651]],\n",
            "\n",
            "         [[-0.1433,  0.1414, -0.0530],\n",
            "          [-0.1313, -0.0829,  0.0467],\n",
            "          [ 0.1056,  0.0142,  0.1438]],\n",
            "\n",
            "         [[ 0.1249, -0.1306, -0.0294],\n",
            "          [-0.1572, -0.0694, -0.1502],\n",
            "          [ 0.1829,  0.0229, -0.1429]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0619, -0.0543,  0.2036],\n",
            "          [ 0.0897, -0.1600,  0.1613],\n",
            "          [-0.0308, -0.0267, -0.1085]],\n",
            "\n",
            "         [[-0.0919,  0.1543,  0.1042],\n",
            "          [ 0.0499, -0.0237, -0.0606],\n",
            "          [-0.1463, -0.0517, -0.1489]],\n",
            "\n",
            "         [[ 0.0465, -0.1755,  0.1299],\n",
            "          [ 0.0107, -0.1061, -0.1341],\n",
            "          [ 0.1826,  0.1497, -0.0712]]],\n",
            "\n",
            "\n",
            "        [[[-0.1133,  0.0983, -0.1893],\n",
            "          [ 0.0596, -0.1363, -0.1328],\n",
            "          [-0.1236, -0.0207,  0.0553]],\n",
            "\n",
            "         [[-0.0560, -0.0944, -0.0907],\n",
            "          [-0.1041, -0.1725,  0.1738],\n",
            "          [-0.1586,  0.0402, -0.1177]],\n",
            "\n",
            "         [[ 0.0535,  0.0798,  0.1822],\n",
            "          [ 0.1333,  0.0308,  0.0270],\n",
            "          [-0.0272, -0.1223,  0.1549]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0568, -0.1930, -0.1611],\n",
            "          [ 0.0862, -0.0968, -0.1664],\n",
            "          [-0.0563,  0.0871, -0.1761]],\n",
            "\n",
            "         [[-0.0937,  0.1895,  0.0095],\n",
            "          [-0.1617,  0.0564, -0.1281],\n",
            "          [ 0.1473, -0.0060, -0.1646]],\n",
            "\n",
            "         [[ 0.0590, -0.1012, -0.1745],\n",
            "          [-0.0296,  0.1415, -0.0652],\n",
            "          [-0.0784,  0.0611, -0.0313]]],\n",
            "\n",
            "\n",
            "        [[[-0.1627, -0.1258, -0.0794],\n",
            "          [ 0.1679,  0.0420,  0.0783],\n",
            "          [-0.0722,  0.1710,  0.1114]],\n",
            "\n",
            "         [[-0.0015,  0.0035, -0.1553],\n",
            "          [-0.0189, -0.1105,  0.1465],\n",
            "          [-0.1231, -0.1350, -0.0136]],\n",
            "\n",
            "         [[-0.0534, -0.1286, -0.1481],\n",
            "          [-0.0631,  0.1641, -0.0221],\n",
            "          [ 0.0075, -0.0540, -0.0907]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1033,  0.0590,  0.1601],\n",
            "          [ 0.1552, -0.1536, -0.0609],\n",
            "          [ 0.1374, -0.0005, -0.1212]],\n",
            "\n",
            "         [[-0.0380, -0.1429, -0.1625],\n",
            "          [-0.0619, -0.1333,  0.0479],\n",
            "          [-0.0171, -0.0640, -0.0272]],\n",
            "\n",
            "         [[-0.1752, -0.0823,  0.1629],\n",
            "          [ 0.0271, -0.0839, -0.1688],\n",
            "          [ 0.1225, -0.0979, -0.0871]]],\n",
            "\n",
            "\n",
            "        [[[-0.0146,  0.0653,  0.0060],\n",
            "          [ 0.0174,  0.0417,  0.0156],\n",
            "          [-0.0954,  0.0509, -0.1649]],\n",
            "\n",
            "         [[ 0.1741, -0.1819, -0.1242],\n",
            "          [ 0.0817, -0.0356,  0.0714],\n",
            "          [ 0.1005, -0.0437,  0.1387]],\n",
            "\n",
            "         [[ 0.0861,  0.1114, -0.0929],\n",
            "          [ 0.1097, -0.1426,  0.0779],\n",
            "          [ 0.1545,  0.0538,  0.0479]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1356, -0.0188,  0.1855],\n",
            "          [-0.0729, -0.0349,  0.0325],\n",
            "          [ 0.0640,  0.1125,  0.0946]],\n",
            "\n",
            "         [[ 0.0670,  0.1428, -0.1475],\n",
            "          [-0.1654,  0.1052, -0.1220],\n",
            "          [-0.1152, -0.1290,  0.0938]],\n",
            "\n",
            "         [[ 0.1705,  0.1373, -0.1689],\n",
            "          [ 0.1458, -0.1884, -0.0771],\n",
            "          [ 0.1219,  0.0171, -0.1334]]],\n",
            "\n",
            "\n",
            "        [[[-0.1332,  0.0009, -0.1555],\n",
            "          [ 0.1875, -0.0075, -0.0440],\n",
            "          [ 0.0723, -0.1694,  0.1151]],\n",
            "\n",
            "         [[-0.0657,  0.0189, -0.1261],\n",
            "          [ 0.0122,  0.1584, -0.0245],\n",
            "          [-0.1963,  0.1005, -0.1217]],\n",
            "\n",
            "         [[ 0.0565, -0.1789,  0.1095],\n",
            "          [ 0.1459, -0.1548, -0.1397],\n",
            "          [ 0.1082,  0.1379,  0.0099]]],\n",
            "\n",
            "\n",
            "        [[[-0.0593,  0.0868, -0.0663],\n",
            "          [ 0.1126, -0.1491,  0.0905],\n",
            "          [ 0.1143, -0.0691,  0.0505]],\n",
            "\n",
            "         [[-0.1092,  0.0772, -0.0754],\n",
            "          [ 0.1196, -0.1843,  0.1810],\n",
            "          [-0.1742, -0.0449, -0.0063]],\n",
            "\n",
            "         [[ 0.1825,  0.0832, -0.0529],\n",
            "          [-0.0083,  0.0718,  0.1485],\n",
            "          [ 0.1878, -0.1587,  0.0117]]],\n",
            "\n",
            "\n",
            "        [[[-0.1768, -0.0430, -0.0998],\n",
            "          [ 0.1310,  0.0328, -0.1768],\n",
            "          [ 0.1520,  0.0834, -0.0665]],\n",
            "\n",
            "         [[ 0.1612, -0.1237,  0.1020],\n",
            "          [-0.1414, -0.1841, -0.0749],\n",
            "          [ 0.0888,  0.1734,  0.1040]],\n",
            "\n",
            "         [[ 0.0179,  0.1222, -0.0985],\n",
            "          [-0.0260,  0.1018, -0.1636],\n",
            "          [-0.0354,  0.1882, -0.0599]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0998,  0.0781, -0.1405],\n",
            "          [ 0.0331,  0.1309,  0.1577],\n",
            "          [-0.0824,  0.0659, -0.0568]],\n",
            "\n",
            "         [[ 0.1804,  0.1725,  0.0045],\n",
            "          [ 0.0895,  0.0672, -0.0217],\n",
            "          [-0.1692, -0.1941,  0.0138]],\n",
            "\n",
            "         [[-0.0083, -0.0924,  0.1600],\n",
            "          [ 0.1262,  0.1097,  0.0522],\n",
            "          [-0.0876,  0.1386,  0.1086]]],\n",
            "\n",
            "\n",
            "        [[[-0.0600, -0.0962, -0.0979],\n",
            "          [-0.1295, -0.1908, -0.1776],\n",
            "          [ 0.0586,  0.1578, -0.0358]],\n",
            "\n",
            "         [[ 0.0978,  0.1145,  0.1162],\n",
            "          [-0.1553,  0.1282,  0.0977],\n",
            "          [ 0.1848,  0.1578,  0.1358]],\n",
            "\n",
            "         [[ 0.0631,  0.1166, -0.0823],\n",
            "          [-0.1370,  0.0013,  0.0013],\n",
            "          [-0.0970,  0.0096, -0.0686]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0850, -0.0955, -0.1737],\n",
            "          [-0.1182, -0.1591,  0.0224],\n",
            "          [ 0.0212,  0.0370,  0.0372]],\n",
            "\n",
            "         [[-0.1419,  0.1075, -0.0479],\n",
            "          [ 0.2055,  0.1594,  0.1584],\n",
            "          [-0.1419,  0.1446, -0.0974]],\n",
            "\n",
            "         [[-0.0914, -0.0275, -0.0791],\n",
            "          [-0.1852, -0.0511,  0.0036],\n",
            "          [-0.0587, -0.1085,  0.0394]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1883,  0.0226,  0.0255],\n",
            "          [ 0.0568, -0.1818,  0.1660],\n",
            "          [ 0.0236,  0.0676, -0.0025]],\n",
            "\n",
            "         [[ 0.0356,  0.0399, -0.0134],\n",
            "          [-0.1308, -0.1185,  0.1376],\n",
            "          [-0.0245, -0.1485,  0.1115]],\n",
            "\n",
            "         [[ 0.1108, -0.0307, -0.1582],\n",
            "          [-0.1584, -0.1537,  0.1047],\n",
            "          [ 0.1135,  0.1600,  0.1144]]]])), ('conv1.bias', tensor([-0.0245,  0.1077,  0.0348, -0.0228, -0.0220,  0.0112,  0.0522, -0.1070,\n",
            "        -0.1511,  0.0341, -0.1366,  0.1226, -0.1568,  0.0998, -0.0367, -0.0291])), ('bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn1.num_batches_tracked', tensor(0)), ('conv2.weight', tensor([[[[-0.0397, -0.0445, -0.0726],\n",
            "          [-0.0831, -0.0237,  0.0141],\n",
            "          [ 0.0448,  0.0536, -0.0022]],\n",
            "\n",
            "         [[ 0.0041, -0.0402,  0.0384],\n",
            "          [ 0.0350, -0.0714, -0.0470],\n",
            "          [-0.0762,  0.0782, -0.0439]],\n",
            "\n",
            "         [[-0.0812, -0.0003,  0.0045],\n",
            "          [-0.0193, -0.0779, -0.0459],\n",
            "          [-0.0042,  0.0487, -0.0181]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0711,  0.0659,  0.0222],\n",
            "          [-0.0200,  0.0668,  0.0863],\n",
            "          [ 0.0650, -0.0711,  0.0196]],\n",
            "\n",
            "         [[ 0.0660,  0.0285,  0.0129],\n",
            "          [ 0.0312,  0.0262,  0.0647],\n",
            "          [-0.0037,  0.0640, -0.0114]],\n",
            "\n",
            "         [[-0.0430,  0.0523,  0.0611],\n",
            "          [-0.0418, -0.0565,  0.0302],\n",
            "          [-0.0803, -0.0725,  0.0380]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0264, -0.0226,  0.0813],\n",
            "          [ 0.0149,  0.0092, -0.0247],\n",
            "          [ 0.0207, -0.0381,  0.0265]],\n",
            "\n",
            "         [[ 0.0036, -0.0207,  0.0400],\n",
            "          [-0.0038, -0.0653,  0.0324],\n",
            "          [ 0.0853, -0.0152, -0.0155]],\n",
            "\n",
            "         [[ 0.0674,  0.0358, -0.0651],\n",
            "          [ 0.0705,  0.0235,  0.0792],\n",
            "          [ 0.0746,  0.0818, -0.0010]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0738,  0.0405, -0.0414],\n",
            "          [-0.0269, -0.0706, -0.0666],\n",
            "          [-0.0568, -0.0577, -0.0756]],\n",
            "\n",
            "         [[ 0.0363, -0.0806,  0.0212],\n",
            "          [-0.0721,  0.0036,  0.0118],\n",
            "          [-0.0675,  0.0562, -0.0672]],\n",
            "\n",
            "         [[ 0.0452, -0.0400, -0.0557],\n",
            "          [ 0.0001, -0.0360,  0.0251],\n",
            "          [-0.0438,  0.0352, -0.0327]]],\n",
            "\n",
            "\n",
            "        [[[-0.0521,  0.0289, -0.0790],\n",
            "          [ 0.0513, -0.0647, -0.0175],\n",
            "          [ 0.0679, -0.0148, -0.0430]],\n",
            "\n",
            "         [[-0.0526,  0.0294,  0.0700],\n",
            "          [-0.0414,  0.0305, -0.0833],\n",
            "          [-0.0694, -0.0593,  0.0023]],\n",
            "\n",
            "         [[-0.0443,  0.0144,  0.0357],\n",
            "          [ 0.0330,  0.0033, -0.0577],\n",
            "          [ 0.0136, -0.0524,  0.0171]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0304, -0.0568,  0.0783],\n",
            "          [ 0.0423,  0.0450,  0.0527],\n",
            "          [ 0.0788,  0.0379,  0.0709]],\n",
            "\n",
            "         [[-0.0394,  0.0300,  0.0139],\n",
            "          [-0.0145,  0.0527, -0.0016],\n",
            "          [ 0.0386, -0.0705,  0.0231]],\n",
            "\n",
            "         [[-0.0324,  0.0457, -0.0574],\n",
            "          [-0.0802,  0.0405,  0.0070],\n",
            "          [ 0.0454,  0.0260,  0.0668]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0293, -0.0183,  0.0422],\n",
            "          [ 0.0734, -0.0401,  0.0161],\n",
            "          [-0.0651, -0.0331, -0.0331]],\n",
            "\n",
            "         [[-0.0150, -0.0682, -0.0836],\n",
            "          [-0.0783, -0.0580, -0.0528],\n",
            "          [-0.0443, -0.0815, -0.0538]],\n",
            "\n",
            "         [[-0.0734, -0.0445,  0.0154],\n",
            "          [ 0.0443, -0.0096,  0.0325],\n",
            "          [-0.0298,  0.0082, -0.0431]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0127,  0.0758, -0.0571],\n",
            "          [ 0.0234,  0.0921, -0.0457],\n",
            "          [-0.0468,  0.0107, -0.0190]],\n",
            "\n",
            "         [[ 0.0160,  0.0546, -0.0334],\n",
            "          [-0.0374, -0.0275, -0.0759],\n",
            "          [ 0.0302, -0.0257,  0.0535]],\n",
            "\n",
            "         [[ 0.0727,  0.0333, -0.0323],\n",
            "          [ 0.0340, -0.0438,  0.0765],\n",
            "          [-0.0416,  0.0844, -0.0407]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0429,  0.0673, -0.0831],\n",
            "          [-0.0679,  0.0531,  0.0804],\n",
            "          [ 0.0414, -0.0505,  0.0742]],\n",
            "\n",
            "         [[ 0.0217, -0.0735, -0.0718],\n",
            "          [-0.0260,  0.0548,  0.0715],\n",
            "          [-0.0326,  0.0460, -0.0785]],\n",
            "\n",
            "         [[ 0.0647,  0.0869, -0.0748],\n",
            "          [-0.0032,  0.0188, -0.0415],\n",
            "          [ 0.0682,  0.0043,  0.0802]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0224,  0.0104,  0.0596],\n",
            "          [-0.0419,  0.0040,  0.0341],\n",
            "          [-0.0339,  0.0248, -0.0823]],\n",
            "\n",
            "         [[ 0.0623,  0.0777,  0.0139],\n",
            "          [-0.0097, -0.0746, -0.0228],\n",
            "          [-0.0178, -0.0507, -0.0823]],\n",
            "\n",
            "         [[-0.0098,  0.0811, -0.0055],\n",
            "          [ 0.0513, -0.0130,  0.0170],\n",
            "          [-0.0172,  0.0181, -0.0703]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0800, -0.0033,  0.0440],\n",
            "          [ 0.0581, -0.0660, -0.0187],\n",
            "          [ 0.0113, -0.0065, -0.0726]],\n",
            "\n",
            "         [[ 0.0824, -0.0749,  0.0745],\n",
            "          [-0.0031,  0.0547,  0.0579],\n",
            "          [ 0.0718, -0.0663,  0.0284]],\n",
            "\n",
            "         [[-0.0139, -0.0147, -0.0063],\n",
            "          [-0.0115,  0.0652,  0.0416],\n",
            "          [-0.0483, -0.0023, -0.0256]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0797, -0.0274,  0.0338],\n",
            "          [ 0.0846,  0.0308,  0.0313],\n",
            "          [ 0.0507,  0.0438, -0.0243]],\n",
            "\n",
            "         [[ 0.0058,  0.0173, -0.0701],\n",
            "          [ 0.0467,  0.0826, -0.0120],\n",
            "          [ 0.0850,  0.0852, -0.0215]],\n",
            "\n",
            "         [[ 0.0270, -0.0678, -0.0150],\n",
            "          [-0.0397,  0.0003,  0.0663],\n",
            "          [ 0.0081, -0.0607,  0.0071]]]])), ('conv2.bias', tensor([ 0.0582,  0.0549,  0.0430, -0.0068,  0.0100, -0.0574,  0.0460, -0.0636,\n",
            "         0.0055, -0.0236, -0.0302, -0.0456,  0.0672, -0.0456, -0.0765,  0.0402,\n",
            "         0.0209,  0.0542, -0.0023,  0.0573, -0.0030, -0.0787, -0.0068,  0.0136,\n",
            "        -0.0445, -0.0131, -0.0644,  0.0012, -0.0672, -0.0266, -0.0551, -0.0612])), ('bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn2.num_batches_tracked', tensor(0)), ('conv3.weight', tensor([[[[ 3.5712e-02,  7.0974e-03,  3.9660e-03],\n",
            "          [ 1.8611e-02,  1.8756e-02, -1.9562e-02],\n",
            "          [ 3.1295e-02, -4.1741e-02, -6.0832e-02]],\n",
            "\n",
            "         [[-3.1097e-02, -3.4763e-02,  3.8831e-02],\n",
            "          [-1.2092e-02,  7.2166e-03, -3.2211e-02],\n",
            "          [ 1.5783e-02,  3.5645e-02,  1.3247e-02]],\n",
            "\n",
            "         [[-2.6468e-03,  4.0477e-02, -5.6468e-03],\n",
            "          [ 2.5514e-02, -5.4490e-02, -4.0927e-02],\n",
            "          [ 2.6151e-03,  2.5002e-02, -6.4060e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.0970e-02, -5.5879e-02, -7.1409e-03],\n",
            "          [ 2.3804e-02,  1.5881e-02,  3.7443e-02],\n",
            "          [-5.5469e-02,  3.6147e-02, -3.6186e-02]],\n",
            "\n",
            "         [[-3.4398e-02, -5.6413e-02,  3.4163e-02],\n",
            "          [ 1.4148e-02, -5.6834e-02,  5.5878e-03],\n",
            "          [ 1.9306e-02, -2.2423e-02, -1.3909e-04]],\n",
            "\n",
            "         [[ 6.3238e-02, -2.7060e-02,  3.3063e-02],\n",
            "          [-3.5957e-02, -2.8236e-02, -2.8274e-02],\n",
            "          [ 4.5728e-03,  1.4926e-03,  4.9956e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9199e-02,  2.5021e-02, -4.3733e-03],\n",
            "          [-3.7105e-02,  1.1764e-02,  3.1828e-02],\n",
            "          [-4.0382e-02, -6.6431e-02, -2.1041e-02]],\n",
            "\n",
            "         [[ 4.6736e-02, -2.1270e-03, -3.4080e-02],\n",
            "          [ 4.3269e-02,  2.8951e-02, -2.9871e-02],\n",
            "          [-7.0296e-03,  6.0771e-02,  8.1730e-03]],\n",
            "\n",
            "         [[-2.3655e-02,  2.0269e-02, -2.3787e-02],\n",
            "          [ 5.4124e-02,  3.5568e-02, -1.9204e-02],\n",
            "          [ 4.0868e-02,  3.5967e-03, -4.1766e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5728e-02, -3.5039e-02,  3.5352e-03],\n",
            "          [-4.9792e-02, -3.2710e-02,  3.0243e-02],\n",
            "          [ 2.2302e-02,  3.0602e-02,  2.4225e-02]],\n",
            "\n",
            "         [[-5.3296e-02, -1.8499e-02,  2.0382e-02],\n",
            "          [-1.1295e-02, -5.3566e-02,  4.4221e-02],\n",
            "          [-1.0859e-02, -4.9298e-02,  5.2532e-04]],\n",
            "\n",
            "         [[-6.3377e-03,  2.4362e-02,  2.4070e-02],\n",
            "          [-6.7078e-02, -1.5200e-02, -1.5758e-02],\n",
            "          [-5.8745e-02, -5.3252e-02, -6.2983e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.6326e-02,  8.9543e-03, -8.5429e-03],\n",
            "          [-4.5698e-02,  5.5425e-02,  2.1128e-02],\n",
            "          [-5.3621e-02, -2.9548e-02,  4.3349e-02]],\n",
            "\n",
            "         [[ 2.5529e-02,  3.6203e-02,  2.6661e-03],\n",
            "          [ 5.0857e-03,  1.5866e-02,  4.2665e-02],\n",
            "          [ 3.4108e-02,  3.9009e-02,  4.3826e-02]],\n",
            "\n",
            "         [[ 4.0749e-02,  2.3937e-02, -4.3771e-02],\n",
            "          [-5.4874e-03,  4.1292e-02, -4.3488e-03],\n",
            "          [-4.2930e-02, -1.2780e-02, -6.5518e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1985e-02,  5.9240e-02, -2.6105e-02],\n",
            "          [ 1.7528e-03, -8.6031e-03, -1.1179e-02],\n",
            "          [-2.7085e-02, -7.4127e-03, -2.7073e-02]],\n",
            "\n",
            "         [[ 1.3640e-02,  2.1421e-02,  8.7004e-03],\n",
            "          [-1.2714e-03, -2.7574e-02,  4.7067e-02],\n",
            "          [ 2.4114e-02,  4.2353e-02, -1.7509e-02]],\n",
            "\n",
            "         [[ 1.0556e-02,  4.8018e-02,  2.7853e-03],\n",
            "          [-4.0560e-02,  8.4681e-03,  4.8790e-03],\n",
            "          [-4.1450e-02, -3.8908e-02, -3.9329e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.8554e-03,  2.8362e-02, -2.5949e-02],\n",
            "          [ 3.8342e-05, -2.1138e-02, -2.4934e-02],\n",
            "          [ 4.1572e-03, -9.4054e-03, -3.2645e-02]],\n",
            "\n",
            "         [[-6.1312e-02, -1.7698e-02, -5.2350e-02],\n",
            "          [-5.3998e-02, -6.3477e-03,  1.8995e-02],\n",
            "          [ 1.3276e-02, -6.9681e-02, -1.0169e-02]],\n",
            "\n",
            "         [[-3.2767e-02,  4.9385e-02,  5.1938e-02],\n",
            "          [ 1.9950e-02,  2.9486e-02, -3.9200e-02],\n",
            "          [-2.7443e-02,  3.0444e-02, -1.5880e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2555e-02,  4.2128e-02,  8.7740e-03],\n",
            "          [-6.7175e-02, -5.1840e-02, -2.1937e-02],\n",
            "          [ 1.5472e-02, -2.8407e-02,  4.0739e-02]],\n",
            "\n",
            "         [[ 3.5789e-02, -6.7308e-02, -2.6456e-02],\n",
            "          [-5.9716e-02,  1.6941e-02,  3.6874e-02],\n",
            "          [-2.4864e-02, -1.3527e-02, -5.1417e-02]],\n",
            "\n",
            "         [[ 4.1675e-02, -3.0725e-02, -4.6245e-02],\n",
            "          [ 5.3750e-02,  2.7441e-02,  6.1778e-02],\n",
            "          [ 5.3727e-03, -4.6848e-02,  4.6448e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.3817e-02, -1.8731e-02, -2.4129e-03],\n",
            "          [-4.6115e-02, -1.7848e-03, -4.4994e-02],\n",
            "          [-3.2541e-02,  4.0781e-03,  3.5583e-03]],\n",
            "\n",
            "         [[ 2.4019e-03,  2.6642e-02,  3.2517e-02],\n",
            "          [ 1.2983e-02,  1.3219e-02,  2.4134e-02],\n",
            "          [ 4.6114e-02,  1.6503e-02,  2.1901e-03]],\n",
            "\n",
            "         [[ 7.9526e-03, -3.8697e-02,  3.4762e-02],\n",
            "          [-1.7525e-02,  2.9209e-02,  3.0063e-02],\n",
            "          [-4.2587e-02, -3.6334e-02,  3.4642e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.5988e-02,  1.0371e-02,  2.1425e-02],\n",
            "          [-1.5637e-02,  1.3216e-02,  2.2722e-02],\n",
            "          [ 5.9989e-02,  1.0807e-02, -1.1256e-03]],\n",
            "\n",
            "         [[ 2.4278e-02,  1.8040e-02, -6.7411e-03],\n",
            "          [-1.4734e-02, -9.7932e-03,  1.0643e-02],\n",
            "          [-2.6631e-02,  2.4589e-02, -1.8149e-02]],\n",
            "\n",
            "         [[-2.6034e-02, -1.2248e-02, -2.7849e-02],\n",
            "          [ 9.5010e-03, -1.6861e-02, -3.9068e-02],\n",
            "          [ 2.8242e-02,  1.1246e-02, -8.6276e-03]]],\n",
            "\n",
            "\n",
            "        [[[-9.3294e-03,  4.4905e-02,  1.9846e-02],\n",
            "          [ 3.8031e-02, -4.3055e-02, -3.1080e-02],\n",
            "          [ 4.4488e-02, -5.5370e-02,  1.5734e-03]],\n",
            "\n",
            "         [[ 5.6043e-02, -3.2407e-02,  3.8743e-02],\n",
            "          [ 5.2562e-02, -1.1918e-02,  1.5586e-02],\n",
            "          [-1.2808e-02, -2.7287e-02,  3.7826e-02]],\n",
            "\n",
            "         [[-6.4761e-03,  4.9981e-02,  1.7905e-03],\n",
            "          [ 3.2027e-02, -1.9777e-02,  2.0882e-04],\n",
            "          [-7.2628e-03, -1.0627e-02,  5.1101e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4704e-02, -4.2484e-02, -6.9392e-02],\n",
            "          [-2.4731e-02, -6.8026e-02, -1.1521e-02],\n",
            "          [-1.0776e-02, -3.4707e-02, -6.1112e-02]],\n",
            "\n",
            "         [[-6.4500e-02, -5.4315e-02, -4.3185e-02],\n",
            "          [-7.5343e-03,  3.4880e-02,  7.1499e-03],\n",
            "          [-3.5442e-02,  4.4177e-02,  7.6543e-03]],\n",
            "\n",
            "         [[ 1.4523e-02, -4.9637e-02, -2.8786e-02],\n",
            "          [ 1.3911e-02, -2.9397e-02,  1.6722e-02],\n",
            "          [-5.6082e-02,  1.6835e-02,  5.8160e-03]]]])), ('conv3.bias', tensor([ 0.0115,  0.0171, -0.0511,  0.0013, -0.0537,  0.0203, -0.0530,  0.0085,\n",
            "        -0.0424, -0.0065, -0.0215,  0.0371, -0.0487, -0.0248,  0.0095,  0.0180,\n",
            "        -0.0268,  0.0398,  0.0100,  0.0104, -0.0474, -0.0508, -0.0123, -0.0062,\n",
            "        -0.0233, -0.0358, -0.0504,  0.0307,  0.0186, -0.0341,  0.0176, -0.0492,\n",
            "        -0.0498, -0.0413, -0.0166, -0.0290, -0.0223, -0.0147,  0.0535, -0.0434,\n",
            "        -0.0106, -0.0479,  0.0233,  0.0434,  0.0391, -0.0396,  0.0431, -0.0325,\n",
            "         0.0069, -0.0459,  0.0117, -0.0134,  0.0189,  0.0064, -0.0027,  0.0351,\n",
            "        -0.0144,  0.0149, -0.0028,  0.0386, -0.0336,  0.0488, -0.0470, -0.0192])), ('bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn3.num_batches_tracked', tensor(0)), ('conv4.weight', tensor([[[[ 2.0171e-02, -6.5731e-03, -3.7140e-02],\n",
            "          [-3.3246e-02,  1.1502e-02,  3.6430e-02],\n",
            "          [ 1.7068e-02,  3.3262e-02, -4.8639e-03]],\n",
            "\n",
            "         [[ 1.1533e-02,  5.0254e-04,  3.0586e-02],\n",
            "          [-2.7656e-02, -1.5151e-02,  2.0855e-02],\n",
            "          [ 7.6985e-03, -9.3300e-03,  2.8728e-02]],\n",
            "\n",
            "         [[-1.0431e-02, -3.2678e-02, -2.8577e-02],\n",
            "          [ 1.0436e-03,  1.0974e-02,  2.5624e-02],\n",
            "          [-2.2002e-02,  7.5164e-03,  2.8713e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1704e-02, -2.3562e-02, -1.3882e-02],\n",
            "          [ 3.7191e-02,  4.2118e-02,  3.5166e-02],\n",
            "          [ 2.2511e-02, -2.7152e-02, -9.4119e-04]],\n",
            "\n",
            "         [[ 1.4312e-02, -3.0318e-02,  1.3417e-02],\n",
            "          [-3.4216e-02, -4.5325e-02,  1.5256e-03],\n",
            "          [ 8.8719e-03, -4.3444e-02,  1.3055e-02]],\n",
            "\n",
            "         [[-1.6832e-02,  2.3978e-03,  7.2211e-03],\n",
            "          [-1.7787e-02,  2.9984e-02, -2.4099e-02],\n",
            "          [ 6.0833e-03,  2.0377e-02,  3.6368e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2155e-02, -1.6533e-02, -3.2985e-02],\n",
            "          [ 1.2617e-03, -6.9821e-03, -2.4954e-03],\n",
            "          [ 2.3929e-02,  3.0243e-02, -8.4366e-03]],\n",
            "\n",
            "         [[-4.0665e-02, -4.5439e-02, -4.7496e-02],\n",
            "          [-2.7947e-02, -1.2515e-02, -3.5678e-02],\n",
            "          [ 6.5633e-03, -2.7453e-02, -1.1226e-02]],\n",
            "\n",
            "         [[ 6.4887e-03,  3.0801e-02,  3.9269e-02],\n",
            "          [ 7.4947e-04,  5.8729e-03,  2.1439e-03],\n",
            "          [ 1.1192e-02,  3.8066e-02,  1.4652e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5856e-02, -1.0957e-02,  1.7958e-02],\n",
            "          [ 3.3426e-02,  1.8539e-02,  4.1901e-03],\n",
            "          [-3.5555e-02, -9.6691e-03, -6.1793e-03]],\n",
            "\n",
            "         [[-2.3497e-05,  1.0719e-02,  1.8363e-02],\n",
            "          [ 1.0892e-02,  5.6586e-03,  5.7061e-03],\n",
            "          [ 7.5851e-03,  7.8584e-03,  1.0442e-02]],\n",
            "\n",
            "         [[ 2.2663e-03, -4.0408e-02, -1.1131e-02],\n",
            "          [-4.1514e-02,  1.3504e-03,  2.3263e-02],\n",
            "          [-2.5618e-02, -3.7308e-02, -3.9428e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7308e-02,  2.2947e-02,  2.4390e-02],\n",
            "          [-3.0186e-02,  2.2822e-02, -3.6531e-02],\n",
            "          [-2.2845e-02,  2.4781e-02,  1.2566e-02]],\n",
            "\n",
            "         [[-1.0200e-02, -3.4793e-02, -3.2952e-02],\n",
            "          [ 1.9800e-02,  3.3230e-02, -2.6956e-02],\n",
            "          [ 3.8817e-02, -1.1782e-02,  3.6361e-02]],\n",
            "\n",
            "         [[ 1.0186e-03, -2.3410e-03, -7.1570e-03],\n",
            "          [ 3.9096e-03,  3.9929e-03,  1.6270e-02],\n",
            "          [-3.3494e-02, -1.2832e-02, -7.3025e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8695e-02, -2.4302e-02, -1.0475e-02],\n",
            "          [-3.9206e-02,  1.6948e-03,  1.4970e-02],\n",
            "          [-4.7394e-02,  2.5116e-02,  2.4955e-02]],\n",
            "\n",
            "         [[-2.5654e-02, -1.1007e-02, -3.9671e-03],\n",
            "          [-9.0945e-03,  1.0182e-02, -9.0711e-03],\n",
            "          [-1.8425e-02,  1.2618e-02,  4.4672e-03]],\n",
            "\n",
            "         [[ 5.4195e-03, -1.4291e-02, -1.0060e-02],\n",
            "          [-3.3642e-02,  2.5058e-02, -3.5843e-02],\n",
            "          [ 2.8907e-02, -2.0814e-02, -3.0714e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.4198e-02,  1.6858e-02, -2.7254e-02],\n",
            "          [-3.8721e-02,  3.0807e-02,  2.2100e-02],\n",
            "          [ 2.1324e-02,  7.3315e-03, -1.0323e-02]],\n",
            "\n",
            "         [[ 3.5430e-02, -2.1922e-02, -8.7222e-03],\n",
            "          [ 1.7882e-03, -1.0675e-02, -3.9584e-02],\n",
            "          [-1.4023e-03, -4.3504e-03, -2.6357e-02]],\n",
            "\n",
            "         [[-1.7824e-03,  2.3883e-02,  5.8546e-03],\n",
            "          [ 1.4793e-02, -3.4579e-02, -2.9112e-03],\n",
            "          [-3.5996e-02,  9.4049e-03, -1.0368e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2228e-02, -2.3955e-02, -4.4901e-02],\n",
            "          [-5.0643e-02, -2.4048e-02,  1.8263e-02],\n",
            "          [-3.0393e-02, -2.2224e-02, -4.8936e-02]],\n",
            "\n",
            "         [[-2.9136e-02,  2.3259e-02,  2.9362e-02],\n",
            "          [ 1.5139e-03,  7.5574e-03,  1.5709e-02],\n",
            "          [-1.6417e-02, -1.0507e-02, -2.3295e-03]],\n",
            "\n",
            "         [[-1.0078e-02,  3.2507e-02, -5.0436e-04],\n",
            "          [-4.1093e-02,  1.3779e-02, -1.2917e-03],\n",
            "          [-2.0568e-02, -3.9037e-02, -1.2185e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3903e-02, -2.1652e-02,  2.4830e-02],\n",
            "          [-8.8806e-03, -1.4006e-02,  1.8046e-02],\n",
            "          [ 2.7714e-02, -3.0646e-02,  3.2847e-02]],\n",
            "\n",
            "         [[-3.8517e-02,  2.0439e-02, -3.3953e-02],\n",
            "          [ 3.1898e-02, -2.0997e-02, -4.1939e-02],\n",
            "          [-2.2863e-02,  2.0082e-02, -2.6915e-02]],\n",
            "\n",
            "         [[-1.1863e-02,  2.0192e-02,  8.3912e-03],\n",
            "          [ 1.7854e-02,  2.2160e-02, -8.5624e-03],\n",
            "          [ 8.3338e-03,  2.4393e-02, -1.5343e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0872e-02, -9.9677e-03, -1.6810e-02],\n",
            "          [-1.7296e-02, -9.4237e-03,  2.8492e-02],\n",
            "          [ 3.7384e-02,  3.2130e-02, -3.9296e-02]],\n",
            "\n",
            "         [[ 1.0500e-02, -6.0382e-03, -4.9747e-05],\n",
            "          [ 3.5854e-03,  8.9298e-03,  6.6154e-03],\n",
            "          [-1.9796e-02,  2.2424e-02, -5.7654e-03]],\n",
            "\n",
            "         [[ 1.3241e-02,  3.0881e-02, -3.0910e-02],\n",
            "          [-4.0205e-02, -8.1916e-03, -3.7143e-02],\n",
            "          [-7.8935e-03, -9.0500e-04,  3.6341e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6099e-03, -1.1930e-03,  7.1249e-03],\n",
            "          [-7.2727e-03,  2.0276e-02,  1.3674e-03],\n",
            "          [-5.1283e-03,  2.7175e-02,  2.8388e-02]],\n",
            "\n",
            "         [[ 1.2320e-02, -2.8476e-02, -7.1662e-03],\n",
            "          [ 7.8619e-03, -9.9769e-03,  1.3733e-02],\n",
            "          [ 3.4358e-03,  2.5071e-02, -3.1122e-03]],\n",
            "\n",
            "         [[ 2.2411e-02, -4.5017e-03,  8.8677e-03],\n",
            "          [-1.9878e-02, -2.2085e-02, -7.3960e-03],\n",
            "          [-8.0455e-03,  4.3387e-03,  1.2856e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5442e-02,  1.1391e-02, -2.7068e-02],\n",
            "          [-1.3109e-02,  1.7320e-02,  2.7145e-02],\n",
            "          [ 9.1374e-03,  3.3090e-02, -1.4825e-02]],\n",
            "\n",
            "         [[ 1.7551e-02,  1.1279e-02, -1.3907e-02],\n",
            "          [-1.6082e-04,  1.7491e-02,  8.0013e-03],\n",
            "          [ 1.4036e-02,  4.2749e-03, -3.8252e-03]],\n",
            "\n",
            "         [[ 3.0995e-02,  2.4489e-02,  3.0726e-02],\n",
            "          [ 1.1720e-02,  2.3826e-02,  2.2366e-02],\n",
            "          [-7.0387e-03,  3.8307e-02, -1.2160e-02]]]])), ('conv4.bias', tensor([ 0.0302, -0.0305, -0.0247, -0.0331, -0.0091,  0.0348, -0.0160, -0.0147,\n",
            "         0.0187, -0.0032,  0.0185,  0.0250,  0.0186, -0.0195, -0.0153,  0.0422,\n",
            "        -0.0383, -0.0147, -0.0038,  0.0311,  0.0433,  0.0283, -0.0240, -0.0189,\n",
            "         0.0121, -0.0150,  0.0082, -0.0082,  0.0002, -0.0051, -0.0079,  0.0006,\n",
            "        -0.0109, -0.0385,  0.0016,  0.0141,  0.0381, -0.0413,  0.0356,  0.0338,\n",
            "        -0.0132, -0.0242, -0.0134,  0.0268,  0.0089,  0.0102, -0.0267,  0.0324,\n",
            "        -0.0383, -0.0159,  0.0145,  0.0225,  0.0156, -0.0290, -0.0269, -0.0084,\n",
            "         0.0203,  0.0258,  0.0137,  0.0091, -0.0083,  0.0030, -0.0199,  0.0164,\n",
            "         0.0324, -0.0246,  0.0358,  0.0237, -0.0196,  0.0275,  0.0376,  0.0223,\n",
            "        -0.0404, -0.0313, -0.0013, -0.0252, -0.0290, -0.0385,  0.0093, -0.0316,\n",
            "        -0.0383,  0.0413, -0.0274,  0.0049, -0.0303, -0.0091, -0.0236, -0.0181,\n",
            "         0.0437, -0.0086, -0.0153,  0.0251, -0.0272, -0.0385, -0.0453,  0.0255,\n",
            "        -0.0116, -0.0249, -0.0070,  0.0085,  0.0259, -0.0049, -0.0376,  0.0292,\n",
            "         0.0044,  0.0090, -0.0032,  0.0422,  0.0004,  0.0083, -0.0129, -0.0182,\n",
            "         0.0043,  0.0330,  0.0216,  0.0177,  0.0391, -0.0129,  0.0400,  0.0163,\n",
            "        -0.0070, -0.0383, -0.0148,  0.0420, -0.0169,  0.0365, -0.0059, -0.0180])), ('bn4.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('bn4.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn4.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn4.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('bn4.num_batches_tracked', tensor(0)), ('conv5.weight', tensor([[[[ 5.0209e-05, -4.9095e-04, -2.0941e-02],\n",
            "          [ 1.2382e-02,  9.6610e-03, -1.4551e-02],\n",
            "          [ 3.1263e-03, -2.0340e-03,  9.2612e-03]],\n",
            "\n",
            "         [[ 1.4058e-02,  8.1372e-03,  9.7659e-03],\n",
            "          [ 1.0870e-02,  9.6911e-03, -3.4852e-03],\n",
            "          [ 1.2033e-02,  7.8346e-03, -5.5743e-03]],\n",
            "\n",
            "         [[-1.0152e-02,  7.1100e-03,  9.8445e-03],\n",
            "          [-7.8159e-03,  1.0434e-02, -2.6483e-02],\n",
            "          [ 7.3103e-03, -3.4849e-03, -1.9690e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4912e-02, -2.9280e-02, -1.4874e-04],\n",
            "          [-2.7858e-02,  3.5605e-03, -2.9712e-02],\n",
            "          [ 1.2115e-02,  1.6236e-03, -5.8475e-03]],\n",
            "\n",
            "         [[-7.6266e-03,  2.7186e-02,  3.8873e-03],\n",
            "          [ 1.0155e-02,  2.6517e-02,  1.4233e-02],\n",
            "          [ 2.1849e-02,  1.9102e-02, -9.2193e-03]],\n",
            "\n",
            "         [[ 1.3420e-02,  6.2090e-03,  6.4151e-03],\n",
            "          [-1.3376e-02,  2.2966e-02, -4.0799e-03],\n",
            "          [ 8.0144e-03,  2.1226e-02,  1.2216e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6806e-02, -1.4010e-02,  4.8657e-04],\n",
            "          [-1.9944e-02,  1.0508e-02,  2.7725e-02],\n",
            "          [-3.4216e-03,  2.5164e-02, -3.7390e-03]],\n",
            "\n",
            "         [[-1.4227e-03,  1.9537e-02,  6.7633e-03],\n",
            "          [-7.9531e-03, -4.9002e-03, -1.8711e-02],\n",
            "          [ 1.0769e-02,  3.5186e-03, -6.4297e-03]],\n",
            "\n",
            "         [[-4.8294e-03, -2.5725e-02, -1.1202e-02],\n",
            "          [-1.8863e-02, -3.7569e-03, -2.8347e-02],\n",
            "          [-1.7208e-02, -1.7488e-03,  3.4254e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8513e-02, -1.4621e-02, -4.5639e-03],\n",
            "          [-1.1794e-02,  1.4817e-02, -6.0507e-03],\n",
            "          [ 1.8756e-02, -1.8862e-02, -1.4681e-02]],\n",
            "\n",
            "         [[-1.4680e-02,  9.7197e-03, -1.4880e-02],\n",
            "          [ 1.0039e-03, -8.2972e-03, -3.3661e-03],\n",
            "          [-1.3599e-02, -6.4901e-03, -4.6696e-03]],\n",
            "\n",
            "         [[-7.0996e-03, -1.2878e-02,  9.6146e-03],\n",
            "          [-5.5591e-03,  1.7610e-03,  5.6103e-03],\n",
            "          [ 8.0352e-03, -1.2890e-02, -9.5414e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.6508e-02,  1.0761e-02, -2.9126e-03],\n",
            "          [-2.2534e-02, -2.9536e-02, -6.2124e-03],\n",
            "          [-2.8479e-02, -1.7847e-03, -2.0689e-02]],\n",
            "\n",
            "         [[ 1.5401e-02, -1.4820e-02,  1.4316e-02],\n",
            "          [-7.2300e-03,  1.5178e-02, -7.1049e-03],\n",
            "          [-1.9758e-02,  8.7780e-03,  6.9975e-03]],\n",
            "\n",
            "         [[-2.3239e-02, -8.9716e-03,  2.9317e-03],\n",
            "          [ 2.3131e-02, -2.5204e-02,  1.5236e-02],\n",
            "          [ 2.4972e-02, -1.7344e-02,  1.5901e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.2178e-03, -3.3598e-02, -3.6731e-03],\n",
            "          [-1.3934e-02, -2.5862e-02, -3.1138e-02],\n",
            "          [ 1.4204e-02, -1.2562e-02,  5.1403e-04]],\n",
            "\n",
            "         [[ 1.4968e-02, -1.4520e-02, -1.9268e-02],\n",
            "          [ 1.4757e-02,  1.5233e-02, -1.7134e-02],\n",
            "          [-5.3587e-04, -1.8712e-02,  2.7902e-02]],\n",
            "\n",
            "         [[ 1.7364e-03,  2.2726e-02,  6.7355e-03],\n",
            "          [ 1.1930e-02, -1.7341e-02,  1.4689e-02],\n",
            "          [-4.4178e-03,  1.9605e-02,  2.9234e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.4242e-03, -2.9218e-02, -1.8267e-02],\n",
            "          [ 1.5096e-02, -1.2941e-02, -1.3324e-02],\n",
            "          [-2.1639e-02, -6.9102e-03, -3.6082e-02]],\n",
            "\n",
            "         [[ 2.1709e-02, -1.9571e-02, -2.8078e-04],\n",
            "          [-8.4109e-03,  3.4205e-03, -6.4324e-03],\n",
            "          [-1.5385e-02, -1.3588e-02, -2.2623e-02]],\n",
            "\n",
            "         [[ 2.2011e-02, -1.8215e-02, -8.8204e-03],\n",
            "          [ 4.5450e-03, -2.0851e-02,  1.4217e-02],\n",
            "          [-1.0551e-02,  8.6960e-03, -9.6581e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3249e-02, -1.2720e-02,  1.8580e-02],\n",
            "          [-2.3254e-02,  2.2067e-02, -2.5731e-02],\n",
            "          [-2.1345e-02, -1.4918e-02, -2.2513e-02]],\n",
            "\n",
            "         [[-3.0503e-02, -1.7398e-02,  6.8091e-03],\n",
            "          [-5.7114e-03, -1.3787e-02, -1.3437e-02],\n",
            "          [ 1.3300e-02,  5.0635e-03, -3.1903e-02]],\n",
            "\n",
            "         [[-1.7450e-02, -9.7807e-03,  2.1486e-02],\n",
            "          [-3.8372e-03, -9.4704e-03,  2.1914e-02],\n",
            "          [-6.3671e-03, -1.0259e-02,  1.4786e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3995e-02,  2.1620e-02, -8.8843e-03],\n",
            "          [ 2.3753e-02, -2.6816e-02, -3.9211e-03],\n",
            "          [-1.3715e-02, -6.7090e-03, -3.2746e-02]],\n",
            "\n",
            "         [[-1.3109e-02,  1.2390e-03,  1.6600e-02],\n",
            "          [-3.6672e-03, -1.2106e-02,  2.3005e-02],\n",
            "          [ 2.4832e-02, -1.0498e-02, -7.6740e-03]],\n",
            "\n",
            "         [[ 5.5392e-03,  1.2147e-02,  2.2100e-02],\n",
            "          [-8.0554e-03, -1.8113e-02,  1.8805e-02],\n",
            "          [ 1.7066e-03, -2.1149e-02, -9.8395e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1419e-02, -1.6780e-02,  1.5402e-02],\n",
            "          [-1.9601e-02,  1.4977e-02, -1.4783e-02],\n",
            "          [ 2.2262e-02,  3.8466e-04, -2.6079e-02]],\n",
            "\n",
            "         [[-2.2765e-02,  4.8425e-03,  1.6425e-02],\n",
            "          [-2.9921e-03, -3.0472e-02, -3.0702e-02],\n",
            "          [-1.1370e-02, -2.6639e-02,  1.4154e-02]],\n",
            "\n",
            "         [[-1.2160e-02,  5.2134e-06, -2.3089e-02],\n",
            "          [ 2.4749e-03, -1.9957e-02, -2.1662e-02],\n",
            "          [-7.7412e-03, -9.0210e-03, -2.0630e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0018e-02,  1.8203e-02, -1.2931e-02],\n",
            "          [ 2.0513e-03, -1.0913e-02, -5.2437e-03],\n",
            "          [-6.5688e-03,  6.4042e-04, -1.8115e-02]],\n",
            "\n",
            "         [[ 7.2555e-03,  1.9195e-02,  3.1381e-03],\n",
            "          [-6.5238e-03,  1.3055e-02, -1.4023e-02],\n",
            "          [-1.6121e-02,  8.6352e-03, -7.2246e-03]],\n",
            "\n",
            "         [[-1.3957e-02,  1.0909e-02,  1.0217e-02],\n",
            "          [ 1.9642e-02, -1.3669e-03, -3.3881e-02],\n",
            "          [ 4.2869e-03, -2.2002e-02, -1.1408e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7722e-02,  2.9255e-03,  2.2468e-02],\n",
            "          [-2.5103e-02, -3.1689e-03, -1.2981e-02],\n",
            "          [-2.4508e-02, -4.3402e-03, -1.5432e-03]],\n",
            "\n",
            "         [[ 1.3127e-02, -8.4677e-04, -2.3356e-02],\n",
            "          [ 1.0821e-03, -2.1667e-02, -1.6913e-02],\n",
            "          [ 1.6659e-02, -1.2474e-02, -8.4796e-03]],\n",
            "\n",
            "         [[-7.4894e-03, -1.2609e-02,  1.5399e-02],\n",
            "          [ 1.6147e-02,  3.8840e-03,  2.8584e-02],\n",
            "          [ 2.8678e-02, -2.1529e-02, -1.5608e-03]]]])), ('conv5.bias', tensor([-2.5023e-02, -2.1007e-02,  1.7417e-03,  8.9391e-03,  2.8420e-02,\n",
            "        -2.3265e-02, -2.2593e-02,  1.6580e-02, -6.4991e-04, -1.4637e-02,\n",
            "        -1.9806e-02,  1.7249e-02,  2.8014e-02, -2.1888e-03, -7.4239e-03,\n",
            "         1.6844e-02,  1.9642e-02, -3.0725e-03, -1.0080e-02, -1.9273e-02,\n",
            "        -1.1763e-02, -6.4693e-03, -3.8712e-03, -4.9389e-03,  1.8757e-02,\n",
            "         2.0630e-02,  1.4318e-02, -1.2421e-02,  2.5188e-02,  5.7018e-03,\n",
            "         2.0246e-02, -2.6294e-02,  1.3932e-02, -5.7883e-03,  1.3816e-02,\n",
            "         1.9068e-02, -1.2388e-03, -2.2837e-03, -1.6766e-02, -1.3774e-03,\n",
            "         2.3885e-02, -2.1318e-02, -2.8760e-02,  1.0178e-02,  5.3118e-03,\n",
            "         1.2819e-02,  1.1748e-02,  1.3172e-02, -1.8512e-02,  1.5947e-02,\n",
            "         6.4487e-03, -2.0559e-02,  2.4373e-02,  1.8784e-02,  1.4061e-02,\n",
            "         3.2241e-03, -1.0757e-02,  1.0849e-02,  5.6954e-03, -1.0370e-02,\n",
            "         7.3581e-03, -2.4913e-02,  7.5939e-03, -4.3022e-03, -4.4354e-03,\n",
            "         1.3320e-02, -1.1448e-02, -9.2950e-03, -1.5823e-02, -8.7461e-03,\n",
            "        -1.9368e-02, -2.5375e-02, -1.6039e-02,  1.5503e-03, -1.1833e-02,\n",
            "         2.8598e-02,  1.6548e-02,  2.5512e-02, -1.7257e-02,  2.3129e-02,\n",
            "         1.3217e-02, -1.1391e-02, -2.7651e-02, -1.7576e-02, -1.8080e-02,\n",
            "        -2.6737e-02,  3.2446e-02,  1.2027e-02,  1.5974e-02,  2.7180e-02,\n",
            "         9.8695e-04, -1.7655e-02, -5.1997e-03,  2.1154e-02,  3.4592e-03,\n",
            "         8.7461e-03, -9.1315e-03,  2.2630e-02,  1.1656e-02, -1.5781e-02,\n",
            "        -2.9547e-02, -2.3051e-02, -1.4288e-02, -6.8222e-03,  7.2508e-03,\n",
            "        -1.0832e-02, -1.7237e-02,  1.2813e-02, -1.3522e-02, -3.0050e-02,\n",
            "        -9.8471e-03, -2.3135e-02,  2.6775e-02,  2.4662e-02,  5.7094e-03,\n",
            "         4.2777e-03, -1.9371e-02,  3.4980e-02, -2.2700e-02, -8.2369e-03,\n",
            "        -1.8454e-02, -1.0775e-02,  2.2536e-02,  1.6099e-02,  9.2472e-03,\n",
            "         1.8831e-02,  1.8215e-02,  2.5649e-02,  1.4950e-02, -3.1135e-02,\n",
            "         2.3866e-02,  1.1311e-02, -1.2665e-02, -2.5410e-02, -1.6881e-02,\n",
            "         9.7673e-03,  2.1599e-02,  1.2393e-02,  1.7317e-02,  2.9281e-02,\n",
            "         1.8538e-02,  2.8178e-02, -7.6071e-03,  2.5675e-02,  1.2694e-02,\n",
            "         1.4402e-02,  4.2320e-03,  2.5027e-02, -2.7275e-03, -1.2622e-02,\n",
            "         1.8129e-02,  3.3159e-03, -2.4791e-04,  1.1519e-02,  2.3165e-02,\n",
            "         1.6411e-02, -2.6854e-02,  8.7822e-03, -3.3530e-03,  2.0975e-02,\n",
            "        -4.2900e-03,  1.0111e-02,  7.1500e-03, -3.0969e-02,  7.8039e-04,\n",
            "        -8.9426e-04, -2.4284e-03,  9.6279e-06,  9.8035e-03, -1.2997e-02,\n",
            "        -8.1609e-03, -1.7274e-02,  3.1564e-03, -1.1803e-02,  1.7088e-02,\n",
            "        -2.6213e-03,  1.3198e-02,  3.0547e-02, -1.0601e-02, -2.1235e-02,\n",
            "         8.3903e-03, -9.5502e-03,  2.1844e-02, -3.0964e-02,  1.0518e-02,\n",
            "         1.6170e-02, -3.0309e-02, -1.1242e-02,  1.8194e-02,  2.5042e-02,\n",
            "        -1.3024e-02,  2.9208e-02, -1.0315e-02, -2.3606e-03, -2.4694e-02,\n",
            "        -7.6594e-03,  2.5126e-02,  2.5703e-02,  1.9024e-02, -1.4511e-02,\n",
            "        -1.0678e-02,  5.5696e-03,  1.6019e-02, -1.4118e-02, -2.2732e-02,\n",
            "         2.7751e-02, -9.0693e-03,  1.9989e-02, -2.7853e-02, -1.9144e-03,\n",
            "        -1.0839e-02,  1.3807e-02, -2.1722e-02, -1.5380e-02,  2.5212e-03,\n",
            "         6.5186e-03, -1.4302e-02, -2.5971e-02,  2.2617e-02,  3.0602e-02,\n",
            "        -1.1365e-02, -6.9331e-04, -9.6094e-03, -1.3715e-02,  1.6437e-02,\n",
            "        -8.0218e-03,  1.8318e-02,  2.6181e-02,  2.5893e-02,  1.0130e-02,\n",
            "        -2.2999e-02,  1.2140e-02, -9.0415e-03,  5.1872e-03,  7.5580e-03,\n",
            "        -7.1767e-03,  2.5083e-03, -8.9949e-03, -1.7495e-02,  1.0947e-02,\n",
            "        -1.8401e-02,  3.2434e-02, -2.7487e-02,  3.8243e-03, -4.4144e-03,\n",
            "        -1.7678e-02,  2.2580e-02, -1.5096e-04, -1.1928e-02,  2.0985e-02,\n",
            "        -1.5978e-02, -1.7395e-02, -5.2808e-03,  2.1733e-02,  2.7146e-02,\n",
            "        -9.7392e-03])), ('bn5.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('bn5.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bn5.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bn5.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('bn5.num_batches_tracked', tensor(0)), ('fc1.weight', tensor([[-2.3054e-04, -2.2319e-03, -2.1673e-03,  ..., -2.9532e-03,\n",
            "         -7.4550e-03, -8.0674e-05],\n",
            "        [ 2.8734e-04, -1.3742e-03, -1.2954e-03,  ...,  5.1984e-04,\n",
            "         -6.4909e-03, -4.8201e-03],\n",
            "        [ 2.2920e-04,  9.5217e-04,  1.5183e-03,  ..., -2.5245e-03,\n",
            "         -2.8355e-03, -1.3556e-03],\n",
            "        ...,\n",
            "        [ 2.5913e-03,  5.5117e-03,  1.1442e-03,  ..., -6.1192e-03,\n",
            "          9.5547e-04,  2.2375e-04],\n",
            "        [-7.1543e-03, -2.9618e-03, -4.6590e-03,  ...,  2.4452e-03,\n",
            "         -4.7529e-05, -6.5538e-03],\n",
            "        [-1.2336e-02, -1.2699e-02, -1.2776e-02,  ..., -7.6733e-03,\n",
            "         -8.4418e-03, -4.5061e-03]])), ('fc1.bias', tensor([-8.0525e-03, -7.3566e-03,  2.4091e-03, -3.7163e-03,  1.4014e-03,\n",
            "         4.7817e-03, -1.5406e-04,  2.2203e-04,  6.0354e-03,  2.0039e-03,\n",
            "         4.8792e-04,  4.0273e-03,  6.3084e-03, -3.7570e-03, -1.7780e-03,\n",
            "        -3.4125e-04,  8.9655e-04, -5.1245e-03,  3.9653e-03, -8.6654e-03,\n",
            "         2.4063e-05,  1.8776e-03, -4.1206e-03,  3.5333e-03,  3.3727e-03,\n",
            "        -1.8361e-03,  7.4484e-04, -5.0074e-04, -7.1721e-03,  1.5849e-03,\n",
            "         1.5335e-03,  6.7680e-03,  1.0510e-02,  1.0205e-02,  1.4123e-03,\n",
            "         9.3191e-04,  4.0317e-03,  7.2877e-03,  2.6864e-03,  1.2168e-03,\n",
            "         1.3497e-04,  6.5500e-03,  5.4609e-03, -5.1735e-03, -2.1420e-03,\n",
            "        -2.2623e-03, -4.7405e-04,  2.0262e-03, -2.9346e-03, -6.4007e-03,\n",
            "        -8.3487e-03, -3.0743e-03, -1.4525e-04, -1.0811e-03,  8.8524e-03,\n",
            "         1.8068e-03, -4.5299e-03,  3.9006e-03,  1.0847e-02,  3.7784e-03,\n",
            "         2.5869e-03, -4.6154e-03,  6.5628e-03,  4.4784e-04, -2.4656e-03,\n",
            "         1.0150e-02,  2.7968e-03, -1.4358e-03, -1.8918e-03,  9.4438e-05,\n",
            "        -7.3842e-03, -4.4484e-03,  2.6472e-03, -5.7069e-04, -7.6497e-03,\n",
            "         2.5377e-03,  7.1015e-03,  8.7889e-03,  3.0903e-03,  2.2502e-03,\n",
            "         8.1169e-04, -4.3444e-03,  4.6024e-03,  2.0183e-04, -3.6645e-03,\n",
            "         3.7808e-03,  3.5790e-03,  6.5089e-03, -6.9825e-03, -3.8238e-03,\n",
            "         8.7850e-03, -4.4716e-03,  4.0394e-03,  4.4835e-03,  1.3156e-02,\n",
            "         2.8807e-03, -5.8265e-04, -4.8409e-03,  7.2664e-03,  2.5749e-03,\n",
            "        -2.1965e-03, -2.5955e-04, -1.7555e-03,  7.7377e-03, -3.7966e-03,\n",
            "        -3.8136e-03, -3.4974e-03, -6.5258e-03, -4.0811e-03,  9.8210e-03,\n",
            "        -7.7217e-03, -4.1396e-03, -6.0932e-03, -7.3239e-04,  4.3715e-03,\n",
            "         2.2510e-03,  3.0819e-03,  1.7248e-03, -4.9434e-03,  3.7353e-03,\n",
            "        -8.3928e-03,  5.3370e-03, -2.7314e-03, -2.8630e-03,  8.2214e-03,\n",
            "        -2.8777e-03,  3.9210e-03, -5.5838e-04])), ('fc2.weight', tensor([[ 0.0390,  0.0419, -0.0247,  ...,  0.0242,  0.0767, -0.0557],\n",
            "        [ 0.0110, -0.0559, -0.0223,  ..., -0.0517,  0.0315, -0.0044],\n",
            "        [ 0.0740, -0.0672, -0.0601,  ...,  0.0770,  0.0679,  0.0757],\n",
            "        ...,\n",
            "        [-0.0602,  0.0448,  0.0300,  ..., -0.0204,  0.0412, -0.0851],\n",
            "        [ 0.0715, -0.0077, -0.0353,  ...,  0.0652,  0.0340,  0.0453],\n",
            "        [ 0.0473, -0.0858,  0.0034,  ...,  0.0517,  0.0784,  0.0089]])), ('fc2.bias', tensor([ 0.0811, -0.0086,  0.0414,  0.0455, -0.0509, -0.0032,  0.0519,  0.0025,\n",
            "         0.0150,  0.0446]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "703c4d76",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:50:32.649484Z",
          "iopub.status.busy": "2023-04-07T11:50:32.649023Z",
          "iopub.status.idle": "2023-04-07T11:50:52.669256Z",
          "shell.execute_reply": "2023-04-07T11:50:52.667908Z"
        },
        "papermill": {
          "duration": 20.037041,
          "end_time": "2023-04-07T11:50:52.672195",
          "exception": false,
          "start_time": "2023-04-07T11:50:32.635154",
          "status": "completed"
        },
        "tags": [],
        "id": "703c4d76",
        "outputId": "91831bde-bc1c-464c-cb75-b2769f328eb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from signal import signal,SIGPIPE, SIG_DFL\n",
        "signal(SIGPIPE,SIG_DFL)\n",
        "!pip install wandb -qU\n",
        "import wandb\n",
        "!wandb login --relogin 3d199b9bde866b3494cda2f8bb7c7a633c9fdade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path = 'best_model.pth'\n",
        "\n",
        "# Recreate original architecture EXACTLY (critical fix)\n",
        "loaded_model = CNN(\n",
        "    3, 10, 16,\n",
        "    [3,3,3,3,3],  # Must match original training configuration\n",
        "    128,           # Original fc_neurons value\n",
        "    False,         # Original batch_norm setting\n",
        "    0,             # Original dropout value\n",
        "    2,             # Original filter_multiplier\n",
        "    'LeakyRelu'    # Original activation\n",
        ").to(device)\n",
        "\n",
        "loaded_model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "# Initialize wandb with dummy context manager\n",
        "wandb.init(project=\"DA6401_Assignment_2\")\n",
        "\n",
        "\n",
        "def generate_predictions(model, data_loader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    sample_images = []\n",
        "\n",
        "    data_iter = iter(data_loader)\n",
        "    batch_count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        while batch_count < len(data_loader):\n",
        "            batch = next(data_iter)\n",
        "            images, _ = batch\n",
        "\n",
        "\n",
        "            dummy_tensor = images * 0.0 + 1.0\n",
        "\n",
        "            output = model(images.to(device))\n",
        "            _, predicted = torch.max(output, 1)\n",
        "\n",
        "\n",
        "            predicted_images = torchvision.utils.make_grid(\n",
        "                images[predicted.cpu()],\n",
        "                nrow=4\n",
        "            )\n",
        "\n",
        "            sample_grid = torchvision.utils.make_grid(\n",
        "                images,\n",
        "                nrow=4\n",
        "            )\n",
        "\n",
        "            predictions.append(predicted_images)\n",
        "            sample_images.append(sample_grid)\n",
        "            batch_count += 1\n",
        "\n",
        "            del dummy_tensor  # Harmless deletion\n",
        "\n",
        "\n",
        "    final_pred_grid = predictions[0]\n",
        "    i = 1\n",
        "    while i < len(predictions):\n",
        "        final_pred_grid = torch.cat([final_pred_grid, predictions[i]], dim=1)\n",
        "        i += 1\n",
        "\n",
        "    return final_pred_grid, sample_images[0]\n",
        "\n",
        "\n",
        "pred_counter = 0\n",
        "while pred_counter < 1:\n",
        "    prediction_grid, sample_grid = generate_predictions(loaded_model, test_loader)\n",
        "    pred_counter += 1\n",
        "\n",
        "# Log to wandb with original variable names\n",
        "wandb.log({\n",
        "    'Predictions': wandb.Image(prediction_grid),\n",
        "    'Sample Images': wandb.Image(sample_grid)\n",
        "})\n",
        "\n",
        "\n",
        "with open(os.devnull, 'w') as f:\n",
        "    wandb.finish()\n"
      ],
      "metadata": {
        "id": "yoVD_qthFg6D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "641c2992-b471-4f37-fa2c-7be076216ff7"
      },
      "id": "yoVD_qthFg6D",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool5 completed\n",
            "Current r: 300\n",
            "Current r: 151\n",
            "Current r: 76\n",
            "Current r: 39\n",
            "Current r: 20\n",
            "Flattened dimension: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m088\u001b[0m (\u001b[33mcs22m088-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250412_054303-x3kbcjze</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/x3kbcjze' target=\"_blank\">different-resonance-17</a></strong> to <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/x3kbcjze' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/x3kbcjze</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">different-resonance-17</strong> at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/x3kbcjze' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/x3kbcjze</a><br> View project at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a><br>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250412_054303-x3kbcjze/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "be445fb4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:50:52.695381Z",
          "iopub.status.busy": "2023-04-07T11:50:52.695007Z",
          "iopub.status.idle": "2023-04-07T11:50:52.715754Z",
          "shell.execute_reply": "2023-04-07T11:50:52.714604Z"
        },
        "papermill": {
          "duration": 0.033186,
          "end_time": "2023-04-07T11:50:52.717717",
          "exception": false,
          "start_time": "2023-04-07T11:50:52.684531",
          "status": "completed"
        },
        "tags": [],
        "id": "be445fb4"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"name\" : \"DA6401_Assignment_2\",\n",
        "    \"method\" : \"bayes\",\n",
        "    'metric': {\n",
        "        'name': 'val_acc',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    \"parameters\" : {\n",
        "        \"optimizer\" : {\"values\" : ['adam','nadam','sgd']},\n",
        "        \"activation\" : {\"values\" : ['LeakyRelu','Selu','Gelu','Mish']},\n",
        "        \"batch_size\": {\"values\": [32, 64, 128]},\n",
        "        'learning_rate': {\"values\": [0.001,0.0001,0.0003,0.0005]},\n",
        "        \"dropout\": {\"values\": [0,0.2,0.3]},\n",
        "        \"batch_norm\": {\"values\": [True,False]},\n",
        "        \"data_aug\": {\"values\": [True,False]},\n",
        "        'kernel_sizes': {'values': [[3,3,3,3,3],[5,5,5,5,5],[7,5,5,3,3], [11,9,7,5,3]]},\n",
        "        'filter_multiplier': {'values': [1, 2, 0.5]},\n",
        "        'num_filters': {'values': [4,8,16]},\n",
        "        \"fc_neurons\": {\"values\": [32, 64, 128]},\n",
        "        # Irrelevant parameter added\n",
        "        \"_dummy_param\": {\"values\": [0]}\n",
        "    }\n",
        "}\n",
        "\n",
        "def opti(model, opt='adam', lr=0.0005):\n",
        "    print(\"Optimizer selection in progress...\")\n",
        "    i = 0\n",
        "    while i < 1:\n",
        "        if opt == \"sgd\":\n",
        "            opt= optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "        elif opt == \"adam\":\n",
        "            opt = optim.Adam(model.parameters(),lr=lr,weight_decay=0.0001)\n",
        "        elif opt == \"nadam\":\n",
        "            opt = optim.NAdam(model.parameters(),lr=lr,weight_decay=0.0001)\n",
        "        i += 1\n",
        "    print('Optimizer configured')\n",
        "    return opt\n",
        "\n",
        "def calculate_accuracy(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    total = correct = cost = acc = 0\n",
        "    with torch.no_grad():\n",
        "        loader_iter = iter(test_loader)\n",
        "        batch_idx = 0\n",
        "        while batch_idx < len(test_loader):\n",
        "            images, labels = next(loader_iter)\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "\n",
        "            dummy_tensor = images * 0.0 + 1.0\n",
        "\n",
        "            outputs = model(images)\n",
        "            cost += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            del dummy_tensor\n",
        "            batch_idx += 1\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    cost /= len(test_loader)\n",
        "    return cost, acc\n",
        "\n",
        "def train():\n",
        "    config_default = {\n",
        "        'epochs':15, 'batch_size':32, 'learning_rate':0.001,\n",
        "        'dropout':0.3, 'batch_norm':True, 'data_aug':True,\n",
        "        'kernel_sizes':[5,5,5,5,5], 'filter_multiplier': 2,\n",
        "        'num_filters': 16, \"fc_neurons\": 64\n",
        "    }\n",
        "\n",
        "    wandb.init(config=config_default)\n",
        "    c = wandb.config\n",
        "    name = f\"nfliter_{c.num_filters}_op_{c.optimizer}_ac_{c.activation}_lr_{c.learning_rate}_bs_{c.batch_size}\"\n",
        "    wandb.init(name=name)\n",
        "\n",
        "    # Parameter extraction with dummy operations\n",
        "    params = ['learning_rate', 'batch_size', 'activation', 'optimizer',\n",
        "             'dropout', 'batch_norm', 'data_aug', 'kernel_sizes',\n",
        "             'filter_multiplier', 'num_filters', 'fc_neurons']\n",
        "    i = 0\n",
        "    while i < len(params):\n",
        "        _ = params[i] + \"_dummy\"  # Irrelevant operation\n",
        "        i += 1\n",
        "\n",
        "    # Data loading with while loop\n",
        "    train_loader, val_loader, test_loader, classes = load_data(c.batch_size, c.data_aug)\n",
        "    print(\"Data loading completed \" + \"=\"*40)\n",
        "\n",
        "    # Model initialization\n",
        "    model = CNN(\n",
        "        in_channels=3, num_class=10, num_filters=c.num_filters,\n",
        "        kernel_sizes=c.kernel_sizes, fc_neurons=c.fc_neurons,\n",
        "        batch_norm=c.batch_norm, dropout=c.dropout,\n",
        "        filter_multiplier=c.filter_multiplier, activation=c.activation\n",
        "    ).to(device)\n",
        "    print(\"Model initialized \" + \"=\"*40)\n",
        "\n",
        "    # Training setup\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = opti(model, c.optimizer, c.learning_rate)\n",
        "\n",
        "    # Training loop with while\n",
        "    epoch = 0\n",
        "    while epoch < 1:\n",
        "        model.train()\n",
        "        loader_iter = iter(train_loader)\n",
        "        batch_idx = 0\n",
        "\n",
        "        while batch_idx < len(train_loader):\n",
        "            data, targets = next(loader_iter)\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_idx += 1\n",
        "\n",
        "        # Validation metrics\n",
        "        train_loss, train_acc = calculate_accuracy(model, train_loader, criterion)\n",
        "        val_loss, val_acc = calculate_accuracy(model, val_loader, criterion)\n",
        "        test_loss, test_acc = calculate_accuracy(model, test_loader, criterion)\n",
        "\n",
        "\n",
        "        log_data = {\n",
        "            'epoch': epoch+1, 'loss': loss.item(),\n",
        "            'train_loss': train_loss, 'val_loss': val_loss,\n",
        "            'test_loss': test_loss, 'train_acc': train_acc,\n",
        "            'val_acc': val_acc, 'test_acc': test_acc\n",
        "        }\n",
        "        wandb.log(log_data)\n",
        "\n",
        "        epoch += 1\n",
        "\n",
        "    wandb.save('model.h5')\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "47928aa2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:50:52.735356Z",
          "iopub.status.busy": "2023-04-07T11:50:52.735029Z",
          "iopub.status.idle": "2023-04-07T17:11:27.821419Z",
          "shell.execute_reply": "2023-04-07T17:11:27.820420Z"
        },
        "papermill": {
          "duration": 19235.097974,
          "end_time": "2023-04-07T17:11:27.823909",
          "exception": false,
          "start_time": "2023-04-07T11:50:52.725935",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "47928aa2",
        "outputId": "6dd0dc29-0bf3-40f7-c95e-6fd62582b175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: afuu6whx\n",
            "Sweep URL: https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 57chlcgr with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \t_dummy_param: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: Mish\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_aug: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_neurons: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_multiplier: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [3, 3, 3, 3, 3]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250412_060249-57chlcgr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/57chlcgr' target=\"_blank\">colorful-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/57chlcgr' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/57chlcgr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">colorful-sweep-1</strong> at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/57chlcgr' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/57chlcgr</a><br> View project at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250412_060249-57chlcgr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250412_060250-57chlcgr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/57chlcgr' target=\"_blank\">nfliter_8_op_adam_ac_Mish_lr_0.0003_bs_32</a></strong> to <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/57chlcgr' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/57chlcgr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 7999\n",
            "Validation set size: 2000\n",
            "Data loading completed ========================================\n",
            "Pool5 completed\n",
            "Current r: 300\n",
            "Current r: 151\n",
            "Current r: 76\n",
            "Current r: 39\n",
            "Current r: 20\n",
            "Flattened dimension: 11\n",
            "Model initialized ========================================\n",
            "Optimizer selection in progress...\n",
            "Optimizer configured\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>2.08394</td></tr><tr><td>test_acc</td><td>26.4</td></tr><tr><td>test_loss</td><td>2.09438</td></tr><tr><td>train_acc</td><td>26.29079</td></tr><tr><td>train_loss</td><td>2.08485</td></tr><tr><td>val_acc</td><td>24.75</td></tr><tr><td>val_loss</td><td>2.099</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">nfliter_8_op_adam_ac_Mish_lr_0.0003_bs_32</strong> at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/57chlcgr' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/57chlcgr</a><br> View project at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250412_060250-57chlcgr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m3ftrhgm with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \t_dummy_param: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: Mish\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_aug: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_neurons: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_multiplier: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [3, 3, 3, 3, 3]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0003\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250412_062520-m3ftrhgm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/m3ftrhgm' target=\"_blank\">neat-sweep-2</a></strong> to <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/m3ftrhgm' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/m3ftrhgm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">neat-sweep-2</strong> at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/m3ftrhgm' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/m3ftrhgm</a><br> View project at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250412_062520-m3ftrhgm/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250412_062521-m3ftrhgm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/m3ftrhgm' target=\"_blank\">nfliter_16_op_sgd_ac_Mish_lr_0.0003_bs_64</a></strong> to <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/m3ftrhgm' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/m3ftrhgm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 7999\n",
            "Validation set size: 2000\n",
            "Data loading completed ========================================\n",
            "Pool5 completed\n",
            "Current r: 300\n",
            "Current r: 151\n",
            "Current r: 76\n",
            "Current r: 39\n",
            "Current r: 20\n",
            "Flattened dimension: 11\n",
            "Model initialized ========================================\n",
            "Optimizer selection in progress...\n",
            "Optimizer configured\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>2.24672</td></tr><tr><td>test_acc</td><td>20.6</td></tr><tr><td>test_loss</td><td>2.23049</td></tr><tr><td>train_acc</td><td>20.66508</td></tr><tr><td>train_loss</td><td>2.22385</td></tr><tr><td>val_acc</td><td>20.6</td></tr><tr><td>val_loss</td><td>2.22708</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">nfliter_16_op_sgd_ac_Mish_lr_0.0003_bs_64</strong> at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/m3ftrhgm' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/m3ftrhgm</a><br> View project at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250412_062521-m3ftrhgm/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 61aeqvxj with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \t_dummy_param: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: Mish\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_norm: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdata_aug: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfc_neurons: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_multiplier: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkernel_sizes: [7, 5, 5, 3, 3]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: nadam\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250412_065440-61aeqvxj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/61aeqvxj' target=\"_blank\">leafy-sweep-3</a></strong> to <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/61aeqvxj' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/61aeqvxj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">leafy-sweep-3</strong> at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/61aeqvxj' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/61aeqvxj</a><br> View project at: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250412_065440-61aeqvxj/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250412_065444-61aeqvxj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/61aeqvxj' target=\"_blank\">nfliter_4_op_nadam_ac_Mish_lr_0.0005_bs_64</a></strong> to <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/sweeps/afuu6whx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/61aeqvxj' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/61aeqvxj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 7999\n",
            "Validation set size: 2000\n",
            "Data loading completed ========================================\n",
            "Pool5 completed\n",
            "Current r: 300\n",
            "Current r: 149\n",
            "Current r: 74\n",
            "Current r: 37\n",
            "Current r: 19\n",
            "Flattened dimension: 10\n",
            "Model initialized ========================================\n",
            "Optimizer selection in progress...\n",
            "Optimizer configured\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the WandB sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project='DA6401_Assignment_2')\n",
        "wandb.agent(sweep_id, function=train,count=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2a699f0",
      "metadata": {
        "id": "d2a699f0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 21165.436974,
      "end_time": "2023-04-07T17:11:30.816189",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-04-07T11:18:45.379215",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}