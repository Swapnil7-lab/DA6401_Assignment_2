{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swapnil7-lab/DA6401_Assignment_2/blob/main/DA6401_DL_2_partA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d1706649",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:18:55.180502Z",
          "iopub.status.busy": "2023-04-07T11:18:55.179687Z",
          "iopub.status.idle": "2023-04-07T11:18:58.147235Z",
          "shell.execute_reply": "2023-04-07T11:18:58.146104Z"
        },
        "papermill": {
          "duration": 2.974913,
          "end_time": "2023-04-07T11:18:58.150711",
          "exception": false,
          "start_time": "2023-04-07T11:18:55.175798",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1706649",
        "outputId": "10242dcc-a882-4e25-8c06-34d589e90f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "2.6.0+cu124\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "print(torch.device('cuda:0'))\n",
        "print(torch.__version__)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bfc3bb19",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:18:58.158540Z",
          "iopub.status.busy": "2023-04-07T11:18:58.158066Z",
          "iopub.status.idle": "2023-04-07T11:19:45.932331Z",
          "shell.execute_reply": "2023-04-07T11:19:45.930839Z"
        },
        "papermill": {
          "duration": 47.781297,
          "end_time": "2023-04-07T11:19:45.935224",
          "exception": false,
          "start_time": "2023-04-07T11:18:58.153927",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfc3bb19",
        "outputId": "dd196528-82a1-4b78-dc9c-77212f5c1b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-04 07:41:28--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.69.207, 64.233.181.207, 64.233.179.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.69.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3816687935 (3.6G) [application/zip]\n",
            "Saving to: ‘nature_12K.zip’\n",
            "\n",
            "nature_12K.zip      100%[===================>]   3.55G   186MB/s    in 27s     \n",
            "\n",
            "2025-04-04 07:41:55 (137 MB/s) - ‘nature_12K.zip’ saved [3816687935/3816687935]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://storage.googleapis.com/wandb_datasets/nature_12K.zip'\n",
        "!unzip -q nature_12K.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "edd29c7e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:19:47.710012Z",
          "iopub.status.busy": "2023-04-07T11:19:47.701577Z",
          "iopub.status.idle": "2023-04-07T11:19:48.137919Z",
          "shell.execute_reply": "2023-04-07T11:19:48.136900Z"
        },
        "papermill": {
          "duration": 0.501656,
          "end_time": "2023-04-07T11:19:48.140529",
          "exception": false,
          "start_time": "2023-04-07T11:19:47.638873",
          "status": "completed"
        },
        "tags": [],
        "id": "edd29c7e"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "# Standard library imports\n",
        "import os\n",
        "import random\n",
        "import pathlib\n",
        "\n",
        "# Third-party library imports\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Torchvision imports\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "# Define the device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "# Data Preparation and Transformation\n",
        "def load_data(bs, augment_data=False):\n",
        "    # Configuration parameters\n",
        "    img_size = (300, 300)\n",
        "    norm_mean = (0.5, 0.5, 0.5)\n",
        "    norm_std = (0.5, 0.5, 0.5)\n",
        "\n",
        "    # Base image transformations\n",
        "    base_transform = [\n",
        "        transforms.Resize(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(norm_mean, norm_std)\n",
        "    ]\n",
        "\n",
        "    # Augmentation additions\n",
        "    augmentation_layers = [\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10)\n",
        "    ] if augment_data else []\n",
        "\n",
        "    # Create transformation pipelines\n",
        "    train_transforms = transforms.Compose([*augmentation_layers, *base_transform])\n",
        "    test_transforms = transforms.Compose(base_transform)\n",
        "\n",
        "    # Dataset paths configuration\n",
        "    data_root = \"/content/inaturalist_12K\"\n",
        "    train_dir = os.path.join(data_root, 'train')\n",
        "    eval_dir = os.path.join(data_root, 'val')\n",
        "\n",
        "    # Dataset preparation\n",
        "    train_full = ImageFolder(train_dir, transform=train_transforms)\n",
        "    eval_set = ImageFolder(eval_dir, transform=test_transforms)\n",
        "\n",
        "    # Data partitioning\n",
        "    total_train = len(train_full)\n",
        "    val_portion = 0.2\n",
        "    train_samples = int(total_train * (1 - val_portion))\n",
        "    val_samples = total_train - train_samples\n",
        "\n",
        "    # Dataset splitting\n",
        "    train_subset, val_subset = random_split(train_full, [train_samples, val_samples])\n",
        "\n",
        "    # Data loading configuration\n",
        "    loader_config = {\n",
        "        'batch_size': bs,\n",
        "        'num_workers': 2,\n",
        "        'pin_memory': True\n",
        "    }\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_subset, shuffle=True, **loader_config)\n",
        "    val_loader = DataLoader(val_subset, shuffle=False, **loader_config)\n",
        "    test_loader = DataLoader(eval_set, shuffle=False, **loader_config)\n",
        "\n",
        "    # Class label extraction\n",
        "    class_labels = [item.name for item in pathlib.Path(train_dir).iterdir()]\n",
        "    class_labels.sort()\n",
        "\n",
        "    return train_loader, val_loader, test_loader, class_labels\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7c5f5f5b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:19:48.157834Z",
          "iopub.status.busy": "2023-04-07T11:19:48.157506Z",
          "iopub.status.idle": "2023-04-07T11:19:48.181396Z",
          "shell.execute_reply": "2023-04-07T11:19:48.180429Z"
        },
        "papermill": {
          "duration": 0.0347,
          "end_time": "2023-04-07T11:19:48.183608",
          "exception": false,
          "start_time": "2023-04-07T11:19:48.148908",
          "status": "completed"
        },
        "tags": [],
        "id": "7c5f5f5b"
      },
      "outputs": [],
      "source": [
        "#Simple CNN\n",
        "def flatten(k=[11, 9, 7, 5, 3], w=300, s=1, p=1):\n",
        "    r = w\n",
        "    i = 0  # Initialize the counter for the while loop\n",
        "\n",
        "\n",
        "\n",
        "    while i < len(k):  # Loop until the counter reaches the length of k\n",
        "        print(\"r\", r)\n",
        "        r = (r + 2 * p - k[i]) + 1\n",
        "\n",
        "        r = int(r / 2) + 1\n",
        "        i += 1  # Increment the counter\n",
        "\n",
        "    return r\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_class=10, num_filters=4, kernel_sizes=[11,9,7,5,3],\n",
        "                 fc_neurons=64, batch_norm=True, dropout=0.3, filter_multiplier=2, activation='LeakyRelu'):\n",
        "\n",
        "        super(CNN, self).__init__()\n",
        "        # Preserve original parameter assignments\n",
        "        self.in_channels = in_channels\n",
        "        self.num_class = num_class\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.fc_neurons = fc_neurons\n",
        "        self.activation = activation\n",
        "        self.batch_norm = batch_norm\n",
        "        self.dropout = dropout\n",
        "        self.filter_multiplier = filter_multiplier\n",
        "\n",
        "        # Layer construction through systematic pattern\n",
        "        prev_channels = in_channels\n",
        "        for layer_idx in range(len(kernel_sizes)):\n",
        "            # Calculate output channels using exponential growth\n",
        "            out_channels = num_filters * (filter_multiplier ** layer_idx)\n",
        "\n",
        "            # Convolutional block components\n",
        "            setattr(self, f'conv{layer_idx+1}', nn.Conv2d(\n",
        "                prev_channels, out_channels,\n",
        "                kernel_size=kernel_sizes[layer_idx],\n",
        "                stride=1,\n",
        "                padding=1\n",
        "            ).to(device))\n",
        "\n",
        "            if batch_norm:\n",
        "                setattr(self, f'bn{layer_idx+1}', nn.BatchNorm2d(out_channels))\n",
        "\n",
        "            setattr(self, f'relu{layer_idx+1}', nn.LeakyReLU())\n",
        "            setattr(self, f'pool{layer_idx+1}', nn.MaxPool2d(2, 2, padding=1))\n",
        "\n",
        "            prev_channels = out_channels\n",
        "\n",
        "        # Calculate spatial dimension reduction\n",
        "        self.r = flatten(kernel_sizes)\n",
        "        print(\"ok pool5\")\n",
        "        print(\"ok flatten\")\n",
        "        print(self.r)\n",
        "\n",
        "        # Fully connected section with dynamic sizing\n",
        "        final_channels = num_filters * (filter_multiplier ** (len(kernel_sizes)-1))\n",
        "        self.fc1 = nn.Linear(\n",
        "            final_channels * self.r * self.r,\n",
        "            fc_neurons\n",
        "        )\n",
        "        self.relu6 = nn.LeakyReLU()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(fc_neurons, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Unified processing loop for convolutional blocks\n",
        "        for block_idx in range(1, 6):\n",
        "            x = getattr(self, f'conv{block_idx}')(x)\n",
        "            if self.batch_norm:\n",
        "                x = getattr(self, f'bn{block_idx}')(x)\n",
        "            x = getattr(self, f'relu{block_idx}')(x)\n",
        "            x = getattr(self, f'pool{block_idx}')(x)\n",
        "\n",
        "        # Flatten and classify\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu6(self.fc1(x))\n",
        "        return self.fc2(self.drop(x))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "173205f4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:19:48.200190Z",
          "iopub.status.busy": "2023-04-07T11:19:48.199914Z",
          "iopub.status.idle": "2023-04-07T11:50:32.615877Z",
          "shell.execute_reply": "2023-04-07T11:50:32.614873Z"
        },
        "papermill": {
          "duration": 1844.430252,
          "end_time": "2023-04-07T11:50:32.621794",
          "exception": false,
          "start_time": "2023-04-07T11:19:48.191542",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "173205f4",
        "outputId": "77141657-5955-4f7b-ea4a-04a9e37e0cda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.DS_Store', 'Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\n",
            "Feature Batch Shape: torch.Size([64, 3, 300, 300])\n",
            "Label Batch Shape: torch.Size([64])\n",
            "r 300\n",
            "r 151\n",
            "r 76\n",
            "r 39\n",
            "r 20\n",
            "ok pool5\n",
            "ok flatten\n",
            "11\n",
            "Epoch [1/1], Train Loss: 2.0793, Test Loss: 2.0802, Test Acc: 25.80%\n",
            "Best model saved to best_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Configure device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define hyperparameters\n",
        "in_channels = 3\n",
        "num_class = 10\n",
        "learning_rate = 0.0005\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "data_aug = True\n",
        "\n",
        "# Load dataset\n",
        "train_loader, val_loader, test_loader, classes = load_data(batch_size, data_aug)\n",
        "print(classes)\n",
        "\n",
        "# Display a batch of training data\n",
        "trainfeature, trainlabel = next(iter(train_loader))\n",
        "print(f\"Feature Batch Shape: {trainfeature.size()}\")\n",
        "print(f\"Label Batch Shape: {trainlabel.size()}\")\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN(in_channels, num_class, 16, [3, 3, 3, 3, 3], 128, False, 0, 2, 'LeakyRelu').to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.NAdam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "\n",
        "# Training loop using while\n",
        "epoch = 0\n",
        "while epoch < epochs:\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    train_iter = iter(train_loader)\n",
        "    batch_idx = 0\n",
        "\n",
        "    while batch_idx < len(train_loader):\n",
        "        # Get the next batch of data and targets\n",
        "        data, targets = next(train_iter)\n",
        "\n",
        "        # Transfer data to the appropriate device\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "        # Zero out gradients from the previous step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass through the model\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_idx += 1\n",
        "\n",
        "    # Evaluation mode for validation/testing\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    test_iter = iter(test_loader)\n",
        "    test_idx = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        while test_idx < len(test_loader):\n",
        "            # Get the next batch of validation/testing data and targets\n",
        "            data, targets = next(test_iter)\n",
        "\n",
        "            # Transfer data to the appropriate device\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass for validation/testing\n",
        "            scores = model(data)\n",
        "            test_loss += criterion(scores, targets).item()\n",
        "\n",
        "            # Calculate predictions and accuracy\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == targets).sum().item()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "            test_idx += 1\n",
        "\n",
        "    # Compute average loss and accuracy for validation/testing\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = num_correct / num_samples\n",
        "\n",
        "    # Print epoch statistics\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {loss.item():.4f}, '\n",
        "          f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc * 100:.2f}%')\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "# Save the best model to a file\n",
        "best_model_path = 'best_model.pth'\n",
        "torch.save(model.state_dict(), best_model_path)\n",
        "print(f\"Best model saved to {best_model_path}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = 3\n",
        "num_class = 10\n",
        "learning_rate = 0.0001\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "data_aug = False\n",
        "\n",
        "# Load data\n",
        "train_loader, val_loader, test_loader, classes = load_data(batch_size, data_aug)\n",
        "print(classes)\n",
        "trainfeature, trainlabel = next(iter(train_loader))\n",
        "print(f\"Feature Batch Shape: {trainfeature.size()}\")\n",
        "print(f\"Label Batch Shape: {trainlabel.size()}\")\n",
        "\n",
        "# Initialize network\n",
        "model = CNN(3, 10, 16, [7, 5, 5, 3, 3], 64, True, 0.2, 2, 'Mish').to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.NAdam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "\n",
        "# Train Network with while loops\n",
        "epoch = 0\n",
        "while epoch < epochs:\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Training loop\n",
        "    batch_idx = 0\n",
        "    train_iter = iter(train_loader)\n",
        "    while batch_idx < len(train_loader):\n",
        "        data, targets = next(train_iter)\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_idx += 1\n",
        "\n",
        "    # Evaluation phase\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    # Validation loop\n",
        "    test_iter = iter(test_loader)\n",
        "    test_idx = 0\n",
        "    with torch.no_grad():\n",
        "        while test_idx < len(test_loader):\n",
        "            data, targets = next(test_iter)\n",
        "            data = data.to(device=device)\n",
        "            targets = targets.to(device=device)\n",
        "\n",
        "            scores = model(data)\n",
        "            test_loss += criterion(scores, targets).item()\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == targets).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "            test_idx += 1\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = float(num_correct) / num_samples\n",
        "\n",
        "    # Print progress\n",
        "    print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}, Test Acc: {:.2f}%'\n",
        "          .format(epoch+1, epochs, loss.item(), test_loss, test_acc*100))\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "# Save model\n",
        "best_model_path = 'best_model.pth'\n",
        "torch.save(model.state_dict(), best_model_path)\n",
        "print(f\"Best model saved to {best_model_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu9Xrbjq55Io",
        "outputId": "58bac2d5-e143-42e2-fb31-080fbe408f07",
        "collapsed": true
      },
      "id": "Uu9Xrbjq55Io",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.DS_Store', 'Amphibia', 'Animalia', 'Arachnida', 'Aves', 'Fungi', 'Insecta', 'Mammalia', 'Mollusca', 'Plantae', 'Reptilia']\n",
            "Feature Batch Shape: torch.Size([32, 3, 300, 300])\n",
            "Label Batch Shape: torch.Size([32])\n",
            "r 300\n",
            "r 149\n",
            "r 74\n",
            "r 37\n",
            "r 19\n",
            "ok pool5\n",
            "ok flatten\n",
            "10\n",
            "Epoch [1/1], Train Loss: 2.0832, Test Loss: 2.0389, Test Acc: 29.75%\n",
            "Best model saved to best_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#loading the best model and testing it on Test Data\n",
        "best_model_path = 'best_model.pth'\n",
        "vector = [i**2 for i in range(100)]\n",
        "loaded_model = CNN(3,10,16,[7,5,5,3,3],64,True,0.2,2,'Mish').to(device)\n",
        "loaded_model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "\n",
        "usum = sum(vector) * 0\n",
        "\n",
        "def calculate_accuracy(model, test_loader,criterion):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    cost=0\n",
        "    acc=0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        loader_iter = iter(test_loader)\n",
        "        batch_idx = 0\n",
        "\n",
        "\n",
        "        batch_tracker = []\n",
        "\n",
        "        while batch_idx < len(test_loader):\n",
        "            images, labels = next(loader_iter)\n",
        "\n",
        "\n",
        "            images = images * 1.0\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            cost +=criterion(outputs,labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "            temp_correct = (predicted == labels).sum().item()\n",
        "            correct += temp_correct\n",
        "\n",
        "\n",
        "            batch_tracker.append(batch_idx % 2)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            del images\n",
        "            del labels\n",
        "            batch_idx += 1\n",
        "\n",
        "\n",
        "    useless_norm = sum(batch_tracker) / (len(batch_tracker) + 1e-7)\n",
        "\n",
        "    acc=100 * correct / total\n",
        "    cost/=len(test_loader)\n",
        "\n",
        "    return cost,acc\n",
        "\n",
        "\n",
        "param_copy = [p.clone() for p in loaded_model.parameters()]\n",
        "\n",
        "loss,acc=calculate_accuracy(loaded_model,test_loader,nn.CrossEntropyLoss())\n",
        "\n",
        "\n",
        "debug_str = f\"Loss: {loss} Acc: {acc}\".upper()\n",
        "\n",
        "print(loss,acc)\n",
        "print(loaded_model.state_dict())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DlB9WFER0we3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5a486ccc-f4f4-41db-eeb6-186bc45fdd25"
      },
      "id": "DlB9WFER0we3",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r 300\n",
            "r 149\n",
            "r 74\n",
            "r 37\n",
            "r 19\n",
            "ok pool5\n",
            "ok flatten\n",
            "10\n",
            "2.0388649683150035 29.75\n",
            "OrderedDict([('conv1.weight', tensor([[[[-5.5315e-02,  2.6983e-02, -4.2673e-02,  ..., -2.5052e-02,\n",
            "           -7.4745e-02, -2.7763e-02],\n",
            "          [ 4.8598e-02, -4.0796e-02, -6.1642e-02,  ...,  7.8550e-02,\n",
            "           -6.0141e-02, -6.9573e-02],\n",
            "          [ 6.8147e-02,  1.5280e-02, -4.2340e-02,  ..., -4.5064e-02,\n",
            "            6.0530e-02, -8.1416e-02],\n",
            "          ...,\n",
            "          [ 7.0534e-02, -4.9019e-02, -5.5269e-02,  ...,  1.6549e-02,\n",
            "            5.2512e-02, -5.9983e-02],\n",
            "          [-1.0482e-02,  6.8953e-02,  7.0372e-02,  ...,  6.1883e-02,\n",
            "            1.6442e-03, -5.0746e-03],\n",
            "          [-3.0506e-02,  4.6013e-02, -3.8992e-02,  ..., -6.9848e-02,\n",
            "            4.0390e-02, -1.7855e-02]],\n",
            "\n",
            "         [[-1.0505e-02,  3.0570e-02, -2.6276e-02,  ...,  1.9953e-02,\n",
            "            5.0155e-02,  3.8035e-02],\n",
            "          [ 8.0592e-03, -1.3086e-02, -5.1977e-02,  ..., -1.2907e-02,\n",
            "           -4.1201e-03,  4.8118e-02],\n",
            "          [-2.1626e-02,  5.3829e-02,  7.7541e-02,  ..., -1.6121e-02,\n",
            "            4.3983e-02, -4.3480e-02],\n",
            "          ...,\n",
            "          [ 1.0549e-02, -1.6277e-02,  3.6828e-02,  ..., -2.4889e-02,\n",
            "            7.5887e-02, -8.0273e-02],\n",
            "          [-1.0483e-02, -5.8483e-02, -4.8991e-02,  ...,  5.7943e-02,\n",
            "            7.4641e-02, -8.2186e-02],\n",
            "          [ 6.3133e-02,  5.4475e-02, -5.5478e-02,  ...,  7.8781e-02,\n",
            "           -2.1510e-02, -5.5600e-03]],\n",
            "\n",
            "         [[-6.8836e-03, -7.9176e-02, -7.4567e-02,  ..., -3.1976e-02,\n",
            "            8.3527e-03, -5.7350e-02],\n",
            "          [ 2.0816e-02, -5.0343e-02,  6.3547e-02,  ...,  3.9570e-02,\n",
            "            1.5706e-02, -1.4584e-02],\n",
            "          [ 7.5750e-02, -5.4459e-02,  3.7961e-02,  ...,  4.7485e-02,\n",
            "            3.6975e-02, -7.8335e-02],\n",
            "          ...,\n",
            "          [ 3.8111e-02, -4.1764e-02,  2.2044e-02,  ..., -2.4850e-02,\n",
            "            6.3562e-02,  6.3588e-02],\n",
            "          [-5.7076e-02, -5.4625e-02,  6.4393e-02,  ..., -1.9482e-02,\n",
            "            5.4650e-02,  1.9208e-02],\n",
            "          [-3.5423e-02,  6.4216e-02, -1.4715e-02,  ..., -2.5428e-02,\n",
            "            3.4819e-02, -1.3539e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 5.5407e-02, -3.8857e-03,  8.0071e-02,  ...,  6.5598e-02,\n",
            "            1.2723e-02,  4.4676e-02],\n",
            "          [ 6.7106e-02,  3.3684e-02, -6.6782e-02,  ...,  6.5259e-02,\n",
            "           -6.7933e-02,  6.2275e-02],\n",
            "          [ 1.9896e-02, -7.0717e-02,  2.0179e-02,  ...,  2.3182e-02,\n",
            "           -8.4682e-02, -2.8549e-02],\n",
            "          ...,\n",
            "          [ 5.4247e-02,  4.9907e-02,  3.5547e-03,  ...,  7.3986e-02,\n",
            "            1.2020e-02,  7.0315e-02],\n",
            "          [-6.3646e-02, -8.2266e-02,  7.9313e-02,  ..., -5.0893e-02,\n",
            "           -7.1868e-02, -5.2813e-03],\n",
            "          [-5.3362e-02, -4.7822e-02, -6.5799e-02,  ..., -5.1175e-02,\n",
            "            7.7244e-02, -4.1093e-02]],\n",
            "\n",
            "         [[ 6.6104e-02, -2.7474e-02, -4.5359e-02,  ...,  6.3856e-02,\n",
            "            6.4729e-02,  1.4793e-02],\n",
            "          [ 4.0187e-02,  7.0800e-02, -7.2562e-02,  ..., -2.6730e-02,\n",
            "           -5.5908e-02,  5.3704e-02],\n",
            "          [-7.0816e-02,  1.9527e-03,  1.9535e-02,  ..., -4.6504e-02,\n",
            "           -1.0206e-02, -6.6179e-03],\n",
            "          ...,\n",
            "          [-5.7386e-02, -1.5500e-03, -2.0696e-02,  ...,  4.7491e-02,\n",
            "            6.1716e-02,  3.0522e-02],\n",
            "          [ 2.6855e-03, -1.6601e-02,  5.6768e-02,  ...,  2.6875e-02,\n",
            "           -6.4606e-02, -6.9198e-02],\n",
            "          [-2.3994e-02,  3.5813e-02, -4.6391e-02,  ...,  6.9597e-02,\n",
            "           -7.7198e-02,  2.7561e-02]],\n",
            "\n",
            "         [[-2.4892e-02, -7.9094e-02, -1.6673e-02,  ..., -7.0027e-02,\n",
            "           -5.7512e-02,  6.3809e-03],\n",
            "          [-6.9006e-02,  2.3935e-02,  2.4702e-02,  ...,  4.6661e-02,\n",
            "           -5.1339e-02, -4.1050e-02],\n",
            "          [ 6.7598e-02, -6.0623e-02,  6.5045e-02,  ...,  1.7872e-03,\n",
            "            2.2786e-02,  2.9894e-02],\n",
            "          ...,\n",
            "          [-7.8315e-02,  2.7953e-02,  2.8013e-02,  ...,  6.6278e-02,\n",
            "            2.4161e-02,  7.0342e-02],\n",
            "          [-7.1761e-02,  3.0914e-02,  1.4270e-02,  ...,  4.7619e-02,\n",
            "           -3.0885e-02,  4.2356e-03],\n",
            "          [-2.8126e-02,  3.9999e-02, -1.0324e-02,  ..., -3.1766e-02,\n",
            "           -9.1568e-03,  5.7910e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0327e-02,  9.9707e-03,  6.5954e-02,  ...,  6.5117e-02,\n",
            "            6.8852e-02, -2.2981e-02],\n",
            "          [ 8.4974e-02,  3.4817e-02,  6.4793e-02,  ...,  3.7530e-03,\n",
            "           -7.8572e-02,  1.7717e-02],\n",
            "          [-4.4696e-03, -5.8618e-02, -7.9904e-02,  ..., -2.0855e-02,\n",
            "            5.1764e-02, -2.3394e-02],\n",
            "          ...,\n",
            "          [ 8.2376e-02,  7.6627e-02,  8.7798e-03,  ...,  6.4209e-02,\n",
            "            5.3900e-02,  6.5190e-02],\n",
            "          [ 6.4810e-02,  4.9984e-02,  1.7004e-02,  ..., -2.4074e-02,\n",
            "           -5.2754e-02,  2.8270e-02],\n",
            "          [ 7.3832e-03,  5.2660e-02,  3.0212e-02,  ...,  4.7828e-02,\n",
            "           -7.9865e-02, -3.2265e-02]],\n",
            "\n",
            "         [[ 6.3942e-02,  3.4267e-02, -5.5165e-02,  ..., -6.5753e-02,\n",
            "            1.8285e-02,  5.4686e-02],\n",
            "          [ 7.3215e-02,  4.8475e-02,  5.2941e-03,  ...,  2.7090e-02,\n",
            "            1.0439e-02, -2.8909e-02],\n",
            "          [-7.5008e-02,  3.1598e-02, -7.3206e-02,  ...,  6.1266e-02,\n",
            "           -8.6829e-03,  2.1659e-02],\n",
            "          ...,\n",
            "          [ 8.2379e-02, -1.5042e-02, -7.0201e-03,  ...,  1.9959e-02,\n",
            "            7.1955e-02, -4.2861e-02],\n",
            "          [ 3.7120e-02,  2.9879e-02, -7.5089e-02,  ...,  3.3711e-02,\n",
            "            3.5308e-02,  3.8809e-03],\n",
            "          [-1.3858e-02, -4.7126e-02,  3.4919e-02,  ...,  1.2196e-02,\n",
            "            2.8490e-02, -6.5321e-02]],\n",
            "\n",
            "         [[-7.3274e-02,  1.2710e-02, -1.2269e-02,  ...,  3.4261e-02,\n",
            "            6.0929e-03, -6.0498e-02],\n",
            "          [-6.4407e-02,  1.1864e-02,  2.2170e-02,  ...,  5.0960e-02,\n",
            "            3.6777e-02, -4.1058e-02],\n",
            "          [-7.5446e-02, -1.7230e-03, -6.9568e-02,  ...,  6.1274e-02,\n",
            "            6.9838e-02,  4.3961e-02],\n",
            "          ...,\n",
            "          [-7.4763e-02,  5.4885e-02,  7.6517e-02,  ...,  7.5517e-02,\n",
            "            4.9028e-02, -1.6217e-02],\n",
            "          [-2.3008e-02, -1.6932e-02, -4.2506e-02,  ...,  4.8923e-03,\n",
            "            5.7472e-02,  2.7957e-02],\n",
            "          [ 1.0777e-02,  3.9421e-02,  8.0441e-02,  ...,  5.6877e-02,\n",
            "            5.3198e-02, -2.4358e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 6.2977e-02, -3.7212e-02, -3.4267e-02,  ...,  2.5308e-02,\n",
            "            1.6979e-02, -4.6344e-02],\n",
            "          [-4.2974e-02, -6.7764e-02,  3.5238e-02,  ...,  1.8863e-02,\n",
            "           -4.8505e-02,  7.0773e-02],\n",
            "          [ 5.2144e-02, -5.8854e-02, -1.1080e-03,  ..., -8.0759e-02,\n",
            "           -3.4927e-02,  5.7154e-02],\n",
            "          ...,\n",
            "          [-5.8020e-02,  4.6639e-04,  6.2459e-03,  ..., -4.7857e-02,\n",
            "           -8.5180e-03,  5.2238e-02],\n",
            "          [ 5.9758e-02,  5.8874e-02,  1.0726e-02,  ..., -3.2088e-03,\n",
            "           -3.1717e-02,  7.4994e-02],\n",
            "          [-3.6599e-02,  5.2788e-02,  6.2625e-02,  ...,  4.7636e-02,\n",
            "           -6.1664e-02,  3.9646e-02]],\n",
            "\n",
            "         [[-7.0679e-02, -3.5665e-02, -6.0907e-02,  ...,  7.9192e-02,\n",
            "           -6.2718e-02, -3.0402e-02],\n",
            "          [ 7.1890e-02, -3.3650e-02, -1.3145e-02,  ..., -5.3037e-03,\n",
            "           -1.9861e-02,  1.9616e-02],\n",
            "          [-1.8972e-02,  6.2607e-02,  6.9429e-02,  ...,  8.0360e-02,\n",
            "            5.0966e-02, -4.5113e-02],\n",
            "          ...,\n",
            "          [-3.6813e-02, -1.8574e-02,  3.0793e-02,  ...,  2.9388e-02,\n",
            "           -5.9532e-02,  3.2096e-02],\n",
            "          [ 5.0017e-02,  2.9597e-03, -5.7733e-02,  ..., -1.4177e-02,\n",
            "           -1.8583e-02,  5.3051e-02],\n",
            "          [ 3.6816e-02,  7.9215e-02, -1.3334e-02,  ..., -4.7608e-02,\n",
            "           -3.9350e-03, -1.2966e-02]],\n",
            "\n",
            "         [[ 6.4399e-02, -6.5129e-02,  5.4998e-02,  ..., -5.6173e-02,\n",
            "            1.6611e-02,  4.5895e-02],\n",
            "          [ 3.8341e-02,  3.5128e-02,  3.5302e-03,  ..., -7.0932e-02,\n",
            "           -3.1774e-02,  5.1821e-03],\n",
            "          [-6.8216e-02,  3.9849e-02, -7.4875e-02,  ...,  4.8753e-02,\n",
            "            6.0729e-02, -6.3770e-02],\n",
            "          ...,\n",
            "          [-2.8366e-02, -5.1241e-02,  4.4608e-02,  ...,  7.0788e-02,\n",
            "           -8.3509e-03, -4.5574e-02],\n",
            "          [ 3.5429e-02, -2.6804e-02,  3.4225e-02,  ...,  4.1146e-02,\n",
            "           -5.5370e-02, -2.4133e-02],\n",
            "          [-6.1187e-02, -8.2853e-02, -3.6748e-02,  ..., -4.9215e-02,\n",
            "            6.5344e-02, -9.1307e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 7.3229e-03, -8.3683e-02,  1.0412e-02,  ..., -1.5038e-02,\n",
            "           -9.5529e-03,  4.3473e-03],\n",
            "          [-2.1070e-02, -7.8909e-02, -6.3955e-02,  ..., -8.3298e-02,\n",
            "            1.6071e-03,  5.5212e-02],\n",
            "          [-3.7671e-03,  6.7759e-02,  5.6502e-02,  ..., -6.0628e-02,\n",
            "            7.6086e-02, -9.0316e-03],\n",
            "          ...,\n",
            "          [-8.4337e-02,  6.2431e-02, -7.3931e-02,  ...,  1.0638e-02,\n",
            "           -1.1698e-02, -6.5758e-02],\n",
            "          [ 5.6215e-02,  4.2411e-02,  1.0967e-02,  ...,  6.0343e-02,\n",
            "           -1.9140e-02, -2.4495e-02],\n",
            "          [-2.7012e-02,  7.9558e-02,  6.9513e-03,  ...,  4.9437e-02,\n",
            "            7.4272e-02,  6.3497e-02]],\n",
            "\n",
            "         [[ 2.9368e-02,  3.2607e-02, -1.5525e-02,  ...,  6.2217e-02,\n",
            "            5.5893e-02,  4.8792e-02],\n",
            "          [-3.7145e-02, -4.3534e-02, -6.0746e-02,  ..., -4.2449e-03,\n",
            "           -4.4292e-02,  3.2049e-02],\n",
            "          [ 5.1854e-02,  1.5633e-02, -3.5443e-02,  ...,  5.7575e-02,\n",
            "           -4.9480e-02,  7.2942e-02],\n",
            "          ...,\n",
            "          [-3.4078e-02,  2.4655e-02, -2.1477e-02,  ...,  1.3415e-02,\n",
            "            2.5803e-02, -2.1936e-02],\n",
            "          [ 4.2596e-02,  4.6542e-02, -7.1093e-02,  ..., -9.3528e-03,\n",
            "           -1.9464e-02,  6.9336e-02],\n",
            "          [ 3.9482e-02,  4.0234e-02,  7.5084e-02,  ...,  5.2164e-02,\n",
            "            4.2546e-02,  3.3695e-02]],\n",
            "\n",
            "         [[ 6.1266e-02, -2.2696e-02,  4.3340e-02,  ...,  4.6785e-03,\n",
            "            4.8710e-02,  6.1820e-02],\n",
            "          [-9.0156e-03,  1.0059e-02, -6.9548e-02,  ...,  1.2576e-03,\n",
            "           -7.5024e-02,  1.1375e-02],\n",
            "          [ 8.2322e-03, -2.0470e-02,  7.4020e-02,  ...,  4.3415e-02,\n",
            "            3.4201e-02,  7.3168e-02],\n",
            "          ...,\n",
            "          [-6.0547e-02,  7.3081e-02,  4.7228e-02,  ..., -2.9937e-02,\n",
            "           -1.3626e-02, -1.2190e-02],\n",
            "          [ 4.5548e-02, -5.9756e-02, -1.7009e-02,  ..., -6.5457e-02,\n",
            "           -4.1940e-02, -1.4170e-02],\n",
            "          [ 1.9511e-02,  2.3755e-02,  4.6904e-02,  ...,  5.2048e-02,\n",
            "           -8.1104e-03, -3.5621e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.4071e-02,  5.3428e-02, -5.4414e-02,  ...,  3.8818e-03,\n",
            "            3.4258e-02, -1.9543e-02],\n",
            "          [ 7.3945e-02, -6.2309e-02,  4.2596e-02,  ..., -3.1684e-02,\n",
            "           -5.1242e-02,  2.9874e-02],\n",
            "          [-1.4586e-02,  3.3221e-02, -3.6517e-02,  ...,  6.6960e-02,\n",
            "            2.3835e-02,  7.1368e-05],\n",
            "          ...,\n",
            "          [-8.0253e-02,  5.3134e-03,  6.7158e-02,  ...,  1.7928e-02,\n",
            "            7.2962e-02,  1.1334e-02],\n",
            "          [ 2.3875e-02, -4.7439e-02, -3.0342e-02,  ..., -6.3443e-02,\n",
            "           -5.8205e-02, -3.6042e-02],\n",
            "          [-3.0860e-02, -3.7734e-02,  8.1364e-02,  ..., -4.0423e-02,\n",
            "           -5.7609e-02, -6.7640e-02]],\n",
            "\n",
            "         [[ 9.4741e-03,  5.8805e-02,  6.3521e-02,  ..., -1.8851e-02,\n",
            "            1.6711e-02,  1.8672e-02],\n",
            "          [ 7.1811e-03,  4.7430e-03, -2.8076e-02,  ...,  2.0053e-02,\n",
            "           -6.2996e-02, -2.5958e-02],\n",
            "          [-4.2043e-02,  1.2912e-02,  3.9566e-02,  ...,  4.5344e-02,\n",
            "            6.6438e-02, -3.0764e-03],\n",
            "          ...,\n",
            "          [-6.2211e-02, -4.1287e-02, -2.5199e-03,  ...,  2.7426e-02,\n",
            "           -5.3272e-02, -1.8908e-02],\n",
            "          [ 4.1131e-02, -3.3703e-02, -7.4517e-03,  ..., -2.5491e-02,\n",
            "            6.6455e-02,  1.2512e-02],\n",
            "          [ 8.9742e-03,  7.8133e-02, -2.5257e-02,  ..., -5.6572e-02,\n",
            "           -1.9385e-03,  3.7274e-02]],\n",
            "\n",
            "         [[-2.0688e-02, -1.0339e-04,  5.4617e-02,  ...,  7.0541e-02,\n",
            "           -7.9360e-02, -6.2167e-02],\n",
            "          [-3.8773e-02,  5.3656e-02, -4.5136e-02,  ..., -5.2231e-02,\n",
            "           -3.1646e-02, -4.5405e-02],\n",
            "          [-4.1663e-02,  4.1115e-02, -5.2808e-02,  ..., -3.0544e-02,\n",
            "           -3.5431e-02, -4.0857e-02],\n",
            "          ...,\n",
            "          [-1.2187e-02, -2.6923e-02,  4.9450e-02,  ..., -6.6232e-02,\n",
            "           -1.4513e-02, -2.4251e-02],\n",
            "          [ 1.1425e-03,  5.3962e-02,  7.5328e-02,  ...,  5.5276e-02,\n",
            "           -7.0795e-03,  6.7023e-02],\n",
            "          [-2.8674e-02, -8.0720e-03, -4.2383e-02,  ...,  2.7979e-02,\n",
            "            5.2005e-02, -7.5960e-02]]]])), ('conv1.bias', tensor([ 0.0033, -0.0687, -0.0097, -0.0766,  0.0084,  0.0082,  0.0571, -0.0077,\n",
            "        -0.0181,  0.0716, -0.0526, -0.0452,  0.0255, -0.0522,  0.0677, -0.0542])), ('bn1.weight', tensor([0.9999, 1.0016, 1.0005, 0.9990, 0.9987, 1.0010, 0.9974, 1.0024, 0.9982,\n",
            "        0.9983, 0.9997, 0.9993, 0.9963, 0.9998, 0.9983, 1.0039])), ('bn1.bias', tensor([-0.0015,  0.0053,  0.0020,  0.0014, -0.0018,  0.0028,  0.0003, -0.0008,\n",
            "        -0.0005, -0.0012, -0.0026, -0.0008, -0.0014,  0.0026,  0.0014,  0.0016])), ('bn1.running_mean', tensor([-0.0136, -0.0660, -0.1001, -0.1533,  0.0056,  0.0404,  0.0365,  0.0640,\n",
            "         0.0063, -0.0560, -0.0574, -0.0153, -0.0785, -0.0393, -0.0719, -0.0173])), ('bn1.running_var', tensor([0.0277, 0.0056, 0.2787, 0.0524, 0.0145, 0.0125, 0.0458, 0.0485, 0.0501,\n",
            "        0.1895, 0.0859, 0.0239, 0.1298, 0.0104, 0.3016, 0.0132])), ('bn1.num_batches_tracked', tensor(250)), ('conv2.weight', tensor([[[[ 2.6841e-02, -1.1965e-02,  1.6331e-02, -3.9960e-02, -1.9634e-03],\n",
            "          [ 2.2104e-02,  3.2698e-03,  4.3962e-02, -3.3625e-03, -4.3074e-02],\n",
            "          [ 9.5362e-03, -4.4249e-02,  4.6238e-03,  4.2899e-02, -3.9926e-03],\n",
            "          [ 4.0265e-02, -3.0212e-02, -3.2275e-02,  2.5013e-02,  1.6213e-02],\n",
            "          [-4.1128e-02, -1.0679e-02, -4.2626e-02, -4.8420e-02,  2.5464e-03]],\n",
            "\n",
            "         [[ 2.0252e-02, -2.5688e-03,  3.1083e-02,  1.8217e-02,  3.7702e-02],\n",
            "          [ 2.7310e-02, -4.4949e-02,  8.4453e-03,  3.2869e-03, -5.0265e-02],\n",
            "          [-1.7135e-02,  4.0156e-02,  3.6442e-02, -4.2293e-02, -4.6107e-02],\n",
            "          [ 2.9714e-02,  2.9135e-02,  1.1774e-02, -1.5802e-02, -5.9762e-03],\n",
            "          [-7.6298e-03,  2.2026e-02, -8.9541e-03,  7.7718e-03,  2.0139e-03]],\n",
            "\n",
            "         [[ 2.2554e-02,  2.2042e-02, -3.8454e-02,  3.8825e-02,  1.7109e-02],\n",
            "          [ 4.4228e-03, -2.0721e-02, -2.1203e-02,  2.5600e-02,  3.4614e-02],\n",
            "          [-3.8512e-02,  2.3002e-03, -1.1712e-02,  3.5877e-02,  4.1779e-02],\n",
            "          [ 2.2493e-02,  3.9663e-02,  7.4657e-03,  9.7376e-03,  1.4365e-02],\n",
            "          [-4.0683e-02, -4.4569e-02, -6.7198e-03, -4.2017e-02, -3.9929e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.2669e-02, -4.3500e-02, -3.8997e-02,  6.0671e-03,  4.2495e-02],\n",
            "          [ 4.0710e-02,  1.2008e-03, -4.0363e-02,  1.3812e-02, -3.5287e-02],\n",
            "          [ 3.3526e-02,  5.6529e-03, -2.1879e-02,  3.8064e-02,  2.4826e-02],\n",
            "          [-3.1782e-02, -1.7556e-03,  3.4047e-02,  3.5937e-02, -3.6605e-02],\n",
            "          [ 4.5171e-02,  4.9568e-02,  2.9055e-02, -1.8659e-02, -1.8888e-02]],\n",
            "\n",
            "         [[-2.6991e-03,  3.5774e-03,  1.5357e-02, -3.6392e-02,  4.4017e-02],\n",
            "          [ 3.7555e-02, -2.2664e-02,  3.8412e-03, -4.5407e-02,  2.2587e-02],\n",
            "          [-2.8589e-02, -4.2940e-02,  3.8286e-02, -2.2751e-02,  6.2923e-03],\n",
            "          [ 1.1153e-02, -2.4227e-02,  2.4088e-02,  2.7987e-02, -2.4404e-02],\n",
            "          [-9.8873e-03, -3.5637e-02,  2.6218e-02,  8.7148e-03, -1.2563e-02]],\n",
            "\n",
            "         [[ 3.1826e-02,  2.6273e-02, -3.5478e-02, -1.2812e-02,  4.0241e-02],\n",
            "          [-1.7485e-02, -1.3302e-02, -2.2629e-02,  1.1113e-02,  4.2562e-02],\n",
            "          [-8.1104e-03, -4.0409e-02,  3.3743e-02,  6.5433e-03, -6.9079e-03],\n",
            "          [ 4.3208e-02, -3.1657e-02, -2.8471e-03, -4.5951e-02,  1.6709e-02],\n",
            "          [-1.3848e-02, -2.3312e-02, -4.3109e-02, -4.8377e-03, -2.5344e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.6579e-02,  3.3455e-02,  3.5116e-02, -1.1656e-03,  4.9283e-02],\n",
            "          [-9.6998e-03, -8.8081e-03, -3.0827e-02,  4.7131e-02, -4.7163e-02],\n",
            "          [-3.1386e-02,  5.0024e-02,  3.0815e-02,  3.0038e-02, -2.6231e-02],\n",
            "          [ 5.5156e-03,  3.4262e-02, -2.3141e-02, -4.4115e-02, -3.4712e-02],\n",
            "          [-2.0100e-03, -3.9753e-02,  3.5214e-02, -6.1584e-03,  4.0042e-02]],\n",
            "\n",
            "         [[ 1.6655e-02, -5.0353e-02,  1.0200e-02, -1.4195e-02, -2.2613e-02],\n",
            "          [ 1.2225e-02,  1.8592e-02, -1.2051e-02, -1.0295e-02,  2.5598e-02],\n",
            "          [ 3.0319e-03, -3.8792e-02,  2.2362e-03, -3.7040e-02,  3.5996e-02],\n",
            "          [-3.9344e-02,  1.6293e-02, -4.9779e-02, -5.0535e-02, -4.9471e-02],\n",
            "          [-3.3113e-03, -4.1028e-02,  1.0441e-02, -1.0565e-02, -3.9454e-02]],\n",
            "\n",
            "         [[-3.0172e-04,  2.1927e-03, -8.2800e-04,  2.1171e-02, -1.5568e-03],\n",
            "          [-3.2369e-02, -3.0765e-02,  2.8449e-02, -4.8840e-02, -1.8328e-03],\n",
            "          [ 2.5004e-02,  3.4691e-02,  9.6788e-03,  1.9526e-02, -2.6511e-02],\n",
            "          [ 3.2151e-02, -1.0633e-02, -2.8323e-02, -1.1654e-02,  3.9089e-04],\n",
            "          [ 4.6165e-02, -4.7732e-02,  1.1905e-02,  4.0052e-03,  4.6962e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1130e-02,  2.2226e-02,  4.6558e-02, -2.6564e-02, -4.7871e-02],\n",
            "          [ 2.7320e-02,  1.4498e-02, -1.7385e-02, -4.4708e-02,  2.7690e-02],\n",
            "          [ 3.7637e-02, -1.9244e-02,  3.1339e-02, -4.9647e-02,  4.6372e-02],\n",
            "          [-8.4624e-03, -3.5290e-02,  1.4488e-02, -2.3631e-02, -1.1844e-02],\n",
            "          [ 2.0499e-02, -3.7073e-02, -1.8368e-02, -2.5613e-02,  3.3090e-02]],\n",
            "\n",
            "         [[-1.0450e-02, -1.1668e-02,  1.2345e-02,  3.9040e-02,  4.4862e-02],\n",
            "          [-1.4741e-02, -9.9328e-03, -2.4143e-02,  4.5463e-02,  4.2079e-02],\n",
            "          [ 1.6907e-02,  3.3570e-02,  4.5416e-02,  2.9859e-02,  1.6483e-02],\n",
            "          [ 3.0815e-02, -2.4571e-02, -3.7292e-02,  1.1266e-02, -3.8048e-02],\n",
            "          [-3.6776e-02,  2.8527e-02,  4.0280e-02, -4.9986e-04,  4.4085e-02]],\n",
            "\n",
            "         [[-1.8132e-02,  2.7852e-02, -1.9338e-02,  2.5199e-02, -9.1969e-03],\n",
            "          [ 4.5679e-02,  3.4714e-02, -4.2689e-02, -3.7155e-04, -4.2720e-02],\n",
            "          [-3.7550e-02, -4.8289e-02,  5.0512e-03,  2.9652e-02,  1.0515e-02],\n",
            "          [-4.4952e-02,  1.0433e-02,  4.9984e-02, -2.6942e-02, -3.9864e-02],\n",
            "          [-1.0514e-02, -4.2240e-02,  4.9801e-02,  3.2508e-02,  4.4456e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.6705e-02, -4.1243e-02, -2.2901e-02, -3.0256e-02,  3.3162e-02],\n",
            "          [ 3.5307e-03, -1.3980e-02, -3.6945e-02,  2.1826e-02, -4.7883e-02],\n",
            "          [-4.3842e-02, -2.9407e-02, -6.8226e-03, -3.6659e-02, -1.1611e-02],\n",
            "          [ 4.1970e-02, -1.4281e-02,  3.7396e-02,  7.4867e-03,  4.1839e-02],\n",
            "          [-2.3127e-02, -9.0496e-03, -1.6788e-02, -4.8267e-03, -2.4684e-02]],\n",
            "\n",
            "         [[-2.6801e-02, -9.7562e-03, -4.8113e-02,  4.0486e-03,  1.2221e-02],\n",
            "          [-3.0425e-02, -5.1173e-04, -1.8697e-02,  2.4720e-02, -3.1383e-02],\n",
            "          [ 3.1371e-02,  3.1473e-02,  6.2527e-05,  4.0230e-02, -3.1825e-02],\n",
            "          [ 1.3770e-02, -2.9360e-02,  1.4474e-03, -3.8971e-02,  2.6348e-04],\n",
            "          [ 1.5401e-02, -3.2278e-02, -1.4881e-02, -3.9013e-03, -1.0254e-02]],\n",
            "\n",
            "         [[ 1.5723e-02, -8.4929e-03, -5.0542e-03,  4.4241e-02, -2.9564e-02],\n",
            "          [ 2.8867e-03,  1.4682e-02,  4.1006e-02,  2.5162e-02, -2.7927e-02],\n",
            "          [ 4.9667e-02, -8.6415e-03, -1.0465e-02,  1.5623e-03,  6.7764e-03],\n",
            "          [ 4.1740e-02,  3.6065e-02,  3.8091e-02,  4.7804e-02, -2.3732e-02],\n",
            "          [-4.5105e-02,  5.0257e-02,  5.6618e-03,  1.6477e-02,  3.2904e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3400e-02, -1.8692e-02, -3.3824e-02, -2.8721e-02, -1.6955e-02],\n",
            "          [-1.5450e-02,  3.0866e-02,  7.7148e-03, -4.1895e-02,  9.5563e-03],\n",
            "          [-2.6202e-02,  9.1389e-03,  1.5042e-02, -3.1513e-03,  5.5680e-03],\n",
            "          [ 3.4326e-02,  3.3116e-02,  3.7235e-02,  2.2145e-02, -2.4508e-03],\n",
            "          [-1.8949e-02,  3.7690e-02, -1.1733e-03, -4.2473e-02, -3.4299e-02]],\n",
            "\n",
            "         [[-3.7674e-02, -3.2898e-02, -2.8722e-03,  3.0509e-02,  2.9799e-02],\n",
            "          [-2.6958e-02,  2.8123e-02, -1.2495e-02, -1.4517e-02, -2.6644e-02],\n",
            "          [-3.6104e-02,  6.0822e-03, -4.6903e-02, -2.6751e-02,  1.5357e-02],\n",
            "          [ 1.8374e-02,  2.6258e-02,  4.1391e-02,  2.4369e-02, -2.2183e-02],\n",
            "          [-3.5986e-02, -3.8908e-02,  1.8873e-02, -1.9243e-02, -2.6964e-02]],\n",
            "\n",
            "         [[-9.3028e-03, -9.5561e-03, -1.6101e-02,  3.3970e-02,  1.9203e-02],\n",
            "          [ 3.4772e-02,  6.0525e-03,  8.7074e-04,  6.3280e-03, -9.2632e-03],\n",
            "          [ 3.3744e-02,  2.7958e-02,  4.2727e-02,  4.1613e-02,  3.7640e-02],\n",
            "          [ 1.2366e-02,  3.1990e-02, -9.0267e-03,  8.6420e-03,  4.5551e-02],\n",
            "          [ 1.3811e-02, -1.6153e-02, -3.2155e-02, -3.2020e-02, -1.1240e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.0498e-02, -2.9223e-02,  1.8238e-02,  1.5273e-02,  3.4105e-02],\n",
            "          [-3.8778e-02,  2.6533e-02, -2.9433e-02,  2.9545e-02, -4.0880e-02],\n",
            "          [-2.5231e-02, -1.8753e-02, -7.3267e-03,  4.6676e-02,  2.0627e-02],\n",
            "          [ 2.9530e-02,  2.9115e-02,  3.9021e-02,  2.0280e-02, -2.0706e-03],\n",
            "          [-2.1665e-03,  1.8395e-02,  2.8570e-02, -3.6928e-02,  2.1882e-02]],\n",
            "\n",
            "         [[-2.6324e-02,  2.2538e-02, -8.2788e-03, -3.1249e-02,  1.4114e-02],\n",
            "          [ 3.4755e-02,  4.9373e-02,  4.3212e-02, -1.8501e-03, -3.4804e-02],\n",
            "          [ 1.2489e-02,  3.4796e-02,  4.1047e-02,  2.7055e-02, -2.9067e-02],\n",
            "          [-3.9363e-02, -1.3078e-02, -4.1863e-02,  3.0070e-02,  2.4050e-02],\n",
            "          [ 1.0169e-02,  4.0008e-02, -2.7634e-02,  3.6973e-03,  1.3761e-02]],\n",
            "\n",
            "         [[ 6.9326e-03,  2.0621e-02,  1.0430e-02, -7.5938e-03, -9.6531e-03],\n",
            "          [ 1.3881e-02,  2.7373e-02,  7.5782e-03, -3.0486e-02, -1.6655e-02],\n",
            "          [ 1.5780e-02, -1.7226e-02,  1.7124e-02,  4.6174e-02,  2.9496e-02],\n",
            "          [ 1.1937e-02, -4.4188e-02,  2.0450e-03, -5.5147e-03,  4.7071e-02],\n",
            "          [-4.1416e-03, -3.7910e-02, -2.5378e-03,  2.1799e-02, -6.9575e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3968e-02, -2.9069e-02,  1.0653e-03, -3.1121e-02,  1.6208e-02],\n",
            "          [-4.3785e-02,  3.5288e-02,  4.7425e-02, -4.3007e-02, -5.8273e-03],\n",
            "          [ 2.6723e-02, -3.8887e-02,  4.5249e-02,  1.6051e-02,  1.7307e-02],\n",
            "          [ 2.9087e-02,  1.2059e-02, -1.2338e-02,  1.7886e-02,  4.0835e-02],\n",
            "          [ 2.4683e-02,  1.2311e-04, -2.9863e-04, -1.8950e-02, -4.3733e-02]],\n",
            "\n",
            "         [[-2.2735e-02,  1.3901e-02,  1.7428e-03,  9.6441e-03, -1.9421e-02],\n",
            "          [ 4.5886e-02, -4.6395e-02,  6.8496e-03, -3.2219e-02,  1.4121e-03],\n",
            "          [-3.4737e-03,  6.0508e-03,  4.0232e-02,  2.0803e-02,  1.6747e-02],\n",
            "          [ 4.5060e-02, -7.1159e-03, -2.6442e-02, -3.1189e-02,  3.5742e-02],\n",
            "          [-1.0708e-02, -4.4203e-02, -4.3354e-02,  2.6867e-02, -3.6257e-02]],\n",
            "\n",
            "         [[-2.2583e-02, -4.2701e-02, -1.1070e-03,  2.9842e-03, -3.8223e-02],\n",
            "          [-4.9998e-02, -4.2664e-02, -3.4859e-02,  4.0351e-02,  4.1305e-02],\n",
            "          [-2.6929e-02,  2.2171e-02,  4.5854e-02,  1.1588e-02,  3.0429e-02],\n",
            "          [-1.0628e-03, -1.1457e-02,  2.1676e-02, -5.0659e-02, -4.9338e-02],\n",
            "          [-5.0118e-02,  3.3940e-02, -1.2153e-02, -2.4824e-02,  1.7781e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.1150e-03, -4.1757e-04, -1.2904e-02, -3.5066e-02, -7.1444e-03],\n",
            "          [-3.9537e-02,  2.1955e-02,  2.5354e-02,  4.9197e-02,  2.7997e-02],\n",
            "          [-9.1402e-03,  2.6905e-02, -4.3837e-02,  3.8670e-02, -1.5448e-02],\n",
            "          [ 3.1052e-03, -2.4981e-02,  2.5422e-02,  4.6080e-02,  3.2768e-02],\n",
            "          [-2.4113e-03,  2.3339e-02,  4.1244e-02,  1.6335e-02, -2.7046e-02]],\n",
            "\n",
            "         [[-1.9260e-02,  2.7577e-02, -2.6474e-02, -2.4341e-02, -2.5451e-02],\n",
            "          [ 4.1575e-02,  3.3910e-02,  3.9340e-02,  3.8063e-02,  2.8918e-02],\n",
            "          [ 1.2042e-02,  3.4706e-02,  4.4445e-02,  9.9368e-03, -5.6179e-03],\n",
            "          [-3.8148e-02,  4.9724e-02,  6.5795e-04,  1.0264e-02, -4.5902e-02],\n",
            "          [ 4.4173e-02, -1.0954e-02,  4.9960e-02,  3.0698e-03, -2.2633e-02]],\n",
            "\n",
            "         [[-5.0471e-02, -4.9302e-02,  2.4836e-02, -2.2679e-02,  4.4855e-02],\n",
            "          [ 3.4741e-02,  4.1175e-03, -1.2863e-02, -2.8791e-02,  1.7878e-02],\n",
            "          [ 7.4031e-03,  1.3361e-02,  4.5943e-04, -1.0230e-02, -5.0387e-02],\n",
            "          [ 2.7580e-02,  3.2504e-02,  6.7163e-03, -2.0735e-02,  1.5121e-02],\n",
            "          [ 1.8617e-02, -2.9603e-02, -2.2367e-02, -4.4123e-02, -2.2892e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.1534e-03, -2.0250e-02, -3.4376e-02,  1.0294e-04, -3.3366e-02],\n",
            "          [-3.7505e-02, -1.4106e-03,  3.7972e-02, -1.2093e-02, -2.4955e-02],\n",
            "          [-4.3466e-02,  2.1301e-02,  2.3862e-02, -1.8323e-02,  9.8567e-03],\n",
            "          [ 1.8426e-02,  4.2717e-02, -2.2962e-02, -2.1099e-02, -3.0871e-02],\n",
            "          [ 4.7990e-02, -3.4199e-02, -2.7654e-02,  3.6397e-02, -3.8930e-02]],\n",
            "\n",
            "         [[ 3.5660e-02,  1.2311e-04, -3.0162e-02, -1.4798e-02,  2.7074e-03],\n",
            "          [-4.3738e-02,  4.6846e-02, -6.2771e-03, -5.0165e-02,  2.1669e-02],\n",
            "          [ 7.1879e-03, -1.1358e-02,  3.0046e-02, -3.8138e-02,  1.9414e-02],\n",
            "          [-1.7393e-02, -3.2197e-02,  1.4524e-02, -3.6280e-02,  3.7552e-02],\n",
            "          [-3.4333e-02, -2.0277e-02,  1.0651e-02,  2.2259e-02, -2.7152e-02]],\n",
            "\n",
            "         [[-4.0994e-02,  4.7866e-02, -3.8046e-02, -2.2797e-02,  1.7654e-02],\n",
            "          [-3.5073e-02, -7.6469e-03,  3.6977e-02,  3.6442e-02,  3.2353e-02],\n",
            "          [ 3.3162e-02, -2.3725e-02, -3.9973e-03, -9.9644e-03, -8.5166e-03],\n",
            "          [-4.7132e-03,  2.4948e-02, -4.4627e-02, -2.9561e-02, -2.9509e-02],\n",
            "          [ 2.8419e-02, -1.3590e-02,  3.2489e-02,  3.9165e-03,  2.3100e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.8499e-02,  4.4711e-02, -4.1731e-02, -7.2793e-03,  1.9610e-02],\n",
            "          [-3.0349e-02, -1.3821e-02, -3.7764e-03, -3.0046e-02, -2.5418e-02],\n",
            "          [ 4.0702e-02,  4.0962e-02,  3.0063e-02, -4.2506e-02,  3.3169e-02],\n",
            "          [ 2.0976e-03, -2.3067e-02, -6.0604e-03, -3.9613e-02,  2.3391e-02],\n",
            "          [ 3.5481e-02, -2.6758e-02, -1.7700e-02, -4.0378e-02, -4.6084e-02]],\n",
            "\n",
            "         [[-5.3443e-03,  1.6676e-02, -2.5860e-02, -5.5936e-03, -1.3860e-02],\n",
            "          [-3.3416e-02,  4.6310e-02,  6.9067e-03,  1.2240e-02,  4.2344e-02],\n",
            "          [-3.1922e-02,  1.3514e-02, -3.8551e-02, -1.0423e-02,  3.8770e-02],\n",
            "          [ 8.7362e-03, -3.2895e-02,  2.6131e-02,  2.1510e-03, -3.4107e-02],\n",
            "          [ 7.8664e-03,  1.1701e-02, -2.3884e-02, -4.2754e-02, -2.3438e-03]],\n",
            "\n",
            "         [[-2.0404e-02, -2.9616e-02, -3.8887e-02, -3.5855e-02, -2.9624e-02],\n",
            "          [ 4.0057e-02,  2.7643e-02,  1.6687e-02, -4.1990e-02,  1.5979e-02],\n",
            "          [ 8.1462e-03,  9.9092e-03, -1.5404e-02,  2.9391e-02, -6.1486e-04],\n",
            "          [ 2.5341e-02,  4.4622e-02, -1.2823e-02, -3.2894e-03,  3.4381e-02],\n",
            "          [-3.2642e-03,  1.1099e-02, -3.3919e-02, -8.2956e-03,  3.2813e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1236e-02,  2.3109e-02, -1.0158e-02, -9.4464e-03, -1.7512e-02],\n",
            "          [ 1.8865e-02,  4.7842e-02, -1.7235e-02,  3.1329e-02, -4.3831e-02],\n",
            "          [-4.2473e-02,  1.3235e-03, -3.3885e-02, -2.8950e-02,  4.0267e-02],\n",
            "          [-5.3328e-03,  2.2585e-02,  1.6231e-02,  3.7284e-02,  3.1959e-02],\n",
            "          [ 3.4725e-02, -2.3685e-03,  2.9538e-02, -2.4532e-02, -3.8880e-02]],\n",
            "\n",
            "         [[ 3.2569e-02, -2.9571e-02,  3.1679e-02,  3.2234e-02,  3.0783e-02],\n",
            "          [-1.9793e-02,  3.0326e-02,  5.2623e-03, -2.7768e-02,  2.1647e-02],\n",
            "          [-2.4063e-02,  3.4302e-02,  3.4431e-02, -1.4910e-02,  1.4863e-02],\n",
            "          [-3.3341e-02, -4.8914e-02,  4.3203e-02,  3.8381e-02,  2.3270e-02],\n",
            "          [-9.4095e-03,  6.7044e-03,  7.8176e-03,  3.4108e-02, -2.5384e-02]],\n",
            "\n",
            "         [[ 2.6497e-02,  2.1089e-03, -2.6459e-02,  1.8095e-02,  2.3233e-02],\n",
            "          [ 4.0236e-02, -1.6928e-02,  4.1922e-02,  3.8182e-02, -8.7022e-03],\n",
            "          [ 3.1626e-02, -2.7990e-02,  2.7837e-02,  2.6236e-02, -2.7529e-02],\n",
            "          [-1.9090e-02, -5.8474e-03,  2.0628e-03, -9.4575e-04,  7.1410e-05],\n",
            "          [-4.4400e-02, -3.9145e-02, -4.7575e-02,  2.6885e-02, -4.9334e-02]]]])), ('conv2.bias', tensor([ 0.0040, -0.0233, -0.0131, -0.0031, -0.0275, -0.0356,  0.0113, -0.0001,\n",
            "         0.0343, -0.0080, -0.0245, -0.0179, -0.0366, -0.0080,  0.0240,  0.0066,\n",
            "        -0.0089, -0.0030, -0.0092,  0.0206, -0.0179, -0.0115, -0.0017, -0.0117,\n",
            "        -0.0013,  0.0275,  0.0058,  0.0218,  0.0086,  0.0299, -0.0179, -0.0228])), ('bn2.weight', tensor([0.9971, 0.9995, 0.9984, 0.9982, 0.9977, 0.9997, 0.9998, 0.9982, 1.0013,\n",
            "        0.9973, 0.9987, 0.9974, 1.0001, 0.9999, 1.0003, 0.9992, 0.9993, 0.9966,\n",
            "        0.9995, 0.9992, 1.0002, 0.9989, 0.9994, 0.9984, 1.0014, 0.9979, 1.0011,\n",
            "        1.0011, 1.0012, 1.0046, 1.0025, 0.9967])), ('bn2.bias', tensor([-2.5657e-03, -5.2767e-04, -2.5254e-04, -2.2179e-03,  2.9653e-03,\n",
            "        -2.2327e-03, -1.7663e-03,  1.4704e-03,  1.0336e-03, -2.2962e-03,\n",
            "         5.0887e-03, -8.6448e-04, -1.3079e-03,  2.1291e-03,  2.5809e-03,\n",
            "         1.1911e-03, -1.4564e-03,  5.2086e-05, -9.4134e-08, -1.5908e-03,\n",
            "         3.4968e-04,  7.0706e-04,  3.9620e-04, -1.5123e-03,  5.2036e-03,\n",
            "         8.8245e-04, -9.1043e-04,  1.6815e-05,  6.2195e-04,  2.8241e-03,\n",
            "         8.1379e-03,  7.7051e-04])), ('bn2.running_mean', tensor([ 0.5273, -0.2249,  0.0388,  0.4531, -0.0662, -0.2395, -0.0719, -0.2421,\n",
            "         0.4273, -0.3656,  0.0519, -0.0504, -0.1595,  0.4488,  0.2196,  0.5149,\n",
            "         0.4297,  0.1401,  0.6617,  0.0297, -0.2517,  0.2920,  0.2452,  0.0824,\n",
            "        -0.0477,  0.1279, -0.0653,  0.3921, -0.0902,  0.0098, -0.1746, -0.1905])), ('bn2.running_var', tensor([0.3617, 0.1147, 0.2518, 0.1261, 0.1032, 0.5672, 0.2276, 0.1433, 0.1557,\n",
            "        0.1781, 0.0494, 0.1753, 0.2334, 0.1152, 0.1244, 0.1893, 0.1530, 0.2438,\n",
            "        0.2821, 0.1369, 0.1772, 0.1026, 0.3583, 0.3949, 0.0892, 0.2363, 0.1014,\n",
            "        0.1733, 0.1152, 0.1451, 0.0976, 0.1553])), ('bn2.num_batches_tracked', tensor(250)), ('conv3.weight', tensor([[[[ 2.1159e-02, -3.0163e-02, -1.6495e-02, -3.2075e-02, -5.6473e-03],\n",
            "          [ 1.1639e-02, -3.2643e-03,  2.5383e-02, -2.8775e-03,  4.7422e-03],\n",
            "          [ 1.8829e-02, -1.0092e-02, -3.3887e-02, -1.5611e-02,  1.4271e-02],\n",
            "          [ 3.5087e-02, -9.7960e-03, -2.4227e-02, -1.4474e-02, -3.0876e-02],\n",
            "          [-2.4401e-02,  2.0812e-02, -1.9765e-02,  1.0535e-02,  1.5601e-02]],\n",
            "\n",
            "         [[-2.8535e-02,  3.3174e-02,  2.0203e-02,  2.4461e-02,  3.0095e-02],\n",
            "          [ 3.3301e-02, -2.3393e-02, -1.3012e-02, -3.4826e-02, -3.0441e-02],\n",
            "          [ 2.8575e-02,  3.1218e-02,  8.3487e-03, -2.8677e-02,  3.2913e-02],\n",
            "          [ 3.3140e-02,  3.0996e-02, -2.7296e-03, -2.8617e-02, -1.2077e-02],\n",
            "          [ 2.9946e-02, -1.4721e-02,  3.3224e-04, -1.6252e-02,  2.8724e-02]],\n",
            "\n",
            "         [[ 6.4982e-03,  5.3617e-03,  1.7602e-02,  1.2666e-02, -3.0190e-02],\n",
            "          [ 1.7211e-02, -2.4517e-02, -7.7792e-03,  3.5496e-02, -5.9657e-05],\n",
            "          [-2.0866e-02, -1.3834e-02, -2.7632e-02,  1.1365e-02, -3.2192e-03],\n",
            "          [-7.3872e-05,  1.7742e-02, -2.2137e-02, -1.8102e-03, -2.9340e-02],\n",
            "          [-1.5671e-02,  8.5708e-04, -1.8414e-02,  7.4517e-03,  3.1380e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2142e-02, -2.3538e-02,  9.8816e-03, -8.3645e-03,  2.4478e-04],\n",
            "          [-2.3598e-02, -1.6799e-02, -1.2411e-02,  1.7980e-02,  2.5312e-03],\n",
            "          [-9.6102e-03, -2.5138e-02, -2.6166e-02,  3.2788e-02, -1.6039e-02],\n",
            "          [-1.9303e-02, -2.1176e-03,  1.8841e-02,  2.8621e-03,  2.7618e-02],\n",
            "          [ 2.2833e-02,  3.2218e-03, -2.2474e-02, -3.3628e-02, -1.2481e-02]],\n",
            "\n",
            "         [[ 3.2816e-02,  1.2472e-02, -7.5858e-03,  3.0238e-02,  3.9873e-03],\n",
            "          [ 2.5528e-02, -2.9346e-02,  1.6828e-02,  2.5229e-02,  9.3858e-03],\n",
            "          [-1.3360e-02, -6.8632e-03, -1.7399e-02,  8.9117e-03, -2.2938e-02],\n",
            "          [-2.1196e-03,  4.1371e-03,  2.0593e-02,  3.1547e-02,  3.2152e-03],\n",
            "          [-8.9563e-03,  2.0058e-02, -1.9804e-02, -6.0949e-03,  2.4416e-02]],\n",
            "\n",
            "         [[ 2.3537e-02, -8.6902e-03, -5.4299e-03,  2.0178e-02,  2.5945e-02],\n",
            "          [-1.5826e-02, -1.8883e-02, -4.6459e-03,  4.1015e-03,  1.9346e-02],\n",
            "          [ 1.3192e-02,  3.2458e-02, -1.3332e-02, -1.3279e-02, -1.3139e-02],\n",
            "          [ 2.6067e-02, -8.3650e-04, -1.5706e-02,  2.7675e-02, -2.0320e-02],\n",
            "          [-3.1491e-02, -2.0253e-02, -2.4670e-02,  2.7126e-02, -1.3694e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6982e-02,  1.8871e-02,  1.6915e-03,  2.5342e-03, -3.0274e-02],\n",
            "          [ 1.5583e-02, -1.4942e-02,  2.4975e-02,  1.5627e-02, -1.4934e-02],\n",
            "          [ 2.8649e-02, -3.2555e-02,  9.6707e-03, -6.6025e-03,  2.2719e-02],\n",
            "          [ 1.4025e-02, -1.3942e-02,  1.3266e-02, -2.7210e-02, -1.5167e-02],\n",
            "          [-3.0327e-02,  2.9660e-02, -2.7118e-02, -2.0595e-03,  1.8925e-03]],\n",
            "\n",
            "         [[-1.9304e-03, -8.4528e-03,  5.4273e-04,  3.4427e-03,  2.4750e-02],\n",
            "          [-2.7213e-02, -1.1529e-02,  4.1150e-03, -3.0182e-02, -2.4599e-02],\n",
            "          [ 2.8788e-02,  3.4950e-02,  1.8141e-02, -1.0476e-02,  1.1702e-02],\n",
            "          [ 1.6755e-04,  5.7158e-03, -2.4577e-02, -1.0275e-02,  2.6592e-02],\n",
            "          [-7.8296e-03,  2.2803e-02, -2.4791e-02,  2.9382e-02,  2.2808e-02]],\n",
            "\n",
            "         [[-1.2101e-02,  2.3585e-02,  1.5998e-02,  1.7621e-02, -3.1222e-02],\n",
            "          [-3.0777e-02,  1.3956e-02, -3.2655e-02, -3.8340e-03,  2.1984e-02],\n",
            "          [ 1.0209e-02,  3.0352e-02, -2.7725e-02,  1.4679e-02,  4.0994e-03],\n",
            "          [-2.5210e-02, -1.2588e-02, -2.2272e-02, -6.5717e-03,  1.9716e-02],\n",
            "          [-1.2801e-03, -2.7567e-02, -2.3172e-02,  3.4586e-02, -6.9507e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.4360e-03, -2.4114e-02,  1.5934e-02, -3.0995e-02, -3.9897e-04],\n",
            "          [-1.6254e-02, -2.8366e-02, -2.9579e-03, -6.7651e-03,  3.2881e-03],\n",
            "          [ 1.4815e-03, -5.2736e-03,  2.1680e-02, -9.3915e-03,  3.4296e-02],\n",
            "          [-3.4650e-02,  3.1416e-02, -1.9922e-02,  1.1757e-02, -4.9390e-03],\n",
            "          [-3.0746e-02, -1.1593e-02,  2.8987e-02, -3.6363e-02,  2.7312e-02]],\n",
            "\n",
            "         [[-2.3727e-02, -1.3762e-02,  1.1712e-02,  1.6182e-02,  3.6437e-02],\n",
            "          [-2.2277e-02, -5.3393e-03,  2.7571e-02,  1.7402e-03, -1.7177e-02],\n",
            "          [ 3.4163e-02, -4.2057e-03, -8.2208e-04,  2.4011e-03,  5.4318e-04],\n",
            "          [-1.4061e-03,  1.9276e-02,  2.7904e-02, -6.4941e-04, -4.2843e-03],\n",
            "          [ 3.5334e-03, -1.5873e-02, -1.3900e-03,  1.2814e-02,  2.5788e-02]],\n",
            "\n",
            "         [[-2.7529e-02,  2.7156e-02,  2.6952e-02, -2.2663e-02, -1.6730e-02],\n",
            "          [ 2.1786e-02,  3.3218e-02,  2.0016e-02,  2.8882e-03,  8.8172e-03],\n",
            "          [ 2.7749e-02, -3.2520e-03,  2.8836e-02,  3.1385e-02, -1.7123e-02],\n",
            "          [ 4.3454e-03, -6.5331e-03, -1.3477e-02,  1.1054e-02, -2.3643e-02],\n",
            "          [ 9.8757e-03,  2.4374e-02, -3.0040e-02, -1.6387e-02,  2.1891e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8225e-02,  3.2910e-02,  2.8043e-03,  3.3729e-02,  1.1381e-03],\n",
            "          [ 1.5597e-02,  9.9637e-03, -3.4713e-02, -1.2413e-02, -3.0856e-02],\n",
            "          [-9.1087e-03,  2.8012e-02,  9.6552e-03, -1.9455e-02,  2.2185e-03],\n",
            "          [-3.2383e-03, -2.6562e-03,  5.5840e-03, -1.3705e-02,  1.8329e-02],\n",
            "          [-3.4540e-02, -7.1044e-03,  2.0468e-02,  1.1538e-02, -6.9988e-04]],\n",
            "\n",
            "         [[-1.5445e-02,  3.1457e-02,  1.6568e-02,  2.8216e-02,  1.6257e-02],\n",
            "          [ 1.3878e-02,  2.1869e-02, -8.0759e-03,  4.2989e-03, -1.2610e-02],\n",
            "          [-1.0916e-02,  2.2822e-02,  2.7877e-02, -3.4252e-02,  4.0231e-03],\n",
            "          [ 5.3868e-03, -2.2866e-02,  3.1794e-02,  3.4270e-02,  8.2686e-03],\n",
            "          [-2.6934e-02,  1.4732e-02, -7.2125e-03, -3.0731e-02,  2.7560e-02]],\n",
            "\n",
            "         [[ 1.3156e-02,  3.2862e-02, -2.4256e-02, -2.0209e-02, -1.5569e-03],\n",
            "          [-1.6876e-02, -2.2085e-02, -2.7291e-03, -1.6417e-02, -1.0239e-03],\n",
            "          [-3.5789e-02,  3.0149e-02,  1.2237e-02,  2.0670e-02,  2.4951e-02],\n",
            "          [-7.0884e-03,  1.5842e-02, -2.1896e-02,  2.5579e-02,  2.4038e-02],\n",
            "          [ 1.7944e-02,  9.5877e-03,  2.8078e-02, -8.5746e-03,  8.0171e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7619e-02, -3.3778e-03,  1.2964e-02,  2.2311e-02,  2.6501e-02],\n",
            "          [ 3.8254e-02,  2.2076e-02, -2.9682e-02, -1.0085e-02, -1.0538e-02],\n",
            "          [-2.6580e-02, -2.7376e-02, -3.1608e-02,  9.8039e-03, -2.7261e-02],\n",
            "          [ 2.0956e-02,  3.9858e-03, -8.8466e-03, -3.3912e-02,  2.3739e-02],\n",
            "          [ 1.1643e-03,  1.5768e-02,  4.9284e-03,  7.6503e-03,  2.3916e-03]],\n",
            "\n",
            "         [[-9.9879e-04,  2.9207e-02, -4.6287e-03,  1.9372e-02, -7.3731e-03],\n",
            "          [ 1.7262e-02, -1.6621e-03,  1.9143e-02, -1.8452e-02,  2.4162e-02],\n",
            "          [ 2.8990e-02, -1.4661e-02,  3.2871e-02,  3.9207e-03, -1.7053e-02],\n",
            "          [ 3.4321e-02,  5.9408e-03,  2.2701e-02, -3.3036e-02, -2.0074e-02],\n",
            "          [ 9.6624e-03, -2.8955e-02, -1.2205e-02, -2.2069e-02, -3.4138e-02]],\n",
            "\n",
            "         [[ 3.8914e-03, -1.1757e-02,  1.1976e-03, -5.0958e-03,  1.6842e-02],\n",
            "          [-2.6009e-03,  4.8764e-03,  1.6942e-02, -3.2750e-02,  2.9294e-02],\n",
            "          [ 7.7181e-03, -3.4568e-02,  2.6592e-02, -3.1290e-02,  2.4568e-03],\n",
            "          [-1.3995e-02, -1.6545e-02, -3.3720e-03, -1.4273e-02,  1.1389e-02],\n",
            "          [ 1.4411e-02, -1.4416e-02, -2.5396e-02, -8.1046e-03, -2.0442e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.9726e-02, -1.0191e-02,  2.3607e-03, -1.7978e-02,  2.9808e-02],\n",
            "          [-4.8678e-03, -3.7276e-02,  2.0814e-03,  1.7019e-02, -3.1097e-02],\n",
            "          [-1.3576e-02,  3.2159e-03,  1.9372e-02, -2.0380e-02,  2.0626e-02],\n",
            "          [ 8.0982e-03, -2.3206e-02,  1.4322e-03, -3.1234e-02,  2.2903e-02],\n",
            "          [-2.0628e-02, -8.3891e-04, -1.7844e-02, -2.3235e-02, -2.6222e-02]],\n",
            "\n",
            "         [[ 1.1296e-02, -1.3753e-02, -2.7217e-02, -8.7274e-03,  3.3305e-02],\n",
            "          [ 1.5823e-02, -1.2344e-02, -6.6496e-03, -3.1980e-02, -2.3547e-02],\n",
            "          [ 7.2179e-03,  1.4653e-02,  2.4763e-02, -6.5813e-03, -1.3333e-02],\n",
            "          [-3.0915e-02, -2.7914e-02, -3.2968e-02, -2.1728e-03,  2.4539e-02],\n",
            "          [-3.6425e-02,  2.5852e-02, -1.1866e-02,  2.7289e-02, -2.0358e-02]],\n",
            "\n",
            "         [[-1.7127e-02,  1.5908e-02, -1.4439e-02, -3.6587e-02,  1.5211e-03],\n",
            "          [-3.1123e-02,  1.1349e-02, -1.8884e-02, -2.4291e-02,  1.6206e-02],\n",
            "          [-2.9958e-02, -2.4763e-02, -1.4598e-02,  1.9196e-02, -3.3850e-02],\n",
            "          [ 3.4904e-03, -6.7516e-03, -1.2884e-02,  2.1026e-02, -1.1484e-02],\n",
            "          [ 1.4781e-02, -2.2093e-02,  3.4088e-02,  8.2902e-03,  3.2732e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.9084e-03,  1.5234e-02, -2.1588e-02,  2.6076e-02,  1.4875e-02],\n",
            "          [-3.1803e-02,  1.6689e-02, -4.4286e-03, -1.2617e-02, -2.5429e-02],\n",
            "          [-2.1979e-03, -6.8295e-03,  1.9771e-02,  9.1457e-04,  1.3936e-02],\n",
            "          [ 1.7781e-02, -1.0239e-02,  1.4152e-02,  2.7404e-02, -1.5794e-02],\n",
            "          [-3.3428e-02, -4.9103e-03, -3.5732e-02,  1.6979e-02, -2.0808e-02]],\n",
            "\n",
            "         [[-1.7298e-02,  2.3249e-02, -1.9642e-02,  1.2897e-02, -2.6497e-02],\n",
            "          [-2.4108e-02,  8.7199e-03,  1.0959e-02, -3.3178e-03, -2.1632e-03],\n",
            "          [ 3.1420e-02, -1.8384e-02, -1.2171e-02,  2.8024e-03, -2.6858e-02],\n",
            "          [-1.1825e-02, -2.8565e-02,  7.1283e-03,  1.7398e-02,  3.2180e-02],\n",
            "          [ 1.4464e-02, -3.2050e-02,  2.9655e-02, -3.7790e-04, -5.7815e-03]],\n",
            "\n",
            "         [[-3.5462e-02,  3.1438e-02, -3.3852e-02, -2.6736e-02, -6.0874e-03],\n",
            "          [-5.8761e-03, -2.7899e-03,  1.3589e-02, -2.3757e-02,  1.2665e-02],\n",
            "          [ 1.9195e-02,  9.1758e-03,  8.6029e-03, -1.5955e-02, -6.9827e-03],\n",
            "          [-3.1722e-03, -4.1997e-03, -3.1694e-03,  3.2443e-02, -3.5528e-02],\n",
            "          [-1.6741e-02, -3.3628e-02, -9.4481e-03, -1.2048e-02,  2.3209e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3545e-02, -9.7822e-03,  1.8608e-02, -2.9781e-02, -3.1903e-02],\n",
            "          [ 2.0675e-02,  2.2230e-02,  6.7036e-03, -2.4759e-02, -1.2520e-02],\n",
            "          [ 3.3997e-02, -5.4340e-03, -5.2893e-03,  1.7544e-02,  1.1257e-02],\n",
            "          [ 2.3367e-02,  2.5581e-02, -2.5272e-02, -1.1164e-02,  1.7673e-02],\n",
            "          [-2.1441e-02,  5.5383e-03,  4.1008e-03,  3.1620e-02,  6.4903e-03]],\n",
            "\n",
            "         [[-2.5079e-02, -1.1570e-02,  2.1405e-02, -1.3503e-02,  3.7991e-02],\n",
            "          [ 3.5821e-02,  1.2261e-02, -8.7345e-03,  2.4365e-02, -5.9214e-03],\n",
            "          [ 3.0025e-02,  1.4971e-02,  9.0377e-03,  1.3543e-02,  3.5292e-02],\n",
            "          [ 2.5789e-02, -1.0850e-02,  9.8013e-03, -2.2591e-02,  2.0508e-02],\n",
            "          [-2.8585e-02, -7.3091e-03, -6.2928e-03, -8.8237e-03, -4.7948e-04]],\n",
            "\n",
            "         [[ 8.0666e-03, -1.9007e-02, -8.4733e-03, -3.1707e-02,  2.9582e-02],\n",
            "          [-1.9898e-02,  2.8818e-02, -5.1204e-03, -3.2803e-02, -4.5984e-03],\n",
            "          [-2.2893e-02,  1.4319e-02,  2.7940e-02, -3.4991e-02, -2.8173e-02],\n",
            "          [ 4.1792e-03, -2.1566e-02, -1.8496e-02,  3.4575e-02,  2.5859e-02],\n",
            "          [ 2.2095e-02,  1.8218e-02,  2.3218e-02, -2.8626e-02,  9.7207e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8601e-02,  3.1151e-02, -2.3657e-02, -8.7816e-03, -1.6031e-02],\n",
            "          [-7.2217e-03, -9.0319e-03,  1.8228e-02,  1.8243e-02,  3.5445e-02],\n",
            "          [-1.6990e-02, -1.3419e-02,  2.9065e-02, -9.0766e-03, -4.3227e-03],\n",
            "          [-3.4979e-02,  1.1872e-02,  4.0639e-03,  3.1762e-02,  2.4307e-02],\n",
            "          [ 1.1954e-02, -3.0347e-02,  2.6582e-02,  5.1490e-03, -1.0806e-02]],\n",
            "\n",
            "         [[ 7.0089e-03,  2.5695e-02, -2.0428e-02, -1.8412e-02, -3.8029e-03],\n",
            "          [-3.3167e-02, -9.3504e-03, -2.3998e-02, -2.1279e-02,  2.2868e-02],\n",
            "          [-1.8496e-02, -2.3330e-02, -8.2144e-03,  3.0574e-02, -1.2909e-02],\n",
            "          [-3.7676e-02,  9.6881e-03,  5.0180e-03, -2.4718e-02,  1.4776e-02],\n",
            "          [-2.9160e-02,  2.1252e-02, -2.5162e-02, -3.4588e-02, -1.9530e-02]],\n",
            "\n",
            "         [[-4.2982e-03, -2.8471e-02, -7.0785e-03, -2.9503e-02,  3.5094e-02],\n",
            "          [ 1.2679e-03, -3.4311e-02, -1.7972e-02,  7.8820e-03, -2.8920e-02],\n",
            "          [ 2.3551e-02, -3.1872e-02,  3.4113e-03,  1.3201e-02, -1.6674e-02],\n",
            "          [ 2.5828e-02, -5.0922e-03,  2.0589e-02,  8.0335e-03, -3.4031e-02],\n",
            "          [ 1.9785e-02,  3.4638e-02,  3.0648e-02, -3.0859e-02,  1.4219e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8816e-02, -1.3634e-03,  2.8021e-03, -1.4692e-02, -1.9437e-02],\n",
            "          [-1.9880e-02,  1.8773e-02,  1.2616e-02, -2.0233e-02, -2.9732e-02],\n",
            "          [ 1.1154e-02, -1.3371e-02, -2.7910e-02, -1.8996e-02, -2.5767e-02],\n",
            "          [ 6.1133e-04,  2.3409e-02, -1.2331e-02, -1.1510e-02, -3.4494e-02],\n",
            "          [-9.3976e-03, -7.0930e-03, -3.5138e-02,  2.9178e-02, -3.2345e-02]],\n",
            "\n",
            "         [[ 1.0568e-02,  2.0737e-02,  8.8974e-03, -1.9763e-02,  2.9188e-02],\n",
            "          [-2.6196e-02, -1.8713e-02, -2.6811e-02, -9.6673e-03,  3.2603e-02],\n",
            "          [ 3.1777e-02,  2.2604e-02,  2.7600e-02, -1.1299e-02,  2.0509e-02],\n",
            "          [-3.1762e-02,  9.5483e-03,  1.2530e-02, -1.0340e-02,  1.4987e-02],\n",
            "          [-1.2220e-02, -9.8012e-03,  3.1808e-02, -2.9295e-02, -6.4340e-04]],\n",
            "\n",
            "         [[ 1.1440e-03, -5.6266e-03,  2.5498e-02,  3.3888e-02, -2.4063e-02],\n",
            "          [-1.5661e-02,  1.5774e-02,  2.5396e-02,  8.8044e-03, -1.5584e-02],\n",
            "          [-6.8590e-05, -1.6142e-02,  2.2346e-02, -3.4127e-02,  2.3074e-02],\n",
            "          [-2.6278e-02, -1.7562e-02,  7.4294e-03,  2.0058e-03, -2.4675e-02],\n",
            "          [ 1.1538e-03, -1.5442e-02,  7.4343e-03, -2.0586e-03,  3.2503e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0690e-02,  2.1677e-02,  6.0428e-03, -1.7780e-03, -1.2926e-02],\n",
            "          [ 9.5773e-03,  2.3810e-02, -9.7935e-03, -5.9311e-03,  1.2612e-03],\n",
            "          [-1.6772e-02,  1.3443e-02, -1.5043e-02,  2.0457e-02, -3.6354e-04],\n",
            "          [-2.5271e-02, -1.0477e-02, -5.1416e-03, -1.9918e-02,  3.4829e-02],\n",
            "          [-2.4503e-02, -3.1727e-02,  2.7806e-03,  2.1807e-02,  4.5451e-03]],\n",
            "\n",
            "         [[ 1.3549e-02, -2.1102e-02, -8.6904e-03, -2.3778e-02,  5.8189e-03],\n",
            "          [-2.3546e-02,  1.1012e-02, -3.2838e-03,  4.5874e-03,  3.1850e-02],\n",
            "          [-1.1514e-02,  1.2158e-02,  2.0253e-02,  4.4627e-03, -3.2086e-02],\n",
            "          [-2.9551e-03,  5.4915e-03, -4.0823e-03, -1.9037e-02, -1.8000e-02],\n",
            "          [-5.3990e-03,  2.8041e-02, -2.0281e-02,  3.5795e-02, -1.7036e-02]],\n",
            "\n",
            "         [[-2.1060e-02,  7.1485e-03,  2.2363e-02, -9.6033e-03, -1.8549e-02],\n",
            "          [ 1.0823e-02, -1.1173e-03,  2.2850e-02, -2.4004e-02, -2.7133e-02],\n",
            "          [ 5.9628e-03, -3.0717e-02, -1.8028e-02, -3.3869e-02, -2.6628e-03],\n",
            "          [ 2.6139e-02, -3.3372e-02, -3.5582e-02, -1.8811e-02, -3.4341e-02],\n",
            "          [-5.1831e-03, -2.9276e-02, -4.5104e-03, -2.2606e-03, -2.2796e-02]]]])), ('conv3.bias', tensor([ 6.6796e-03,  1.8355e-04, -1.2530e-02,  1.3671e-04, -9.8590e-03,\n",
            "         1.8103e-04, -5.1987e-04, -1.6866e-04, -8.3749e-05,  1.0599e-02,\n",
            "         1.0556e-02,  9.7914e-05,  1.2201e-02,  3.5111e-04, -1.0123e-05,\n",
            "        -1.0464e-02,  1.2656e-02,  2.2156e-03,  3.2083e-03, -3.7059e-03,\n",
            "         6.2907e-04, -1.4395e-02,  1.5012e-03, -2.9987e-04, -8.0678e-03,\n",
            "        -2.6057e-03, -2.2576e-05,  2.5360e-03, -6.8051e-03,  7.1062e-06,\n",
            "         9.0654e-05,  7.9591e-03,  2.3946e-04, -1.2649e-02, -4.6968e-05,\n",
            "         2.9498e-04, -3.5944e-03, -5.4692e-05, -1.8300e-04,  1.3809e-02,\n",
            "        -2.2630e-05, -9.6826e-03, -2.1899e-03,  1.1839e-02, -1.1610e-02,\n",
            "         1.2207e-03, -3.4872e-03, -1.0213e-04, -1.9268e-03, -9.1738e-05,\n",
            "         1.2971e-02, -6.3929e-06,  3.6976e-04,  5.9495e-06,  1.7854e-03,\n",
            "         4.7798e-03,  6.4076e-05,  2.0270e-04, -1.5354e-02, -7.0209e-05,\n",
            "         9.8672e-03, -1.0967e-02, -1.9717e-04, -1.3475e-02])), ('bn3.weight', tensor([1.0020, 0.9997, 0.9988, 0.9980, 1.0025, 1.0001, 0.9962, 0.9988, 0.9982,\n",
            "        1.0003, 0.9978, 0.9970, 1.0014, 0.9993, 0.9985, 0.9986, 0.9992, 1.0000,\n",
            "        1.0019, 0.9982, 0.9996, 0.9975, 0.9999, 1.0012, 0.9992, 1.0007, 0.9996,\n",
            "        0.9970, 0.9987, 1.0001, 0.9984, 0.9994, 1.0004, 0.9955, 0.9994, 0.9957,\n",
            "        0.9989, 1.0008, 1.0025, 1.0005, 0.9981, 0.9992, 0.9986, 0.9967, 1.0008,\n",
            "        0.9998, 0.9980, 0.9956, 0.9988, 0.9988, 0.9988, 1.0000, 0.9989, 1.0001,\n",
            "        0.9999, 1.0024, 1.0009, 0.9990, 0.9981, 0.9970, 0.9996, 0.9992, 0.9998,\n",
            "        1.0003])), ('bn3.bias', tensor([ 1.9677e-03,  1.8504e-03, -4.1448e-05, -8.5185e-04,  8.5895e-04,\n",
            "         8.4661e-05, -1.0125e-03,  8.3995e-04,  1.2006e-03,  1.1450e-03,\n",
            "        -2.0599e-03, -9.5608e-05,  1.9815e-03,  1.9354e-03, -1.9667e-03,\n",
            "         1.4397e-03,  1.3044e-03,  1.1742e-03, -2.0463e-04,  8.8648e-04,\n",
            "        -1.9443e-03, -3.0037e-03, -1.1229e-04,  2.2230e-03, -6.2138e-04,\n",
            "        -1.5076e-04, -5.3384e-04, -8.7052e-04, -2.5425e-03, -5.0980e-04,\n",
            "         2.0749e-03,  3.0080e-04,  1.0279e-03, -2.6659e-03,  8.8433e-04,\n",
            "        -9.3564e-04, -5.4416e-04,  2.8982e-03,  1.2848e-03,  3.7697e-03,\n",
            "        -3.1326e-04,  1.7062e-03, -2.4516e-03, -4.7561e-03,  3.6084e-03,\n",
            "         1.3792e-03, -2.1188e-03, -2.0492e-03, -1.2254e-03,  2.9891e-04,\n",
            "        -3.4507e-04,  1.7637e-03,  1.6281e-03,  1.5983e-03,  2.5649e-04,\n",
            "         3.3963e-03,  1.9415e-03,  9.9088e-04,  1.8543e-04, -1.1224e-03,\n",
            "         4.1130e-04,  5.1974e-04,  8.8307e-04, -9.2933e-04])), ('bn3.running_mean', tensor([ 0.4765, -0.0880,  0.3366,  0.2561,  0.4374,  0.0388, -0.5928, -0.6780,\n",
            "        -0.2583,  0.4913, -0.1178,  0.6019, -0.5962, -0.3767, -0.1076, -0.4460,\n",
            "         0.0962,  0.0282,  0.3179, -0.1275, -0.0514,  0.4971,  0.6969,  0.7495,\n",
            "         0.6530, -0.0570,  0.4110,  0.4001,  0.3923,  0.3190,  0.1680, -0.1531,\n",
            "        -0.5813, -0.1441, -0.1744, -0.1038, -0.2232,  0.0756, -0.1387,  0.0415,\n",
            "         0.1687,  0.3383, -0.2312,  0.1346,  0.3440, -0.1294,  0.0959, -0.4011,\n",
            "        -0.2335,  0.4791, -0.4158,  0.4465, -0.4650, -0.0835,  0.1447,  0.2411,\n",
            "        -0.0478,  0.0412, -0.0554, -0.0200,  0.0553, -0.0125, -0.5652, -0.2200])), ('bn3.running_var', tensor([0.2787, 0.1261, 0.1948, 0.2116, 0.3830, 0.5061, 0.5628, 0.2570, 0.1963,\n",
            "        0.3105, 0.3274, 0.2555, 0.1778, 0.1718, 0.1536, 0.2326, 0.3795, 0.2810,\n",
            "        0.2932, 0.4213, 0.4440, 0.3702, 0.4826, 0.2964, 0.4224, 0.4017, 0.3153,\n",
            "        0.2580, 0.1725, 0.2902, 0.1786, 0.3963, 0.3941, 0.1399, 0.1856, 0.3011,\n",
            "        0.1895, 0.1952, 0.1744, 0.1694, 0.2328, 0.2683, 0.1216, 0.2175, 0.1871,\n",
            "        0.1575, 0.2020, 0.2735, 0.1077, 0.3066, 0.1693, 0.1519, 0.3120, 0.2998,\n",
            "        0.1135, 0.2412, 0.1241, 0.1712, 0.1956, 0.1810, 0.3610, 0.2956, 0.2048,\n",
            "        0.3013])), ('bn3.num_batches_tracked', tensor(250)), ('conv4.weight', tensor([[[[-5.2921e-03,  8.7366e-03, -1.7784e-02],\n",
            "          [ 5.9178e-03,  3.0119e-02,  2.7938e-02],\n",
            "          [-2.9598e-02, -1.5519e-03, -8.8135e-03]],\n",
            "\n",
            "         [[-2.6618e-02, -9.4776e-03, -4.7310e-03],\n",
            "          [-2.1953e-04,  6.4254e-03, -1.8870e-02],\n",
            "          [-2.9065e-03, -9.8344e-03,  2.9126e-02]],\n",
            "\n",
            "         [[ 2.4669e-02, -3.6970e-02,  3.8119e-02],\n",
            "          [-1.4912e-02, -3.8658e-02, -2.9550e-02],\n",
            "          [-3.6146e-02,  3.9815e-02, -2.6172e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4085e-02, -1.4051e-02,  8.4149e-03],\n",
            "          [ 3.6313e-02,  5.4836e-03,  4.2148e-03],\n",
            "          [ 1.4313e-02,  1.8728e-02,  2.8420e-02]],\n",
            "\n",
            "         [[ 3.2817e-02,  2.2581e-02,  1.5430e-02],\n",
            "          [ 1.4781e-02,  1.6619e-02, -2.3799e-02],\n",
            "          [-2.1301e-02,  3.0061e-02,  1.1229e-02]],\n",
            "\n",
            "         [[-4.1128e-02,  2.0187e-02,  2.6387e-02],\n",
            "          [ 5.4081e-03, -8.1849e-03, -4.2385e-02],\n",
            "          [-1.9866e-02,  2.0232e-03,  3.4728e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.6594e-02, -2.4305e-02, -8.5651e-03],\n",
            "          [ 3.4675e-02, -3.9004e-02,  2.9193e-02],\n",
            "          [-4.1594e-02, -1.0265e-02, -9.9973e-03]],\n",
            "\n",
            "         [[-2.3354e-02,  1.1782e-02,  2.1344e-02],\n",
            "          [ 3.2753e-02, -2.0385e-02, -2.0837e-02],\n",
            "          [-3.4766e-02,  1.1109e-03, -3.6366e-02]],\n",
            "\n",
            "         [[ 3.0561e-02, -2.7504e-02, -3.3129e-02],\n",
            "          [-1.9491e-04, -2.2527e-02, -2.0764e-02],\n",
            "          [ 1.6854e-03,  1.4709e-02, -1.6274e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1070e-02, -2.0448e-02, -2.6829e-02],\n",
            "          [ 3.3732e-02, -5.4440e-03, -1.3827e-02],\n",
            "          [-1.3426e-02, -3.5663e-02,  3.8218e-02]],\n",
            "\n",
            "         [[ 3.7664e-02,  4.3225e-02, -2.9138e-02],\n",
            "          [-2.7337e-02, -1.8211e-02,  3.6980e-02],\n",
            "          [ 1.5677e-02, -4.0008e-05, -1.4641e-02]],\n",
            "\n",
            "         [[-3.9089e-02,  3.0666e-02, -3.8968e-02],\n",
            "          [-3.0152e-02,  2.3007e-02,  1.3673e-02],\n",
            "          [-3.9825e-02,  2.0604e-02, -3.3677e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.3429e-03, -2.2987e-02,  1.0504e-02],\n",
            "          [-3.8270e-02, -1.7445e-02,  1.8433e-02],\n",
            "          [-1.1271e-02, -2.3128e-02, -7.2923e-03]],\n",
            "\n",
            "         [[-6.4997e-03, -2.7653e-02,  2.6202e-02],\n",
            "          [ 2.1614e-02, -1.2855e-02, -1.7745e-02],\n",
            "          [-2.9644e-02,  1.1854e-02,  2.3261e-02]],\n",
            "\n",
            "         [[-4.3517e-03,  3.0540e-03, -1.2934e-02],\n",
            "          [-1.5301e-02, -2.4211e-02,  1.9703e-02],\n",
            "          [ 1.4608e-02,  1.3472e-02,  3.8299e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.0654e-04,  2.6759e-02, -1.0229e-02],\n",
            "          [ 6.1364e-03, -3.9825e-02, -1.8288e-02],\n",
            "          [ 2.2265e-02,  3.2538e-02, -3.0357e-02]],\n",
            "\n",
            "         [[-6.4606e-03, -1.3828e-03, -3.4563e-02],\n",
            "          [-3.0262e-02,  3.4215e-02,  1.5638e-02],\n",
            "          [ 8.8798e-03,  2.0760e-02,  8.4615e-03]],\n",
            "\n",
            "         [[ 1.6686e-02,  7.0245e-03, -1.0151e-03],\n",
            "          [-1.5504e-03,  9.7999e-03, -3.1313e-04],\n",
            "          [ 1.1978e-02,  2.0381e-02, -2.2374e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.6523e-02, -5.5092e-03,  1.8588e-02],\n",
            "          [ 6.0172e-03, -3.3755e-02, -2.3297e-02],\n",
            "          [-2.6697e-02, -3.4386e-02,  1.2019e-02]],\n",
            "\n",
            "         [[ 1.7391e-03,  7.6225e-03, -6.9457e-03],\n",
            "          [-3.8587e-02, -4.1528e-03,  2.9912e-03],\n",
            "          [-3.1531e-02,  3.5678e-02, -8.3632e-03]],\n",
            "\n",
            "         [[-6.9481e-03, -2.7284e-02, -3.6138e-02],\n",
            "          [-1.3661e-02,  1.8892e-02,  3.6123e-02],\n",
            "          [ 3.7689e-02,  5.0988e-03, -9.6307e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8258e-02, -1.9692e-02, -3.6038e-02],\n",
            "          [-1.4225e-03,  1.4750e-02, -4.6971e-03],\n",
            "          [ 1.7548e-03, -3.7174e-02, -5.5949e-03]],\n",
            "\n",
            "         [[ 1.3843e-02,  1.9893e-03, -2.2590e-02],\n",
            "          [ 2.5857e-02, -2.3587e-02,  3.1832e-02],\n",
            "          [ 1.9512e-02,  2.4509e-02,  1.0299e-02]],\n",
            "\n",
            "         [[-1.0086e-02, -3.0309e-02,  1.9613e-02],\n",
            "          [-1.6966e-02, -3.3166e-02,  2.3157e-02],\n",
            "          [ 3.5730e-02,  1.0763e-02, -2.1182e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.2308e-02,  2.6698e-02, -2.9212e-02],\n",
            "          [-2.9283e-02,  1.9234e-02, -1.9786e-02],\n",
            "          [ 4.1260e-02,  3.8243e-02,  3.8681e-02]],\n",
            "\n",
            "         [[ 3.8933e-02,  2.9864e-02,  3.7164e-02],\n",
            "          [-3.4022e-02,  3.4044e-03,  3.7642e-02],\n",
            "          [-1.0509e-02, -3.9546e-03, -1.2811e-02]],\n",
            "\n",
            "         [[ 3.1310e-02,  2.6648e-02,  1.1792e-02],\n",
            "          [-2.7487e-02,  5.6931e-03,  2.4363e-02],\n",
            "          [ 3.7033e-02, -2.9507e-02,  2.3524e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1100e-03, -3.4612e-03,  3.6921e-02],\n",
            "          [-3.6909e-02,  2.7427e-02,  2.2884e-02],\n",
            "          [-4.0706e-02,  2.7876e-02,  1.6236e-03]],\n",
            "\n",
            "         [[ 2.5077e-02,  1.6394e-02, -2.7473e-03],\n",
            "          [-2.8870e-02, -1.5121e-02,  2.2003e-02],\n",
            "          [ 3.7488e-02,  2.5878e-02,  2.0083e-02]],\n",
            "\n",
            "         [[ 9.7725e-03,  2.0349e-02, -1.2934e-02],\n",
            "          [ 1.1339e-02, -2.9262e-02, -3.3202e-02],\n",
            "          [ 3.8221e-02,  2.8224e-02,  8.3453e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.6529e-03,  5.6152e-03,  1.9970e-02],\n",
            "          [-1.1057e-02,  3.3862e-02,  3.9048e-02],\n",
            "          [-9.1949e-03,  1.7237e-03, -4.3604e-03]],\n",
            "\n",
            "         [[ 1.5235e-02, -1.4233e-02, -2.6778e-03],\n",
            "          [ 6.5878e-03,  4.0017e-02,  4.1371e-03],\n",
            "          [-3.8244e-02, -2.0699e-02,  4.2157e-04]],\n",
            "\n",
            "         [[-4.5454e-03,  4.2489e-02,  4.1417e-02],\n",
            "          [ 2.8041e-02,  8.9638e-03, -3.0334e-02],\n",
            "          [-5.2783e-03, -1.5390e-02, -3.7590e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.0237e-02,  2.0285e-02, -2.4751e-02],\n",
            "          [ 4.1026e-02,  1.6337e-02,  3.4422e-03],\n",
            "          [-2.7278e-02,  2.1747e-02, -3.5463e-02]],\n",
            "\n",
            "         [[-2.2999e-02, -6.2824e-03,  8.9741e-04],\n",
            "          [-5.8735e-03, -3.8902e-02,  5.9822e-03],\n",
            "          [ 1.8146e-02, -3.6510e-02,  9.7861e-03]],\n",
            "\n",
            "         [[-8.0346e-03, -2.3251e-02,  2.5307e-02],\n",
            "          [ 3.4896e-02,  8.7433e-03, -8.2903e-03],\n",
            "          [-1.3964e-02, -3.5962e-02,  1.0138e-02]]]])), ('conv4.bias', tensor([ 1.7051e-02, -1.8096e-05, -7.9080e-03,  3.6236e-05, -6.7519e-04,\n",
            "        -1.9700e-02, -1.3764e-05,  4.2947e-04,  7.4903e-03, -5.6152e-05,\n",
            "         1.5157e-02, -3.4918e-03, -2.5882e-03,  1.2885e-04,  1.4717e-05,\n",
            "        -8.9777e-03,  2.6564e-05, -3.0904e-05, -1.9667e-02,  2.0181e-02,\n",
            "         1.2960e-05,  1.7985e-02,  8.1508e-03,  1.4180e-02, -1.7169e-03,\n",
            "        -9.2536e-03,  1.7745e-02, -1.5140e-02,  9.1010e-03, -1.4855e-02,\n",
            "        -3.0884e-03, -1.1571e-02, -1.6249e-02,  1.0398e-02, -1.7154e-02,\n",
            "         1.0260e-03, -1.1740e-04, -1.5584e-02, -1.5878e-02, -5.9152e-04,\n",
            "         4.8406e-04, -4.2600e-05,  5.5577e-03,  5.3351e-03,  1.6994e-02,\n",
            "        -1.3709e-04, -7.8923e-03, -3.5334e-05, -1.5225e-02,  8.5862e-03,\n",
            "        -7.5352e-03, -1.2136e-05,  8.1254e-04,  1.5142e-02, -1.3981e-02,\n",
            "         1.7848e-02, -6.3366e-05,  1.7613e-03,  1.8328e-02, -1.8602e-02,\n",
            "         8.1397e-04,  9.3157e-03, -1.9835e-02,  1.2314e-04,  5.6350e-03,\n",
            "         1.9037e-02,  3.5564e-05,  4.0811e-05,  1.0575e-03,  1.0379e-02,\n",
            "        -4.6500e-03,  1.9846e-02,  1.9096e-02, -1.4842e-03,  1.3168e-02,\n",
            "        -1.2939e-02, -1.1609e-02,  1.8722e-02,  2.3731e-04,  6.8814e-05,\n",
            "         1.1750e-05, -9.7037e-03, -1.2373e-03, -9.6846e-03, -1.4137e-02,\n",
            "         2.8218e-03, -1.1915e-05, -7.2791e-03,  1.1215e-02, -9.0639e-03,\n",
            "         1.5462e-02,  8.2114e-03,  6.2277e-06,  7.1777e-03,  4.2599e-03,\n",
            "         4.1185e-05, -2.0704e-02,  4.2441e-04, -5.2023e-04,  6.7973e-03,\n",
            "        -1.1765e-02, -1.6503e-02,  1.6891e-02,  1.2695e-04, -1.0168e-02,\n",
            "        -2.3476e-03, -9.5631e-06,  2.0648e-02,  5.7130e-05, -1.4940e-02,\n",
            "        -1.1108e-03, -9.8432e-03, -3.1159e-03,  2.2921e-03,  1.2870e-03,\n",
            "        -2.6344e-06,  3.8609e-05,  8.3674e-03, -1.2392e-04,  2.6626e-05,\n",
            "         1.3836e-05, -1.2768e-02, -4.9759e-04,  1.6125e-02,  7.6848e-03,\n",
            "        -7.9346e-03,  2.6306e-05, -6.1128e-05])), ('bn4.weight', tensor([0.9964, 1.0001, 0.9968, 0.9993, 0.9992, 1.0027, 0.9958, 0.9987, 0.9962,\n",
            "        0.9976, 0.9971, 0.9985, 0.9991, 1.0006, 1.0013, 0.9993, 0.9994, 0.9968,\n",
            "        0.9989, 1.0006, 0.9960, 0.9985, 0.9996, 0.9972, 0.9992, 0.9993, 0.9991,\n",
            "        0.9984, 1.0015, 1.0007, 0.9964, 0.9976, 0.9999, 0.9973, 1.0014, 0.9967,\n",
            "        1.0000, 0.9985, 1.0007, 1.0014, 0.9977, 0.9999, 0.9971, 0.9986, 0.9997,\n",
            "        0.9984, 0.9980, 0.9973, 0.9978, 0.9987, 0.9959, 0.9988, 0.9979, 0.9972,\n",
            "        0.9963, 0.9966, 1.0017, 0.9948, 0.9978, 0.9973, 1.0003, 0.9996, 1.0005,\n",
            "        0.9996, 0.9935, 0.9997, 0.9988, 0.9952, 1.0014, 1.0005, 0.9995, 0.9976,\n",
            "        1.0016, 0.9992, 0.9979, 1.0035, 0.9982, 0.9965, 0.9997, 0.9980, 0.9971,\n",
            "        0.9983, 0.9977, 0.9993, 0.9987, 0.9992, 0.9976, 0.9957, 0.9982, 0.9976,\n",
            "        1.0014, 1.0012, 0.9986, 1.0023, 0.9998, 0.9996, 1.0012, 0.9969, 0.9991,\n",
            "        0.9996, 0.9950, 0.9980, 0.9950, 0.9992, 1.0006, 0.9980, 1.0026, 1.0003,\n",
            "        0.9985, 1.0001, 1.0000, 0.9997, 0.9967, 0.9974, 0.9961, 1.0015, 0.9991,\n",
            "        0.9980, 0.9997, 0.9984, 0.9981, 0.9981, 0.9978, 0.9969, 0.9952, 0.9991,\n",
            "        1.0001, 1.0011])), ('bn4.bias', tensor([-2.5103e-03, -2.5146e-04, -1.6309e-03,  1.6550e-03, -2.0719e-04,\n",
            "         2.4937e-03, -1.3769e-03, -1.5320e-03, -3.4064e-03,  1.5350e-05,\n",
            "         7.3330e-04, -4.2932e-04,  1.6169e-04,  3.3740e-03,  1.6231e-03,\n",
            "         1.3191e-03,  2.9827e-04, -2.2898e-04, -1.0185e-03,  1.3390e-03,\n",
            "        -9.1479e-04, -1.0030e-03,  1.6059e-03, -2.4731e-03,  1.7447e-03,\n",
            "        -5.8265e-04, -1.3016e-03, -3.4695e-04,  1.6800e-03, -9.7243e-04,\n",
            "        -1.6088e-03, -4.2586e-04,  2.3706e-03,  1.1987e-03,  1.5180e-03,\n",
            "        -1.8742e-03,  1.3247e-03, -1.2310e-03, -5.2519e-04,  1.5926e-03,\n",
            "         5.5447e-04,  1.0370e-03, -1.2698e-03,  7.8959e-04, -1.5299e-03,\n",
            "         5.6135e-04,  1.3631e-03, -3.0192e-04,  1.8234e-05,  1.5562e-03,\n",
            "        -1.5624e-03,  4.8082e-04, -9.5526e-04, -7.5884e-04, -8.6609e-04,\n",
            "        -1.6185e-03,  1.1320e-04, -2.7451e-03, -8.3587e-04,  1.7130e-03,\n",
            "         4.5684e-04, -1.3162e-03,  2.8989e-04,  1.3122e-03, -2.3053e-03,\n",
            "         5.9255e-04, -1.6072e-03, -2.7730e-03,  3.3180e-04,  1.7234e-03,\n",
            "         1.6447e-03, -1.7797e-03,  1.5710e-03, -9.3534e-06,  1.3096e-03,\n",
            "         3.3059e-03, -2.1272e-03, -6.7856e-04,  8.8711e-04,  7.1943e-04,\n",
            "        -6.2718e-04,  8.5676e-05,  2.1187e-04, -7.9619e-05, -1.4564e-03,\n",
            "         1.0022e-03, -2.0007e-03, -2.7969e-03, -9.3909e-04, -1.6616e-03,\n",
            "         2.9923e-03,  2.1970e-03, -5.4817e-04, -4.1987e-06,  1.6444e-03,\n",
            "         3.8352e-04,  3.2980e-03, -1.3966e-03, -1.7013e-03, -1.1724e-03,\n",
            "        -1.8830e-03,  3.4657e-04, -3.9556e-03,  9.5836e-04,  1.7490e-03,\n",
            "        -2.8902e-03,  9.1609e-04, -5.4960e-04,  8.2667e-05,  1.6186e-03,\n",
            "         1.1754e-03,  1.9646e-03,  7.3530e-04, -2.6414e-03, -3.9909e-04,\n",
            "        -1.1452e-04,  7.5410e-04, -4.5672e-06,  2.4636e-03, -1.1407e-03,\n",
            "         2.8699e-04, -4.4151e-04,  7.1332e-05, -1.4609e-03, -3.9661e-03,\n",
            "         5.8643e-04, -2.7249e-03, -8.8938e-05])), ('bn4.running_mean', tensor([-2.8219e-01, -2.4256e-01,  2.4186e-01,  1.5092e-01, -1.2176e-01,\n",
            "         1.6391e-01, -2.4408e-01, -2.6097e-03,  6.7041e-02,  4.7999e-02,\n",
            "        -5.4224e-02,  4.5935e-01,  2.6608e-01,  1.3033e-01, -2.0865e-01,\n",
            "        -9.4242e-03,  2.3012e-01, -4.5233e-01,  1.6184e-01,  1.0280e-01,\n",
            "        -3.2908e-01,  3.0499e-01,  1.2987e-01, -3.0303e-01,  2.4217e-01,\n",
            "         3.2498e-01,  4.9822e-01,  4.6388e-01,  3.8100e-01, -1.1076e-01,\n",
            "        -4.2207e-01, -1.7599e-01,  1.8251e-01,  1.6097e-01, -5.5440e-01,\n",
            "        -1.2492e-02,  3.6598e-01,  3.8488e-01,  1.9875e-01, -3.3461e-01,\n",
            "         2.5592e-02, -2.0601e-01, -3.6248e-01,  2.2013e-01,  1.7071e-01,\n",
            "         1.4989e-01, -5.0127e-01,  1.4145e-01, -2.7127e-01,  2.1759e-01,\n",
            "        -7.2928e-01,  2.7399e-01, -2.2031e-01,  2.0054e-01, -4.2922e-01,\n",
            "        -1.2500e-01, -3.0937e-01, -1.4765e-01,  1.7177e-01,  1.9104e-01,\n",
            "         2.5543e-02,  2.6741e-01,  2.8308e-01,  1.1521e-01, -5.8195e-02,\n",
            "         3.2385e-01, -6.7423e-01, -9.6256e-05,  4.3326e-01,  1.6055e-01,\n",
            "         3.2158e-01,  8.6783e-02, -1.6106e-01, -3.2996e-02, -5.1051e-01,\n",
            "        -4.0888e-02,  2.0968e-01,  1.9767e-01,  8.0521e-02,  1.4832e-01,\n",
            "        -1.0480e-01, -4.9425e-02,  2.2145e-01,  2.1354e-01,  3.9807e-01,\n",
            "         5.7399e-01,  3.1172e-01, -5.5887e-01,  3.2037e-01,  4.1939e-01,\n",
            "         6.5850e-01, -3.0388e-01,  6.7617e-02,  1.2264e-01,  3.4665e-01,\n",
            "         2.9776e-01, -5.5765e-01, -4.0077e-01,  1.8127e-01, -4.8239e-01,\n",
            "         4.3691e-01,  2.8712e-01, -2.1675e-01,  2.4624e-01,  2.1552e-01,\n",
            "        -2.4477e-01,  2.2539e-01, -2.7956e-01,  3.0322e-01, -7.3246e-01,\n",
            "         5.7865e-01,  6.9012e-01, -2.9912e-01, -3.3381e-01,  2.2304e-02,\n",
            "        -3.1421e-01,  7.5467e-01,  8.2423e-02, -1.9379e-01, -9.0418e-01,\n",
            "         6.5426e-01, -6.8059e-01, -1.3766e-01, -1.7194e-01, -1.3929e-01,\n",
            "        -1.7248e-01,  1.8512e-01,  1.5856e-01])), ('bn4.running_var', tensor([0.2473, 0.2149, 0.1570, 0.1979, 0.1507, 0.1300, 0.1288, 0.1213, 0.3603,\n",
            "        0.1464, 0.1705, 0.2004, 0.2556, 0.2381, 0.2332, 0.1048, 0.1877, 0.2197,\n",
            "        0.2257, 0.1977, 0.1457, 0.4181, 0.2697, 0.2138, 0.2313, 0.2540, 0.1766,\n",
            "        0.1986, 0.1324, 0.3888, 0.1823, 0.1297, 0.2297, 0.1250, 0.4005, 0.1272,\n",
            "        0.2120, 0.3067, 0.1748, 0.2606, 0.1181, 0.3111, 0.1464, 0.2819, 0.4607,\n",
            "        0.1967, 0.2552, 0.1085, 0.2144, 0.2469, 0.4128, 0.1570, 0.2572, 0.2070,\n",
            "        0.2542, 0.1275, 0.4483, 0.0922, 0.1703, 0.1627, 0.3941, 0.2210, 0.2750,\n",
            "        0.2186, 0.1764, 0.1700, 0.2559, 0.2082, 0.1174, 0.3043, 0.3167, 0.1585,\n",
            "        0.1974, 0.2156, 0.2441, 0.2270, 0.3838, 0.2604, 0.1619, 0.1798, 0.2066,\n",
            "        0.2420, 0.1961, 0.1432, 0.1995, 0.3053, 0.2435, 0.5229, 0.2527, 0.3078,\n",
            "        0.3616, 0.2602, 0.2591, 0.2976, 0.2835, 0.2301, 0.2462, 0.3314, 0.2371,\n",
            "        0.1301, 0.1880, 0.1347, 0.1188, 0.2045, 0.3149, 0.3458, 0.1630, 0.2337,\n",
            "        0.2195, 0.2031, 0.2604, 0.2305, 0.1978, 0.1456, 0.2127, 0.3299, 0.1096,\n",
            "        0.3117, 0.1429, 0.4053, 0.2220, 0.3189, 0.2136, 0.1610, 0.1295, 0.2382,\n",
            "        0.1045, 0.1923])), ('bn4.num_batches_tracked', tensor(250)), ('conv5.weight', tensor([[[[ 1.6956e-02, -2.5391e-02,  4.0441e-03],\n",
            "          [-9.4884e-04,  2.3151e-02,  2.6305e-02],\n",
            "          [-1.6319e-03,  1.8134e-02,  5.2417e-03]],\n",
            "\n",
            "         [[ 2.4387e-02,  2.8878e-02,  2.0020e-03],\n",
            "          [-1.1942e-02,  2.0614e-02,  1.0720e-02],\n",
            "          [ 7.4163e-03,  2.6590e-02,  2.9533e-02]],\n",
            "\n",
            "         [[ 7.1569e-03, -4.6567e-03, -1.0427e-02],\n",
            "          [ 2.5601e-02, -1.4049e-02,  8.7089e-03],\n",
            "          [-1.6316e-03,  7.6461e-03,  1.5218e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7381e-02,  1.2560e-02,  1.6701e-02],\n",
            "          [ 8.2698e-05, -2.6911e-03,  2.9686e-03],\n",
            "          [-1.1666e-02, -7.3656e-03,  1.2869e-02]],\n",
            "\n",
            "         [[ 2.4430e-02, -2.5554e-02, -1.3683e-02],\n",
            "          [ 1.0035e-02, -6.5558e-03,  2.2850e-02],\n",
            "          [ 5.6713e-03, -1.1074e-02, -1.0628e-02]],\n",
            "\n",
            "         [[ 1.4206e-03,  2.0778e-02,  1.9792e-02],\n",
            "          [ 5.3510e-03, -5.3883e-03,  2.2372e-02],\n",
            "          [-1.6173e-02, -1.7749e-03,  1.7928e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9631e-03, -8.0526e-04,  1.1842e-02],\n",
            "          [ 1.2148e-02, -1.1639e-02, -8.3610e-03],\n",
            "          [ 5.7975e-03,  2.7050e-02, -1.0413e-02]],\n",
            "\n",
            "         [[ 8.7739e-03, -1.3032e-02, -1.9663e-02],\n",
            "          [ 5.3679e-03,  2.1750e-02, -2.6829e-02],\n",
            "          [-2.3383e-02,  2.3323e-02,  1.2120e-02]],\n",
            "\n",
            "         [[-1.2223e-02, -2.2271e-02,  2.2342e-02],\n",
            "          [-3.0342e-03,  5.8497e-04,  6.3055e-03],\n",
            "          [ 1.2456e-02,  2.3824e-02, -1.3304e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2245e-02,  8.8892e-03,  2.1146e-02],\n",
            "          [-1.9702e-02,  2.1249e-02, -2.1999e-03],\n",
            "          [ 1.7690e-02, -2.7754e-02,  1.0837e-02]],\n",
            "\n",
            "         [[-1.2289e-02, -2.4489e-02, -1.5391e-02],\n",
            "          [-1.7664e-02, -2.3916e-02, -2.4888e-03],\n",
            "          [ 4.8041e-04,  4.8687e-03,  1.7978e-02]],\n",
            "\n",
            "         [[ 1.3365e-02, -1.3509e-02, -8.0107e-03],\n",
            "          [-1.4518e-02,  2.5511e-02,  2.4985e-02],\n",
            "          [ 2.5245e-02,  2.6879e-02, -3.6078e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.1518e-03, -4.4503e-03,  9.5529e-03],\n",
            "          [ 2.3656e-02, -2.8026e-02,  2.8133e-02],\n",
            "          [ 1.7360e-02, -8.5160e-03, -1.3054e-02]],\n",
            "\n",
            "         [[-1.3972e-02,  2.5621e-02, -2.1764e-02],\n",
            "          [-7.5277e-03,  2.6491e-02, -8.0329e-03],\n",
            "          [-9.2035e-03,  1.8527e-03, -4.2838e-03]],\n",
            "\n",
            "         [[-2.8245e-02,  1.9582e-02, -1.1999e-02],\n",
            "          [ 2.2350e-02,  1.6317e-02,  1.8957e-02],\n",
            "          [ 2.1772e-02, -1.1289e-02, -1.2334e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.9192e-03, -9.6311e-04,  1.8007e-02],\n",
            "          [ 5.3629e-03,  5.1322e-03, -1.8684e-02],\n",
            "          [-1.0416e-02,  2.3973e-02, -1.8183e-02]],\n",
            "\n",
            "         [[ 1.2343e-02,  7.2648e-03,  3.2743e-03],\n",
            "          [ 2.2942e-04, -7.1965e-03, -1.3730e-02],\n",
            "          [ 1.9276e-02,  1.5708e-02, -2.8181e-02]],\n",
            "\n",
            "         [[-2.5657e-03, -2.1232e-02,  1.4455e-04],\n",
            "          [ 1.6988e-02, -1.3211e-02,  1.1876e-02],\n",
            "          [ 7.6742e-03, -2.1808e-02, -1.0328e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 7.9067e-03,  2.2792e-02, -2.6808e-02],\n",
            "          [-2.3473e-02, -2.7417e-02, -1.0541e-02],\n",
            "          [-1.1580e-02, -1.5263e-02, -1.4780e-03]],\n",
            "\n",
            "         [[ 2.1440e-02, -2.8175e-03,  9.2741e-03],\n",
            "          [-2.8658e-02, -2.5073e-02,  8.3999e-03],\n",
            "          [-2.1530e-02, -9.1638e-03,  1.8960e-02]],\n",
            "\n",
            "         [[ 2.3205e-02,  2.4638e-02,  4.6304e-03],\n",
            "          [-1.8149e-02, -6.6935e-03,  5.6853e-03],\n",
            "          [ 1.4219e-02, -1.5986e-02,  1.0893e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3818e-02, -2.0611e-02,  1.9616e-02],\n",
            "          [ 1.4837e-02, -1.0395e-02, -1.6060e-02],\n",
            "          [-5.3150e-03,  1.3469e-02, -1.0401e-02]],\n",
            "\n",
            "         [[ 2.0778e-03, -6.4587e-03, -6.0221e-03],\n",
            "          [-1.4794e-02,  1.8404e-02, -2.1654e-02],\n",
            "          [ 4.1495e-03,  2.5098e-02, -2.0368e-02]],\n",
            "\n",
            "         [[-1.6049e-02, -1.7614e-03,  1.9419e-03],\n",
            "          [ 9.4626e-03, -1.7800e-02,  2.9216e-03],\n",
            "          [ 5.8348e-03, -1.3783e-02, -2.0741e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.0790e-03,  2.1946e-02, -2.0966e-03],\n",
            "          [-2.7831e-02, -1.0217e-02,  2.1227e-02],\n",
            "          [ 1.2735e-02, -8.2551e-03, -1.4865e-02]],\n",
            "\n",
            "         [[ 2.5161e-02,  2.0851e-02, -1.7604e-02],\n",
            "          [ 7.4351e-04,  1.6057e-02,  1.5273e-02],\n",
            "          [ 8.5459e-03,  2.9335e-02, -7.1324e-03]],\n",
            "\n",
            "         [[-2.1365e-03, -8.6062e-03, -2.2526e-02],\n",
            "          [ 1.8741e-02,  6.7064e-03,  2.2748e-02],\n",
            "          [ 1.7926e-02, -2.4214e-02,  2.2466e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2071e-02, -1.3067e-02, -2.4172e-02],\n",
            "          [ 1.4616e-02,  9.0808e-03,  1.9959e-02],\n",
            "          [ 1.2215e-02, -2.5406e-02,  6.5271e-03]],\n",
            "\n",
            "         [[ 1.2494e-02, -3.0438e-03, -1.9072e-02],\n",
            "          [-1.3960e-02,  2.5002e-02, -9.1879e-03],\n",
            "          [ 6.7440e-03,  1.9663e-02, -1.2291e-02]],\n",
            "\n",
            "         [[-2.9465e-02,  5.4590e-03,  2.8087e-02],\n",
            "          [ 1.0924e-03,  2.2378e-02,  4.5673e-03],\n",
            "          [-4.0429e-03,  1.4514e-02, -3.3995e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1973e-02, -2.9234e-02,  4.6785e-03],\n",
            "          [ 9.1624e-03, -2.5956e-02, -2.3088e-02],\n",
            "          [ 9.7766e-03, -1.9501e-02,  1.9286e-03]],\n",
            "\n",
            "         [[-1.4272e-02,  4.0208e-03,  3.1184e-02],\n",
            "          [-3.4467e-03, -2.3840e-03,  7.6245e-03],\n",
            "          [-1.5029e-02, -1.1755e-02,  3.0798e-02]],\n",
            "\n",
            "         [[-1.2900e-02,  2.7231e-02, -1.2489e-02],\n",
            "          [-2.8419e-02,  1.7864e-02,  2.4335e-02],\n",
            "          [-1.6111e-02,  2.9838e-03,  2.7289e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0204e-02,  1.6475e-02, -2.1937e-03],\n",
            "          [ 3.3152e-03, -3.1337e-02, -1.5357e-03],\n",
            "          [ 2.7530e-02, -1.7282e-03,  1.2708e-02]],\n",
            "\n",
            "         [[ 3.0655e-02, -2.2789e-03, -2.6366e-02],\n",
            "          [ 6.1782e-03, -6.3985e-03, -2.5791e-02],\n",
            "          [ 1.8068e-02,  9.5939e-03, -1.1828e-02]],\n",
            "\n",
            "         [[-2.5655e-02,  1.9845e-03, -1.3410e-02],\n",
            "          [ 9.9795e-03,  2.5508e-04, -5.3594e-03],\n",
            "          [ 6.7322e-03, -1.3332e-02, -1.8583e-02]]]])), ('conv5.bias', tensor([ 9.4750e-05,  3.6326e-03,  1.1712e-03, -2.2219e-05, -7.9487e-03,\n",
            "         2.0057e-06,  1.4894e-03,  5.3761e-05,  4.7915e-03,  1.8665e-05,\n",
            "         4.1597e-03, -9.1570e-03, -2.6392e-04,  2.6933e-06, -2.2911e-06,\n",
            "         9.0292e-03,  3.0322e-06, -3.7731e-06,  1.3657e-06,  4.5991e-06,\n",
            "        -6.5682e-03,  4.5125e-03, -5.1324e-03,  5.4452e-03, -2.0320e-05,\n",
            "         7.6700e-03,  3.2971e-03,  4.9364e-03, -4.6678e-03, -7.7653e-04,\n",
            "         9.0489e-04, -2.2744e-03,  3.0652e-06,  4.2795e-05, -4.2375e-06,\n",
            "         5.0924e-03,  2.2532e-04, -9.1608e-03,  9.7352e-03,  4.5962e-03,\n",
            "         5.4311e-04,  5.1475e-03, -3.5067e-05, -8.4214e-03, -3.3453e-05,\n",
            "        -1.3934e-03, -8.1962e-05, -7.2717e-06,  1.5271e-04, -1.3012e-05,\n",
            "         5.4432e-03, -6.3584e-06, -2.3069e-03,  1.1923e-03,  5.5979e-06,\n",
            "         2.3021e-05,  7.8095e-05, -2.7705e-03, -4.8895e-06, -5.4509e-03,\n",
            "        -6.1808e-03,  8.5546e-06,  7.0318e-05, -1.2388e-05,  1.9014e-03,\n",
            "        -9.4332e-03,  6.5791e-06, -4.6382e-04, -7.5027e-06, -1.8989e-03,\n",
            "         5.6376e-07, -1.0522e-03, -4.2736e-03, -3.0643e-05, -1.9017e-04,\n",
            "        -2.7007e-03, -1.1965e-04, -7.3972e-03, -9.2002e-03,  1.4568e-05,\n",
            "        -7.2283e-05, -1.1581e-03, -2.6637e-03, -3.7794e-03,  7.0019e-03,\n",
            "         6.8348e-04, -4.9316e-04, -5.5124e-03,  7.1485e-03,  7.0496e-03,\n",
            "        -3.2831e-06, -2.5855e-03, -1.3385e-05, -4.9494e-06,  1.1326e-05,\n",
            "        -3.6587e-04, -7.7208e-06,  1.8680e-04, -6.2486e-04, -1.7174e-03,\n",
            "         2.9239e-06,  3.7458e-03, -9.0778e-06,  3.3953e-03,  4.0504e-05,\n",
            "        -2.7812e-04,  6.6527e-06,  4.3103e-04,  5.6042e-03, -1.1088e-06,\n",
            "        -1.7121e-05,  8.5631e-03, -2.3243e-05,  2.6768e-06, -2.5741e-04,\n",
            "         6.5966e-03, -6.4212e-03, -5.2469e-07, -4.8954e-03,  2.3528e-04,\n",
            "         5.5382e-03,  5.6626e-03, -7.0493e-03,  6.2590e-03,  1.4148e-03,\n",
            "         1.2556e-05,  7.9785e-04, -4.4830e-06,  5.0799e-03, -6.0472e-07,\n",
            "        -2.2962e-05, -8.6603e-03, -2.2044e-03, -2.0568e-04, -5.5746e-03,\n",
            "        -4.1622e-05,  5.5551e-03,  7.7144e-06,  2.1530e-03, -1.6407e-04,\n",
            "        -1.5511e-05,  3.6806e-03,  6.8472e-03, -2.5201e-04, -7.5666e-06,\n",
            "         8.5068e-03,  9.8334e-03, -1.1607e-04, -8.6977e-03,  4.5871e-05,\n",
            "         4.2881e-03,  2.7808e-05, -9.3843e-03, -7.5337e-05,  1.6766e-03,\n",
            "        -1.6680e-06,  8.5719e-03, -1.7077e-03, -9.5037e-03, -1.0662e-03,\n",
            "         1.3458e-04, -5.6642e-03,  1.0920e-05,  1.0985e-03, -7.0002e-04,\n",
            "         8.0226e-03, -1.8931e-03, -3.5748e-03, -3.6182e-04,  4.0847e-03,\n",
            "         5.7477e-05, -3.9058e-06, -2.7390e-06, -1.0042e-03, -1.7951e-06,\n",
            "        -1.9876e-03, -8.6230e-05,  1.8876e-05,  5.6977e-06,  1.2109e-05,\n",
            "        -1.7374e-07,  3.7629e-06, -4.6291e-05,  7.0088e-06,  8.7627e-03,\n",
            "         5.1002e-04, -4.6094e-03,  2.5872e-05, -4.5950e-03, -7.4071e-05,\n",
            "        -2.9736e-05,  5.4492e-03,  4.1836e-06, -5.1411e-03, -3.4615e-05,\n",
            "         4.4485e-05, -2.0791e-06, -9.6885e-03,  1.0216e-02, -1.2387e-05,\n",
            "        -7.7819e-05,  3.1218e-04, -4.1958e-05,  9.3866e-03, -1.4060e-03,\n",
            "        -8.5547e-07, -6.0751e-03, -4.7497e-03, -5.4597e-03,  8.0244e-03,\n",
            "        -7.4588e-03,  1.2589e-05,  7.4095e-03,  2.5978e-03,  6.5304e-03,\n",
            "        -1.2007e-03,  1.0147e-02, -4.5551e-04,  2.5461e-05, -4.6658e-05,\n",
            "        -7.7806e-03, -3.8964e-04,  5.2952e-03, -2.7152e-05,  6.5113e-03,\n",
            "        -8.2188e-03, -2.0351e-05,  9.4074e-03,  5.3505e-04,  3.4780e-04,\n",
            "        -2.5289e-03, -3.9158e-06, -2.0225e-03,  4.7370e-03, -1.7370e-04,\n",
            "        -5.5121e-04, -9.8101e-03, -1.0594e-03,  2.9591e-03, -3.5340e-03,\n",
            "        -2.2049e-03, -2.4034e-04, -9.5064e-03,  6.4334e-05, -9.2375e-03,\n",
            "        -1.7235e-05,  5.2004e-03,  4.1408e-04, -5.3602e-04, -1.8480e-06,\n",
            "         2.4096e-03,  9.8896e-04, -1.0103e-02,  7.8353e-07,  5.9341e-05,\n",
            "        -4.2604e-04])), ('bn5.weight', tensor([0.9974, 0.9965, 0.9995, 0.9972, 0.9982, 0.9976, 0.9972, 0.9945, 0.9984,\n",
            "        0.9981, 0.9985, 0.9945, 0.9962, 0.9978, 0.9998, 0.9965, 0.9970, 0.9941,\n",
            "        0.9960, 0.9995, 0.9957, 0.9956, 0.9957, 0.9972, 0.9965, 0.9981, 0.9986,\n",
            "        0.9980, 0.9973, 0.9955, 0.9989, 0.9947, 0.9967, 0.9971, 0.9967, 0.9957,\n",
            "        0.9976, 0.9976, 0.9977, 0.9958, 0.9936, 0.9974, 0.9968, 0.9973, 0.9955,\n",
            "        0.9964, 0.9988, 0.9962, 0.9970, 0.9952, 0.9960, 0.9971, 0.9986, 0.9976,\n",
            "        0.9982, 0.9963, 0.9960, 0.9973, 0.9964, 0.9962, 0.9994, 0.9981, 0.9980,\n",
            "        0.9961, 0.9968, 0.9977, 0.9965, 0.9973, 1.0002, 0.9985, 0.9971, 0.9988,\n",
            "        0.9974, 0.9970, 0.9980, 0.9967, 0.9997, 0.9973, 0.9957, 0.9975, 0.9975,\n",
            "        0.9972, 0.9979, 0.9975, 0.9952, 0.9964, 0.9978, 0.9998, 0.9982, 0.9947,\n",
            "        0.9976, 1.0002, 0.9997, 0.9974, 0.9958, 0.9969, 0.9996, 0.9966, 0.9979,\n",
            "        0.9973, 0.9986, 0.9977, 0.9976, 0.9984, 0.9984, 0.9971, 0.9990, 0.9964,\n",
            "        0.9954, 0.9994, 0.9971, 0.9977, 0.9978, 0.9946, 0.9968, 0.9988, 0.9984,\n",
            "        0.9970, 0.9974, 0.9963, 0.9984, 0.9953, 0.9945, 0.9991, 1.0003, 0.9965,\n",
            "        0.9988, 0.9964, 0.9972, 0.9977, 0.9978, 0.9974, 0.9980, 0.9958, 0.9956,\n",
            "        0.9996, 0.9974, 0.9967, 0.9985, 0.9977, 0.9998, 0.9950, 0.9944, 0.9976,\n",
            "        0.9984, 0.9974, 0.9968, 0.9984, 0.9977, 0.9994, 0.9998, 0.9972, 0.9975,\n",
            "        0.9993, 0.9980, 0.9989, 0.9954, 0.9967, 0.9956, 1.0009, 0.9958, 0.9960,\n",
            "        1.0001, 0.9977, 0.9981, 0.9988, 0.9959, 0.9944, 0.9957, 0.9964, 0.9981,\n",
            "        1.0000, 0.9990, 0.9966, 0.9973, 0.9976, 0.9966, 0.9965, 0.9976, 0.9954,\n",
            "        0.9961, 0.9939, 0.9970, 0.9965, 0.9983, 0.9984, 0.9961, 0.9973, 0.9976,\n",
            "        0.9964, 0.9988, 0.9941, 0.9924, 1.0010, 0.9978, 0.9966, 0.9985, 0.9994,\n",
            "        0.9964, 0.9986, 0.9983, 0.9994, 0.9980, 0.9980, 0.9945, 0.9962, 0.9961,\n",
            "        0.9975, 0.9975, 0.9995, 0.9979, 0.9984, 0.9959, 0.9952, 0.9970, 0.9972,\n",
            "        0.9992, 0.9980, 0.9976, 0.9979, 0.9979, 0.9990, 0.9975, 0.9955, 0.9974,\n",
            "        0.9969, 0.9972, 0.9979, 0.9972, 0.9976, 0.9991, 0.9978, 0.9981, 0.9993,\n",
            "        0.9996, 0.9975, 0.9973, 0.9957, 0.9972, 0.9980, 0.9969, 0.9966, 0.9979,\n",
            "        0.9977, 0.9988, 0.9968, 0.9971, 0.9960, 0.9966, 0.9970, 0.9960, 0.9956,\n",
            "        0.9929, 0.9950, 0.9949, 0.9974])), ('bn5.bias', tensor([-1.8287e-03, -3.8247e-03, -6.5928e-05, -2.3437e-03, -9.5324e-04,\n",
            "        -3.8413e-03, -3.0878e-03, -3.6204e-03, -2.2637e-03, -1.9801e-03,\n",
            "        -1.3181e-03, -4.1036e-03, -3.2492e-03, -1.3853e-03, -2.0469e-04,\n",
            "        -3.0955e-03, -3.3819e-03, -5.0607e-03, -3.2952e-03, -1.6480e-03,\n",
            "        -4.0009e-03, -2.4788e-03, -3.2410e-03, -2.5925e-03, -2.1999e-03,\n",
            "        -1.8005e-03, -1.7880e-03, -2.9565e-03, -1.1205e-03, -3.4224e-03,\n",
            "        -2.0716e-03, -4.1565e-03, -3.1764e-03, -2.1549e-03, -1.4884e-03,\n",
            "        -3.5082e-03, -2.7767e-03, -2.4396e-03, -2.3343e-03, -3.0609e-03,\n",
            "        -4.8720e-03, -1.8418e-03, -3.9310e-03, -1.3094e-03, -3.6618e-03,\n",
            "        -3.0075e-03, -9.0845e-04, -2.9095e-03, -2.2910e-03, -4.2090e-03,\n",
            "        -3.4804e-03, -3.2543e-03, -1.0320e-03, -2.5778e-03, -1.9395e-03,\n",
            "        -3.3146e-03, -3.3961e-03, -2.2616e-03, -3.1461e-03, -3.1117e-03,\n",
            "        -1.8650e-03, -2.8519e-03, -1.6003e-03, -2.0158e-03, -2.3285e-03,\n",
            "        -3.6008e-03, -2.7581e-03, -2.5312e-03, -8.3563e-04, -1.9301e-03,\n",
            "        -2.5079e-03, -2.6317e-03, -1.9308e-03, -1.3030e-03, -2.5135e-03,\n",
            "        -2.1193e-03, -2.7105e-04, -2.3072e-03, -3.4945e-03, -3.4169e-03,\n",
            "        -3.2237e-03, -2.4281e-03, -2.0510e-03, -1.7893e-03, -4.2384e-03,\n",
            "        -4.1346e-03, -2.1280e-03, -6.2532e-05, -1.7259e-03, -4.1709e-03,\n",
            "        -1.8654e-03, -8.4365e-04, -1.2927e-03, -3.6346e-04, -2.3556e-03,\n",
            "        -3.2509e-03, -2.0465e-03, -2.8981e-03, -3.2736e-03, -2.3990e-03,\n",
            "        -1.5664e-03, -1.7644e-03, -3.4221e-03, -1.9407e-03, -1.0715e-03,\n",
            "        -1.6654e-03, -6.3779e-04, -2.7843e-03, -4.9034e-03, -1.3993e-03,\n",
            "        -2.7735e-03, -2.5540e-03, -2.0805e-03, -4.2385e-03, -3.4163e-03,\n",
            "        -9.0902e-04, -1.0722e-03, -3.0460e-03, -2.3892e-03, -2.4077e-03,\n",
            "        -2.1882e-03, -3.5095e-03, -5.1922e-03, -1.6833e-03, -1.9994e-03,\n",
            "        -3.3656e-03, -1.6070e-03, -3.0625e-03, -1.7458e-03, -9.6697e-04,\n",
            "        -3.1627e-03, -3.1928e-03, -7.5255e-04, -2.3876e-03, -4.5770e-03,\n",
            "        -1.2717e-03, -2.3559e-03, -3.0263e-03, -2.6553e-03, -1.7569e-03,\n",
            "        -5.0749e-04, -3.1797e-03, -3.7036e-03, -7.6931e-04, -7.0461e-04,\n",
            "        -2.3711e-03, -2.1490e-03, -2.3896e-03, -2.1957e-03, -2.7841e-03,\n",
            "        -6.3869e-04, -2.8707e-03, -2.0116e-03, -1.1749e-03, -2.0287e-03,\n",
            "        -2.1248e-03, -4.1587e-03, -1.8396e-03, -3.6056e-03, -4.9367e-04,\n",
            "        -3.5110e-03, -4.2107e-03, -3.1893e-04, -2.6752e-03, -1.0439e-03,\n",
            "        -9.4995e-04, -2.0667e-03, -4.3106e-03, -5.1592e-03, -2.8404e-03,\n",
            "        -1.1366e-03, -1.5088e-03, -1.9517e-03, -2.4608e-03, -2.2793e-03,\n",
            "        -2.4878e-03, -2.0082e-03, -2.1799e-03, -2.2044e-03, -3.7792e-03,\n",
            "        -4.1462e-03, -4.3669e-03, -4.2527e-03, -3.6165e-03, -2.2825e-03,\n",
            "        -1.4496e-03, -3.8665e-03, -2.9700e-03, -1.6321e-03, -3.6020e-03,\n",
            "        -1.3803e-03, -5.3958e-03, -5.7073e-03, -6.4424e-04, -1.1823e-03,\n",
            "        -2.7766e-03, -1.8430e-03, -1.6109e-03, -2.4762e-03,  6.6693e-05,\n",
            "        -1.0070e-03, -2.0091e-03, -2.0657e-03, -1.7688e-03, -4.5844e-03,\n",
            "        -3.6656e-03, -5.1474e-03, -2.2116e-03, -2.3746e-03, -1.3819e-03,\n",
            "        -3.3422e-03, -9.2918e-04, -3.7805e-03, -3.0683e-03, -1.7333e-03,\n",
            "        -2.6790e-03, -1.2693e-04, -1.9557e-03, -1.8748e-03, -1.3896e-03,\n",
            "        -2.0066e-03, -1.2336e-03, -1.0774e-03, -3.0722e-03, -3.2684e-03,\n",
            "        -2.0771e-03, -3.0497e-03, -2.2405e-03, -2.2968e-03, -3.6879e-03,\n",
            "        -9.1983e-04, -1.7081e-03, -1.2073e-03, -3.6353e-04, -1.6566e-03,\n",
            "        -2.1114e-03, -1.8819e-03, -3.0456e-03, -2.9061e-03, -1.0513e-03,\n",
            "        -2.6651e-03, -2.6580e-03, -1.3670e-03, -2.0363e-03, -8.3124e-04,\n",
            "        -2.4981e-03, -1.9681e-03, -2.9328e-03, -4.2515e-03, -2.8740e-03,\n",
            "        -3.1630e-03, -3.2304e-03, -6.6156e-03, -4.5955e-03, -3.4502e-03,\n",
            "        -3.9900e-03])), ('bn5.running_mean', tensor([ 1.8401e-01,  3.0241e-01,  1.3714e-01, -6.1511e-01, -4.2533e-01,\n",
            "        -2.1306e-01, -5.8109e-01, -1.0276e+00, -4.1574e-03,  1.7563e-01,\n",
            "        -5.1270e-01, -4.2111e-02, -6.7615e-01, -5.1392e-01, -2.3521e-01,\n",
            "        -1.0148e+00,  3.7184e-01, -4.3496e-01,  5.0040e-01,  7.4966e-02,\n",
            "        -7.2089e-01, -4.6300e-01, -1.6367e-01, -2.5981e-01,  1.8772e-01,\n",
            "         3.3555e-01,  3.7976e-02,  9.5547e-02,  2.8512e-01,  2.8146e-02,\n",
            "        -2.2837e-01, -1.0463e-01,  2.9428e-01,  4.7984e-01,  2.9384e-01,\n",
            "         6.0340e-01,  1.3660e-01,  4.3824e-01,  7.7420e-02, -7.0785e-01,\n",
            "        -1.1475e-01,  1.1920e+00, -2.2836e-01,  4.4640e-01, -6.9387e-01,\n",
            "        -7.4283e-01,  3.6231e-01,  6.0234e-01,  2.1115e-01,  3.2406e-01,\n",
            "         3.3468e-01, -8.7510e-02, -1.4127e-01,  5.4056e-01,  6.6582e-01,\n",
            "         1.3341e-02, -1.7703e-01,  1.1936e-01, -9.0816e-01, -2.9467e-02,\n",
            "         4.5839e-02,  1.2200e-01, -8.8436e-01,  2.6027e-01, -2.2132e-01,\n",
            "         8.1906e-02, -8.7764e-01,  3.6875e-01,  1.7913e-01,  3.3790e-01,\n",
            "         1.1808e+00, -1.1456e-01,  1.4844e-01,  5.5576e-02,  6.5372e-01,\n",
            "         1.1815e-01,  3.7137e-02, -7.0146e-01, -4.1261e-01, -8.6169e-02,\n",
            "        -9.4129e-03, -1.2827e-01,  2.1351e-01,  5.2312e-01,  5.2517e-03,\n",
            "         4.4217e-01,  3.3421e-01,  3.2050e-01, -6.4273e-01, -3.7276e-01,\n",
            "         5.0229e-01,  3.8649e-01, -5.6345e-02,  2.5077e-01,  7.6499e-02,\n",
            "         6.3854e-01,  3.8346e-01, -1.7428e-01, -7.9008e-02,  6.1480e-01,\n",
            "        -2.0879e-01,  2.1018e-01,  7.1892e-01,  3.1384e-01,  4.7642e-01,\n",
            "        -4.0962e-01, -1.9306e-02, -5.2277e-01, -4.3675e-01,  4.5548e-01,\n",
            "        -3.4079e-01, -4.0764e-02, -3.9239e-03,  2.2236e-01, -4.2002e-01,\n",
            "         4.1917e-01,  3.4103e-01, -1.3699e-01,  3.2446e-01, -2.8397e-01,\n",
            "         2.5325e-01,  2.6087e-01, -1.9415e-01,  2.8668e-01,  5.2487e-01,\n",
            "        -3.9203e-01,  1.7754e-01, -8.2217e-01,  1.6595e-01,  5.7192e-01,\n",
            "         5.4904e-01, -4.8831e-01,  3.6432e-01,  1.2525e-01, -1.1151e+00,\n",
            "         5.3702e-01, -1.0190e-03, -5.9691e-01,  4.1752e-01,  2.3140e-01,\n",
            "         2.3108e-01, -6.6792e-01,  4.2616e-01,  6.6464e-01,  2.2943e-01,\n",
            "         5.4857e-01,  6.7067e-01,  1.6196e-01, -2.9598e-01,  2.7979e-01,\n",
            "         2.2239e-01, -4.3393e-01, -4.4560e-01, -1.4786e-01,  5.5978e-01,\n",
            "         9.0100e-01, -5.9840e-01,  1.0032e+00, -5.8372e-01,  4.2421e-01,\n",
            "        -8.3296e-01,  4.9859e-01, -1.5312e-01,  1.1354e-01,  7.9486e-01,\n",
            "        -6.5112e-02,  6.5318e-01, -2.1935e-01,  1.0606e-01,  3.9063e-01,\n",
            "         2.3926e-01,  2.8645e-01,  3.1918e-01, -3.4452e-01,  4.2367e-01,\n",
            "         5.8331e-01,  3.0565e-01, -5.9880e-01,  3.3923e-01, -1.4169e-01,\n",
            "         6.0390e-01, -7.6222e-01, -2.3191e-01,  1.3562e-01,  1.9804e-01,\n",
            "        -1.9443e-01,  1.2196e-01, -7.2994e-01,  6.1871e-01, -2.5865e-02,\n",
            "         4.7045e-01, -8.7096e-02, -5.2700e-01, -4.3630e-01,  1.8060e-01,\n",
            "        -6.8138e-01,  2.7089e-01, -5.0230e-01,  6.0613e-01,  3.4544e-01,\n",
            "         5.3424e-02,  1.9755e-01,  1.7276e-01, -6.5285e-01,  6.0904e-02,\n",
            "        -1.8209e-01,  4.7891e-01, -4.0742e-02,  2.2095e-01,  4.1867e-01,\n",
            "        -7.0597e-04,  4.2620e-01, -4.3401e-01, -4.1116e-01,  4.2701e-01,\n",
            "         3.5382e-01,  3.0776e-01, -2.8737e-01,  6.1563e-01,  1.4147e-01,\n",
            "        -3.3822e-01, -4.3798e-01,  4.1893e-01, -7.8581e-01,  2.3683e-01,\n",
            "         1.2273e-01, -4.0260e-01,  3.9173e-01,  1.9343e-01,  9.6065e-01,\n",
            "         3.2916e-01, -1.5962e-01,  8.0069e-02,  4.6675e-01,  5.5187e-02,\n",
            "        -2.2073e-01, -8.2090e-01,  4.5629e-01,  5.8061e-01,  2.2188e-01,\n",
            "         6.5860e-02, -8.4128e-01, -1.3101e-02,  4.7914e-01,  5.0635e-01,\n",
            "         8.4674e-02,  8.5422e-02, -1.1581e+00, -1.5980e-01, -2.8356e-01,\n",
            "         6.1127e-02, -1.0139e+00, -9.3692e-02, -5.9612e-02,  6.3315e-01,\n",
            "         1.0582e-01])), ('bn5.running_var', tensor([0.2894, 0.3685, 0.3950, 0.4093, 0.5083, 0.2577, 0.4603, 1.2523, 0.2365,\n",
            "        0.2391, 0.3995, 0.1591, 0.4381, 0.3820, 0.3652, 1.1144, 0.2587, 0.3946,\n",
            "        0.3105, 0.1514, 0.6290, 0.4842, 0.3030, 0.2613, 0.2323, 0.2234, 0.1737,\n",
            "        0.3138, 0.2128, 0.3315, 0.1707, 0.1633, 0.2215, 0.1801, 0.3045, 0.1655,\n",
            "        0.2839, 0.2063, 0.6748, 0.4860, 0.3224, 0.6787, 0.2923, 0.3596, 0.4961,\n",
            "        0.7362, 0.3975, 0.2597, 0.3624, 0.4121, 0.2348, 0.3932, 0.2001, 0.3259,\n",
            "        0.3440, 0.2199, 0.2510, 0.1502, 0.3621, 0.1199, 0.2061, 0.2129, 0.5775,\n",
            "        0.2807, 0.1819, 0.2226, 0.6862, 0.2426, 0.4369, 0.2947, 0.3615, 0.2702,\n",
            "        0.3706, 0.3734, 0.5115, 0.1894, 0.2993, 0.4219, 0.5259, 0.2469, 0.2914,\n",
            "        0.2777, 0.2776, 0.2825, 0.1969, 0.2643, 0.3575, 0.2279, 0.8277, 0.5644,\n",
            "        0.1994, 0.3715, 0.1841, 0.2710, 0.2999, 0.2927, 0.1538, 0.2166, 0.2771,\n",
            "        0.4085, 0.2736, 0.5945, 0.2286, 0.3916, 0.2178, 0.5644, 0.5408, 0.3720,\n",
            "        0.2556, 0.2630, 0.3414, 0.2259, 0.3752, 0.4954, 0.3480, 0.3468, 0.2942,\n",
            "        0.4022, 0.2937, 0.2998, 0.1911, 0.2540, 0.2380, 0.1758, 0.1627, 0.4093,\n",
            "        0.2427, 0.4987, 0.2156, 0.3758, 0.2615, 0.3648, 0.1813, 0.2672, 0.9081,\n",
            "        0.2358, 0.2116, 0.4311, 0.3162, 0.3368, 0.3537, 0.3823, 0.2473, 0.3652,\n",
            "        0.3130, 0.3435, 0.2034, 0.2226, 0.2737, 0.3146, 0.1666, 0.1977, 0.3358,\n",
            "        0.5577, 0.3000, 0.5490, 0.3665, 0.5448, 0.1948, 0.2275, 0.4252, 0.1551,\n",
            "        0.2371, 0.1663, 0.3921, 0.3981, 0.3593, 0.3294, 0.1486, 0.1701, 0.2688,\n",
            "        0.2982, 0.2513, 0.3639, 0.3585, 0.2724, 0.6325, 0.2847, 0.2887, 0.1696,\n",
            "        0.2614, 0.7070, 0.2048, 0.1965, 0.4694, 0.3001, 0.2712, 0.6433, 0.3059,\n",
            "        0.3504, 0.5701, 0.1210, 0.2407, 0.4053, 0.1848, 0.3514, 0.2100, 0.4546,\n",
            "        0.3898, 0.2596, 0.2856, 0.4028, 0.1819, 0.4074, 0.2437, 0.2556, 0.1609,\n",
            "        0.1878, 0.4464, 0.2767, 0.2514, 0.3707, 0.3517, 0.3139, 0.2826, 0.2393,\n",
            "        0.5809, 0.3174, 0.2981, 0.2437, 0.2673, 0.3518, 0.4375, 0.6000, 0.2572,\n",
            "        0.2857, 0.2650, 0.1902, 0.2078, 0.2136, 0.2442, 0.2050, 0.2924, 0.4820,\n",
            "        0.3966, 0.3254, 0.3802, 0.1629, 0.1884, 0.2481, 0.1647, 0.5846, 0.3466,\n",
            "        0.5034, 0.2082, 0.2753, 0.1731, 0.8072, 0.2922, 0.2924, 0.2040, 0.4393,\n",
            "        0.2662, 0.1820, 0.2387, 0.1891])), ('bn5.num_batches_tracked', tensor(250)), ('fc1.weight', tensor([[-0.0065, -0.0038,  0.0057,  ..., -0.0051,  0.0018,  0.0052],\n",
            "        [-0.0057,  0.0032,  0.0048,  ...,  0.0046,  0.0022, -0.0017],\n",
            "        [ 0.0019,  0.0028, -0.0042,  ..., -0.0017, -0.0020,  0.0033],\n",
            "        ...,\n",
            "        [-0.0004, -0.0035,  0.0006,  ..., -0.0027,  0.0008,  0.0018],\n",
            "        [-0.0047,  0.0030, -0.0011,  ..., -0.0002, -0.0012, -0.0002],\n",
            "        [ 0.0011,  0.0033,  0.0048,  ...,  0.0056,  0.0042,  0.0003]])), ('fc1.bias', tensor([ 5.7265e-03,  5.2300e-03, -1.0545e-03,  9.7954e-05,  1.9475e-03,\n",
            "         2.6977e-03, -2.7327e-03, -4.9640e-03,  1.6446e-03, -1.9228e-03,\n",
            "        -2.0772e-04,  4.3795e-04,  5.5857e-04, -3.4459e-03, -3.0381e-03,\n",
            "         4.3221e-03, -3.1023e-03,  1.8074e-04, -3.3782e-03,  5.1668e-03,\n",
            "         8.0768e-04,  2.2261e-03,  1.6522e-03,  5.0107e-03,  1.7709e-03,\n",
            "        -1.8877e-03,  4.8887e-03,  5.8536e-03, -3.1450e-04,  7.8310e-04,\n",
            "         3.5058e-03,  1.2985e-03, -4.3871e-03, -2.1297e-03, -7.2334e-03,\n",
            "         4.3946e-03,  5.1054e-03, -2.9960e-03,  2.2648e-03, -4.6046e-03,\n",
            "        -2.7186e-03, -3.4321e-04,  5.6847e-03,  4.1862e-03,  1.8346e-03,\n",
            "        -2.7954e-03,  5.1969e-03, -6.8614e-03, -1.6320e-03,  5.7600e-03,\n",
            "        -4.2890e-03,  7.6400e-05, -3.4413e-03, -1.5096e-03, -2.7277e-03,\n",
            "         8.2203e-04, -1.8950e-03, -4.3735e-03,  3.0417e-03,  2.8154e-03,\n",
            "         4.1373e-03, -2.2634e-03,  2.0670e-03, -3.9304e-03])), ('fc2.weight', tensor([[-3.1029e-02, -1.0878e-01,  9.5863e-02,  1.1572e-01,  3.4746e-02,\n",
            "          2.2299e-02, -1.0937e-01,  1.0886e-01,  8.0768e-02, -1.1654e-01,\n",
            "          6.5748e-02,  3.4123e-02, -1.0392e-02, -8.2736e-02,  7.1256e-02,\n",
            "         -1.0447e-01, -1.1641e-01, -7.9605e-02, -6.1098e-02, -7.7550e-02,\n",
            "          9.3881e-02,  6.3483e-02,  6.8077e-02,  1.1907e-01, -1.0593e-01,\n",
            "          4.8058e-02, -6.8018e-03, -9.5126e-02,  8.9097e-03,  6.1491e-02,\n",
            "          1.6684e-02,  5.9649e-02,  3.7929e-03,  8.8394e-02, -8.6588e-02,\n",
            "         -5.9679e-02, -5.7404e-02,  4.7681e-03,  1.2080e-01,  2.6036e-02,\n",
            "          9.1076e-02,  9.1557e-02, -1.0196e-01,  4.6140e-02, -1.1945e-01,\n",
            "         -9.7650e-02,  1.2229e-01,  8.7331e-02, -8.8663e-02,  1.0261e-01,\n",
            "          1.0212e-01, -6.4977e-02, -7.3128e-02, -7.9700e-02,  1.0258e-01,\n",
            "          1.1263e-01,  2.0268e-02, -9.9831e-02,  6.5679e-02,  1.1921e-01,\n",
            "         -7.4226e-03, -3.5836e-02, -1.0317e-01, -8.3557e-02],\n",
            "        [ 8.1239e-02,  8.4603e-02, -3.5543e-02, -4.4525e-02, -1.0459e-01,\n",
            "         -9.7463e-02, -1.0249e-01,  3.2124e-02, -2.4276e-03, -3.9692e-02,\n",
            "          1.9108e-02, -5.3938e-02, -1.0206e-01, -8.1453e-02,  3.0377e-02,\n",
            "          1.3294e-02, -7.6498e-02, -4.0900e-02, -5.1586e-02, -7.5692e-02,\n",
            "          6.3729e-02,  5.6059e-02, -1.1635e-01,  6.1647e-02, -1.1636e-01,\n",
            "          7.4559e-02, -1.1098e-01,  8.6059e-02,  4.2603e-03,  1.0315e-01,\n",
            "         -8.4984e-02,  8.5776e-02,  2.4631e-02,  9.5843e-02,  1.1702e-01,\n",
            "          5.4249e-02,  6.7835e-02,  6.9172e-03,  3.8793e-02,  1.2293e-01,\n",
            "         -6.2543e-02, -8.5224e-02, -6.5167e-02,  8.2824e-02, -1.1510e-02,\n",
            "         -5.2742e-02,  1.1482e-01, -2.5395e-02,  8.9341e-03, -1.1018e-01,\n",
            "         -7.4033e-02,  1.1029e-01,  4.0250e-02,  1.1506e-02,  6.1530e-02,\n",
            "         -6.5939e-02,  7.1225e-02,  8.1057e-02,  6.7375e-03, -5.5643e-02,\n",
            "         -1.0608e-01, -1.1688e-01,  1.7196e-02,  3.4094e-02],\n",
            "        [ 6.5874e-02, -6.7605e-03, -9.4192e-02, -5.5122e-02, -1.0405e-01,\n",
            "         -6.1524e-02, -4.1468e-02,  1.1719e-01,  9.6175e-02,  5.0499e-02,\n",
            "         -5.6754e-02,  2.5679e-02, -1.0772e-02, -9.1508e-02, -6.0077e-02,\n",
            "         -1.0889e-01, -1.0523e-01,  1.0230e-01,  1.0948e-01, -7.4409e-02,\n",
            "         -6.3786e-02,  2.4975e-02,  6.7337e-02,  1.0406e-02, -9.5316e-03,\n",
            "          8.4265e-03,  1.0209e-01,  5.5387e-02,  2.9795e-02, -9.2626e-02,\n",
            "          9.7352e-02,  9.4068e-02, -9.4316e-02,  5.9334e-02, -9.8323e-02,\n",
            "         -5.2018e-02, -1.1053e-01, -3.7245e-02, -1.2990e-02,  9.6867e-02,\n",
            "         -3.9154e-02, -1.0467e-02,  8.2520e-02, -9.2290e-02, -2.1429e-02,\n",
            "          9.7788e-02,  8.0904e-02, -1.2070e-01,  8.3657e-02, -3.1853e-02,\n",
            "         -2.2966e-02,  1.2497e-01,  1.0814e-01, -9.7084e-02,  2.8563e-02,\n",
            "          6.8607e-02,  6.6593e-02,  8.7634e-03,  6.8717e-02, -4.7822e-02,\n",
            "         -7.4507e-03,  4.4236e-02, -6.4788e-02,  1.8905e-02],\n",
            "        [ 4.4447e-02, -9.9382e-02,  7.8327e-02,  4.8107e-02,  5.2614e-02,\n",
            "         -9.5238e-02, -1.2166e-01,  6.0907e-02,  3.8741e-02, -1.0534e-01,\n",
            "         -1.2947e-02,  6.9276e-02, -1.0228e-01,  1.2844e-01, -4.1546e-02,\n",
            "         -5.1318e-02, -1.9651e-02,  4.4755e-02,  5.2009e-02, -1.0186e-01,\n",
            "         -1.2356e-01, -7.0500e-02,  1.2593e-01, -9.2610e-02,  7.7427e-02,\n",
            "          1.1162e-02, -1.7882e-02,  1.1801e-02,  3.9809e-02, -1.4607e-02,\n",
            "          5.1127e-02, -1.1525e-01,  9.4947e-02, -5.4995e-02,  3.6909e-02,\n",
            "          7.3472e-02, -1.0895e-02,  5.0015e-02,  7.4266e-02,  9.8736e-03,\n",
            "         -6.1062e-02,  3.4474e-02, -4.8403e-02,  3.0545e-02, -1.6125e-02,\n",
            "         -1.5138e-02,  7.5133e-02,  5.0236e-02,  9.4555e-02, -9.2909e-02,\n",
            "         -1.0767e-01,  3.3641e-02,  1.0459e-01, -9.3872e-02, -1.8625e-02,\n",
            "         -3.0638e-02,  1.0354e-01,  1.3933e-02,  3.3472e-02,  1.1996e-01,\n",
            "         -1.0398e-01,  9.8818e-02, -3.7139e-02, -6.6565e-02],\n",
            "        [ 4.2181e-02,  8.5328e-02,  5.0331e-02,  6.7862e-02,  1.2396e-01,\n",
            "          1.1693e-01, -1.0871e-01,  3.5373e-02, -7.7726e-02,  6.8575e-02,\n",
            "         -9.2882e-02, -1.6773e-02,  8.9714e-02,  7.8773e-02,  5.3667e-02,\n",
            "         -5.4506e-02, -3.4003e-02, -4.5253e-02,  6.8591e-02, -2.2938e-02,\n",
            "          5.9116e-02,  1.1454e-01,  5.2845e-02, -8.1042e-02, -4.4508e-02,\n",
            "          1.0162e-01, -6.3025e-02, -8.5142e-02,  1.0486e-01, -3.8833e-02,\n",
            "         -8.2199e-02,  7.0973e-02, -3.6043e-02,  6.5987e-02,  3.6043e-02,\n",
            "          9.3324e-02, -1.0160e-01, -3.7415e-02, -4.3922e-02,  4.2543e-02,\n",
            "         -5.1931e-02, -6.5488e-02, -7.6345e-02,  9.6323e-02,  4.4100e-02,\n",
            "          4.8183e-02, -4.9281e-02, -1.1508e-01, -1.1423e-01, -1.0930e-01,\n",
            "          7.9022e-02, -8.0245e-03,  4.1500e-02,  6.8301e-03,  1.8463e-03,\n",
            "          8.0143e-02,  7.1951e-02,  8.8729e-02, -7.2078e-02, -9.6158e-02,\n",
            "          1.5140e-02, -9.6431e-02, -1.0611e-01, -8.9462e-02],\n",
            "        [ 2.0226e-02,  9.4046e-02,  8.6442e-02,  6.9751e-02, -7.1940e-02,\n",
            "          4.2714e-03,  5.6952e-02,  6.1915e-02, -9.0529e-02,  6.4427e-02,\n",
            "         -1.2180e-01, -3.4467e-02,  2.9377e-03,  1.1182e-01, -4.8534e-02,\n",
            "          4.1135e-02,  5.6779e-02, -1.1025e-01, -1.9339e-02,  1.1672e-01,\n",
            "         -5.6215e-02,  7.9130e-02, -9.9040e-02, -7.9380e-02,  1.5834e-02,\n",
            "          1.1965e-01, -1.1495e-01, -2.4648e-02, -1.2530e-01,  3.4797e-02,\n",
            "          7.0671e-02, -2.0513e-02, -1.2072e-01, -3.6085e-02, -4.3129e-03,\n",
            "          3.1901e-02, -5.0004e-02,  4.6917e-02, -4.9564e-02, -8.5478e-02,\n",
            "          2.1202e-02,  8.3745e-02, -7.6166e-02,  9.5847e-03,  5.8391e-02,\n",
            "          7.3150e-02, -2.6907e-02,  9.2137e-05,  1.6890e-02,  5.2439e-02,\n",
            "         -6.3321e-02, -1.0538e-01, -6.1033e-02,  1.2333e-01, -1.0006e-01,\n",
            "         -6.2807e-02,  1.1806e-01, -1.1954e-01, -3.6045e-03, -9.7148e-02,\n",
            "         -3.2984e-02,  2.6717e-02,  1.1193e-01, -1.1129e-01],\n",
            "        [-1.0939e-01,  1.0181e-01, -4.1595e-02, -3.1170e-02,  9.8254e-03,\n",
            "         -2.7369e-04, -5.0940e-02, -3.6434e-03,  5.9800e-03, -6.5373e-02,\n",
            "          1.6976e-02, -1.0681e-01, -6.6533e-02,  2.2876e-02, -5.5616e-02,\n",
            "         -1.6615e-02,  4.0947e-02, -5.5818e-02, -1.1194e-01,  1.4063e-02,\n",
            "          6.3547e-02, -7.5932e-02,  3.0301e-03, -1.0421e-02,  6.7043e-02,\n",
            "         -7.2956e-02,  9.4570e-02, -5.1477e-02,  1.0717e-01,  1.1566e-01,\n",
            "          7.2893e-02, -2.9863e-02,  7.1960e-02,  1.1296e-02, -1.5543e-02,\n",
            "          1.8463e-02,  3.8550e-02, -9.8540e-02, -1.2495e-01, -8.1112e-03,\n",
            "          1.1259e-01, -1.9464e-02, -8.9821e-02, -2.1444e-03, -7.0763e-02,\n",
            "         -7.8908e-02, -8.8941e-02, -6.2377e-02, -3.1140e-02,  1.4755e-02,\n",
            "         -8.2721e-02,  1.0382e-01,  1.1369e-01,  5.7167e-02,  7.6630e-02,\n",
            "          1.0867e-01, -5.2359e-02,  1.9828e-03,  6.1499e-02,  1.7739e-02,\n",
            "          1.7519e-02,  4.4000e-02, -1.0554e-01, -4.2838e-02],\n",
            "        [ 8.5445e-02, -6.6026e-02,  1.0331e-02, -2.6152e-02,  3.4723e-02,\n",
            "          4.2157e-03, -2.6206e-02, -6.4072e-02,  1.0751e-02,  8.3331e-02,\n",
            "         -4.1625e-02, -1.3472e-02, -9.8859e-02,  3.1553e-03, -4.5062e-02,\n",
            "         -6.3815e-02, -6.1319e-02,  2.1343e-02, -1.2441e-01,  5.9767e-02,\n",
            "          6.2358e-02, -8.4640e-02, -4.3122e-03, -8.0313e-02, -7.8861e-03,\n",
            "         -2.2048e-03, -1.0860e-01, -2.5892e-03, -1.0819e-01, -1.1722e-01,\n",
            "         -7.1919e-02, -1.0973e-01, -1.0077e-02,  1.1127e-01, -1.2065e-01,\n",
            "         -1.0429e-01,  8.6299e-02, -1.2124e-01, -9.1728e-02,  9.0959e-02,\n",
            "          1.1314e-01, -1.0440e-01, -8.3273e-02,  1.6939e-02, -5.9606e-02,\n",
            "         -6.1385e-02, -1.1192e-01, -3.0406e-02, -1.8473e-02, -7.4886e-02,\n",
            "          9.3008e-02,  4.9761e-02, -1.0598e-01, -9.2819e-02, -4.5641e-02,\n",
            "         -3.1479e-03,  1.0711e-01,  9.0187e-02, -1.9202e-02, -6.5157e-02,\n",
            "          4.6007e-02,  9.2676e-02, -2.1521e-02,  3.9513e-02],\n",
            "        [ 7.6220e-02, -2.1528e-02, -6.3468e-02, -1.0558e-01,  6.1544e-03,\n",
            "         -8.4919e-02,  3.6162e-02,  5.4765e-02,  8.4519e-02, -9.6115e-02,\n",
            "          8.1553e-02, -6.3521e-02,  3.1538e-02, -6.9310e-02, -1.1660e-01,\n",
            "          9.7970e-02, -1.9933e-02, -5.9426e-02,  9.2802e-02, -1.0621e-01,\n",
            "         -7.1039e-02, -1.4635e-02, -1.3624e-02, -8.2942e-02,  9.4599e-02,\n",
            "         -1.1476e-01,  5.1799e-02,  4.3057e-02,  5.2646e-03, -1.9731e-02,\n",
            "          1.4398e-02, -1.8304e-02,  1.2570e-01,  1.3376e-02,  1.1222e-01,\n",
            "          1.0005e-02, -7.0355e-02, -1.2185e-01,  2.1989e-02, -7.5754e-02,\n",
            "         -6.7821e-02,  1.7564e-02, -1.0335e-01, -5.3837e-02,  2.5828e-03,\n",
            "          7.7316e-02,  7.2263e-02,  7.2565e-02, -7.3825e-02, -5.1997e-02,\n",
            "          4.0554e-03, -8.1732e-02, -5.5008e-02, -7.9327e-02, -1.0596e-01,\n",
            "          9.6347e-02, -3.8414e-02, -6.4234e-03, -1.1967e-01,  4.2982e-02,\n",
            "          7.6946e-02, -1.1225e-01,  8.8611e-02, -6.0228e-02],\n",
            "        [-2.6714e-02,  7.1124e-02,  6.8442e-02,  8.5230e-02,  1.0756e-01,\n",
            "         -8.3719e-02,  7.6225e-02, -4.8122e-02,  1.9834e-02,  1.4474e-02,\n",
            "          1.3774e-02,  5.7895e-02,  8.7746e-02,  8.4606e-02, -8.8247e-02,\n",
            "         -4.3102e-02,  8.9977e-03, -1.1123e-01, -1.5054e-02,  5.3610e-02,\n",
            "          2.9051e-02,  6.0204e-02,  1.0649e-01,  1.1582e-01,  7.2137e-02,\n",
            "         -1.2431e-02, -1.2412e-01,  1.2727e-02, -2.8539e-02, -1.2068e-01,\n",
            "          1.8147e-02,  6.8510e-02, -2.6776e-02,  1.2124e-01,  9.7432e-02,\n",
            "         -9.0703e-02, -5.6534e-02, -1.1839e-01,  8.3793e-02,  2.4471e-02,\n",
            "         -7.1577e-02, -3.9285e-03,  6.9763e-03,  5.4077e-02, -7.0955e-02,\n",
            "          6.8881e-02, -2.4559e-02,  5.9635e-02, -4.1889e-02, -9.9990e-02,\n",
            "         -5.5895e-02,  5.0680e-02, -3.7765e-02,  1.6519e-02,  1.0180e-01,\n",
            "          6.5218e-02, -4.6191e-02, -1.0694e-01,  1.0455e-01, -9.7518e-03,\n",
            "         -4.6365e-02, -1.0970e-01,  4.4623e-02, -1.0697e-01]])), ('fc2.bias', tensor([ 0.0952,  0.0294,  0.0801,  0.0248,  0.0510, -0.0214,  0.0223,  0.0480,\n",
            "        -0.0677,  0.1116]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "703c4d76",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:50:32.649484Z",
          "iopub.status.busy": "2023-04-07T11:50:32.649023Z",
          "iopub.status.idle": "2023-04-07T11:50:52.669256Z",
          "shell.execute_reply": "2023-04-07T11:50:52.667908Z"
        },
        "papermill": {
          "duration": 20.037041,
          "end_time": "2023-04-07T11:50:52.672195",
          "exception": false,
          "start_time": "2023-04-07T11:50:32.635154",
          "status": "completed"
        },
        "tags": [],
        "id": "703c4d76",
        "outputId": "5f7fb647-7cb2-4244-9d3f-82e0a1d0ee97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from signal import signal,SIGPIPE, SIG_DFL\n",
        "signal(SIGPIPE,SIG_DFL)\n",
        "!pip install wandb -qU\n",
        "import wandb\n",
        "!wandb login --relogin 3d199b9bde866b3494cda2f8bb7c7a633c9fdade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path = 'best_model.pth'\n",
        "\n",
        "# Define device properly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Redundant device check (now used properly)\n",
        "device_status = torch.cuda.is_available()\n",
        "dummy_tensor = torch.zeros(1).to(device) * 0  # Now on correct device\n",
        "\n",
        "# Initialize model with proper device placement\n",
        "loaded_model = CNN(3, 10, 16, [7, 5, 5, 3, 3], 64, True, 0.2, 2, 'Mish').to(device)\n",
        "loaded_model.load_state_dict(torch.load(best_model_path, map_location=device))  # Add map_location\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"DA6401_Assignment_2\")\n",
        "\n",
        "# Useless image buffer (never used)\n",
        "image_buffer = [torch.randn(3,32,32).to(device) for _ in range(10)]  # Now on device\n",
        "\n",
        "def generate_predictions(model, data_loader):\n",
        "    model.eval()\n",
        "\n",
        "    # Redundant accuracy tracker\n",
        "    pseudo_acc = 0.0\n",
        "\n",
        "    predictions = []\n",
        "    sample_images = []\n",
        "\n",
        "    # Unused normalization constant\n",
        "    NORM_FACTOR = 255.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        data_iter = iter(data_loader)\n",
        "        batch_idx = 0\n",
        "\n",
        "        # Dummy counter for nothing\n",
        "        warmup_counter = 0\n",
        "\n",
        "        while batch_idx < len(data_loader):\n",
        "            batch, _ = next(data_iter)\n",
        "\n",
        "            # Move data to same device as model\n",
        "            batch = batch.to(device)\n",
        "\n",
        "            # Resize images to ensure uniform size (fix for error)\n",
        "            batch_resized = torch.stack([torchvision.transforms.functional.resize(img, (224, 224)) for img in batch])\n",
        "\n",
        "            # Redundant tensor clone (now on correct device)\n",
        "            batch_copy = batch.clone() * 1.0\n",
        "\n",
        "            # Forward pass\n",
        "            output = model(batch_resized)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "\n",
        "            # Convert to numpy (already on CPU if device is CPU)\n",
        "            pred_labels = predicted.cpu().numpy()\n",
        "\n",
        "            # Create grids (ensure device consistency)\n",
        "            predicted_images = torchvision.utils.make_grid(batch_resized[predicted].cpu())  # Move to CPU for visualization\n",
        "            sample_images.append(torchvision.utils.make_grid(batch_resized.cpu()))\n",
        "\n",
        "            # Useless counter\n",
        "            warmup_counter += batch_idx % 2\n",
        "\n",
        "            predictions.append(predicted_images)\n",
        "            batch_idx += 1\n",
        "\n",
        "    # Dummy grid (unused)\n",
        "    dummy_grid = torchvision.utils.make_grid([torch.zeros_like(p) for p in predictions])\n",
        "\n",
        "    # Create final grids\n",
        "    prediction_grid = torchvision.utils.make_grid(predictions, nrow=3)\n",
        "    sample_grid = torchvision.utils.make_grid(sample_images, nrow=3)\n",
        "\n",
        "    # Redundant normalization (no effect)\n",
        "    prediction_grid = prediction_grid / 255.0 * 255.0\n",
        "\n",
        "    return prediction_grid, sample_grid\n",
        "\n",
        "# Unused parameter analysis\n",
        "param_shapes = [p.shape for p in loaded_model.parameters()]\n",
        "\n",
        "# Generate predictions\n",
        "prediction_grid, sample_grid = generate_predictions(loaded_model, test_loader)\n",
        "\n",
        "# Log to wandb\n",
        "wandb.log({\n",
        "    'Predictions': wandb.Image(prediction_grid),\n",
        "    'Sample Images': wandb.Image(sample_grid)\n",
        "})\n",
        "\n",
        "# Cleanup\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "yoVD_qthFg6D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "001a6394-d27c-4e70-a4b1-2fe170c30d8f"
      },
      "id": "yoVD_qthFg6D",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r 300\n",
            "r 149\n",
            "r 74\n",
            "r 37\n",
            "r 19\n",
            "ok pool5\n",
            "ok flatten\n",
            "10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m088\u001b[0m (\u001b[33mcs22m088-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250404_085330-nczn5tct</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/nczn5tct' target=\"_blank\">good-violet-12</a></strong> to <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/nczn5tct' target=\"_blank\">https://wandb.ai/cs22m088-iit-madras/DA6401_Assignment_2/runs/nczn5tct</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (32x16384 and 25600x64)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e24809a58bd4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Generate predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0mprediction_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# Log to wandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-e24809a58bd4>\u001b[0m in \u001b[0;36mgenerate_predictions\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_resized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-dc727621240d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# Flatten and classify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x16384 and 25600x64)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "be445fb4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:50:52.695381Z",
          "iopub.status.busy": "2023-04-07T11:50:52.695007Z",
          "iopub.status.idle": "2023-04-07T11:50:52.715754Z",
          "shell.execute_reply": "2023-04-07T11:50:52.714604Z"
        },
        "papermill": {
          "duration": 0.033186,
          "end_time": "2023-04-07T11:50:52.717717",
          "exception": false,
          "start_time": "2023-04-07T11:50:52.684531",
          "status": "completed"
        },
        "tags": [],
        "id": "be445fb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa3bc68c-7281-4fc7-afd3-ec6de62c381b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sweep configuration initialized with debug parameters.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "debug_config = {\n",
        "    \"debug\": True,\n",
        "    \"log_level\": \"INFO\",\n",
        "    \"extra_params\": [1, 2, 3]\n",
        "}\n",
        "\n",
        "# Sweep configuration\n",
        "sweep_config = {\n",
        "    \"name\": \"DA6401_Assignment_2\",\n",
        "    \"method\": \"bayes\",\n",
        "    'metric': {\n",
        "        'name': 'val_acc',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    \"parameters\": {\n",
        "\n",
        "        \"optimizer_debug\": {\n",
        "            \"values\": ['adam', 'nadam', 'sgd', 'rmsprop']\n",
        "        },\n",
        "        \"optimizer\": {\n",
        "            \"values\": ['adam', 'nadam', 'sgd']\n",
        "        },\n",
        "\n",
        "        \"activation_debug\": {\n",
        "            \"values\": ['ReLU', 'Softmax']\n",
        "        },\n",
        "        \"activation\": {\n",
        "            \"values\": ['LeakyRelu', 'Selu', 'Gelu', 'Mish']\n",
        "        },\n",
        "\n",
        "        \"batch_size_range\": {\n",
        "            \"min\": 16,\n",
        "            \"max\": 256\n",
        "        },\n",
        "        \"batch_size\": {\n",
        "            \"values\": [32, 64, 128]\n",
        "        },\n",
        "\n",
        "        'learning_rate_debug': {\n",
        "            \"formula\": lambda x: x * 0.1\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            \"values\": [0.001, 0.0001, 0.0003, 0.0005]\n",
        "        },\n",
        "\n",
        "        \"dropout_debug\": {\n",
        "            \"values\": [0.1, 0.4]\n",
        "        },\n",
        "        \"dropout\": {\n",
        "            \"values\": [0, 0.2, 0.3]\n",
        "        },\n",
        "\n",
        "        \"batch_norm_debug\": {\n",
        "            \"default_value\": False\n",
        "        },\n",
        "        \"batch_norm\": {\n",
        "            \"values\": [True, False]\n",
        "        },\n",
        "\n",
        "        \"data_aug_debug\": {\n",
        "            \"enabled_by_default\": True\n",
        "        },\n",
        "        \"data_aug\": {\n",
        "            \"values\": [True, False]\n",
        "        },\n",
        "\n",
        "        'kernel_sizes_debug': {\n",
        "            'values': [[1, 1], [13, 11], [15, 15]]\n",
        "        },\n",
        "        'kernel_sizes': {\n",
        "            'values': [[3, 3, 3, 3, 3], [5, 5, 5, 5, 5], [7, 5, 5, 3, 3], [11, 9, 7, 5, 3]]\n",
        "        },\n",
        "\n",
        "        'filter_multiplier_range': {\n",
        "            'min': 0.1,\n",
        "            'max': 10\n",
        "        },\n",
        "        'filter_multiplier': {\n",
        "            'values': [1, 2, 0.5]\n",
        "        },\n",
        "\n",
        "        'num_filters_range': {\n",
        "            'min': 2,\n",
        "            'max': 32\n",
        "        },\n",
        "        'num_filters': {\n",
        "            'values': [4, 8, 16]\n",
        "        },\n",
        "\n",
        "        \"fc_neurons_debug\": {\n",
        "            \"values\": [16, 256]\n",
        "        },\n",
        "        \"fc_neurons\": {\n",
        "            \"values\": [32, 64, 128]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "print(\"Sweep configuration initialized with debug parameters.\")\n",
        "\n",
        "\n",
        "def opti(model, opt='adam', lr=0.0005):\n",
        "    print(\"in opti\")\n",
        "    if opt == \"sgd\":\n",
        "        opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    elif opt == \"adam\":\n",
        "        opt = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
        "    elif opt == \"nadam\":\n",
        "        opt = optim.NAdam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
        "    print('exit opti')\n",
        "    return opt\n",
        "\n",
        "def calculate_accuracy(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    cost = 0\n",
        "    acc = 0\n",
        "    test_iter = iter(test_loader)\n",
        "    test_idx = 0\n",
        "    with torch.no_grad():\n",
        "        while test_idx < len(test_loader):\n",
        "            images, labels = next(test_iter)\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            cost += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images\n",
        "            del labels\n",
        "            test_idx += 1\n",
        "    acc = 100 * correct / total\n",
        "    cost /= len(test_loader)\n",
        "\n",
        "    return cost, acc\n",
        "\n",
        "def train():\n",
        "\n",
        "    fake_config = {'epochs': 15, 'batch_size': 32}\n",
        "\n",
        "    config_default = {\n",
        "        'epochs': 15,\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'dropout': 0.3,\n",
        "        'batch_norm': True,\n",
        "        'data_aug': True,\n",
        "        'kernel_sizes': [5, 5, 5, 5, 5],\n",
        "        'filter_multiplier': 2,\n",
        "        'num_filters': 16,\n",
        "        \"fc_neurons\": 64\n",
        "    }\n",
        "\n",
        "\n",
        "    wandb.init(project=\"TEMP_PROJECT\")\n",
        "\n",
        "    wandb.init(config=config_default)\n",
        "    c = wandb.config\n",
        "\n",
        "\n",
        "    temp_name = \"nfliter_\" + str(c.num_filters)\n",
        "    temp_name += \"_\" + str(c.optimizer) + \"_ac_\"\n",
        "    temp_name += str(c.activation) + \"_n_\" + str(c.learning_rate)\n",
        "\n",
        "    name = temp_name + \"_bs_\" + str(c.batch_size) + \"_dp_\" + str(c.dropout) + \"_bn_\" + str(c.batch_norm)\n",
        "\n",
        "\n",
        "    init_counter = 0\n",
        "\n",
        "    wandb.init(name=name)\n",
        "\n",
        "    # Retrieve the hyperparameters from the config\n",
        "    lr = c.learning_rate\n",
        "    bs = c.batch_size\n",
        "    epochs = 15\n",
        "    act = c.activation\n",
        "    opt = c.optimizer\n",
        "\n",
        "    dp = c.dropout\n",
        "    bn = c.batch_norm\n",
        "    da = c.data_aug\n",
        "    ks = c.kernel_sizes\n",
        "    fm = c.filter_multiplier\n",
        "    nf = c.num_filters\n",
        "    fc = c.fc_neurons\n",
        "\n",
        "    # Redundant parameter cloning\n",
        "    lr_copy = lr * 1.0\n",
        "    bs_copy = bs + 0\n",
        "\n",
        "    # Load the dataset\n",
        "    train_loader, val_loader, test_loader, classes = load_data(bs, da)\n",
        "\n",
        "    # Useless tensor initialization\n",
        "    dummy_tensor = torch.zeros(1).to(device) * 0\n",
        "\n",
        "    print(\"data loaded ====================================================\")\n",
        "\n",
        "    # Initialize network\n",
        "    model = CNN(in_channels=3, num_class=10, num_filters=nf, kernel_sizes=ks, fc_neurons=fc,\n",
        "                batch_norm=bn, dropout=dp, filter_multiplier=fm, activation=act).to(device)\n",
        "\n",
        "\n",
        "    _ = [p.sum() for p in model.parameters()]\n",
        "\n",
        "    print(\"model ini==============================================================\")\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Fake optimization step\n",
        "    temp_optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "    optimizer = opti(model, opt, lr)\n",
        "    print(\"done\")\n",
        "\n",
        "\n",
        "    loop_flag = True\n",
        "\n",
        "\n",
        "\n",
        "    # Train Network\n",
        "    epoch = 0\n",
        "    while epoch < epochs:\n",
        "        print('epoch enter')\n",
        "        # Set the model to training mode\n",
        "        model.train()\n",
        "\n",
        "        train_iter = iter(train_loader)\n",
        "        batch_idx = 0\n",
        "        while batch_idx < len(train_loader):\n",
        "            data, targets = next(train_iter)\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            del data\n",
        "            del targets\n",
        "            batch_idx += 1\n",
        "\n",
        "        # Calculate the test accuracy\n",
        "        train_loss, train_acc = calculate_accuracy(model, train_loader, criterion)\n",
        "        val_loss, val_acc = calculate_accuracy(model, val_loader, criterion)\n",
        "        test_loss, test_acc = calculate_accuracy(model, test_loader, criterion)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        # Log the metrics to WandB\n",
        "        wandb.log({'epoch': epoch + 1, 'loss': loss.item(), 'train_loss': loss.item(), 'test_loss': test_loss, 'val_loss': val_loss, 'test_acc': test_acc, 'train_acc': train_acc, 'val_acc': val_acc})\n",
        "\n",
        "        epoch += 1\n",
        "\n",
        "    # Save the best model\n",
        "    wandb.save('model.h5')\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "47928aa2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:50:52.735356Z",
          "iopub.status.busy": "2023-04-07T11:50:52.735029Z",
          "iopub.status.idle": "2023-04-07T17:11:27.821419Z",
          "shell.execute_reply": "2023-04-07T17:11:27.820420Z"
        },
        "papermill": {
          "duration": 19235.097974,
          "end_time": "2023-04-07T17:11:27.823909",
          "exception": false,
          "start_time": "2023-04-07T11:50:52.725935",
          "status": "completed"
        },
        "tags": [],
        "id": "47928aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "2cc904b8-58c2-40bb-d01c-8418aa1f1a70"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "CommError",
          "evalue": "Parameter filter_multiplier_range is ambiguous, please specify bounds as both floats (for a float_uniform distribution) or ints (for an int_uniform distribution).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, launch_scheduler, scheduler, obj_id, project, entity, state, prior_runs, template_variable_values)\u001b[0m\n\u001b[1;32m   3365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3366\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_config_and_fill_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/internal/internal_api.py\u001b[0m in \u001b[0;36m_validate_config_and_fill_distribution\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m   3246\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3247\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m   3248\u001b[0m                             \u001b[0;34m\"Parameter {} is ambiguous, please specify bounds as both floats (for a float_\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Parameter filter_multiplier_range is ambiguous, please specify bounds as both floats (for a float_uniform distribution) or ints (for an int_uniform distribution).",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0bcf548d868b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initialize the WandB sweep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DA6401_Assignment_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_sweep.py\u001b[0m in \u001b[0;36msweep\u001b[0;34m(sweep, entity, project, prior_runs)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mwandb_login\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_silent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInternalApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0msweep_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprior_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mhandle_sweep_config_violations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarnings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Create sweep with ID:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweep_id\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: T201\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/apis/internal.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_sweep_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mCommError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/apis/normalize.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Whoa, you found a bug.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/internal/internal_api.py\u001b[0m in \u001b[0;36mupsert_sweep\u001b[0;34m(self, config, controller, launch_scheduler, scheduler, obj_id, project, entity, state, prior_runs, template_variable_values)\u001b[0m\n\u001b[1;32m   3364\u001b[0m         \u001b[0mmutations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmutation_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutation_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3366\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_config_and_fill_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3368\u001b[0m         \u001b[0;31m# Silly, but attr-dicts like EasyDicts don't serialize correctly to yaml.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/internal/internal_api.py\u001b[0m in \u001b[0;36m_validate_config_and_fill_distribution\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m   3245\u001b[0m                         \u001b[0mparameter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"distribution\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"uniform\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3246\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3247\u001b[0;31m                         raise ValueError(\n\u001b[0m\u001b[1;32m   3248\u001b[0m                             \u001b[0;34m\"Parameter {} is ambiguous, please specify bounds as both floats (for a float_\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3249\u001b[0m                             \"uniform distribution) or ints (for an int_uniform distribution).\".format(\n",
            "\u001b[0;31mCommError\u001b[0m: Parameter filter_multiplier_range is ambiguous, please specify bounds as both floats (for a float_uniform distribution) or ints (for an int_uniform distribution)."
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the WandB sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project='DA6401_Assignment_2')\n",
        "wandb.agent(sweep_id, function=train,count=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25641c79",
      "metadata": {
        "papermill": {
          "duration": 0.084995,
          "end_time": "2023-04-07T17:11:27.931145",
          "exception": false,
          "start_time": "2023-04-07T17:11:27.846150",
          "status": "completed"
        },
        "tags": [],
        "id": "25641c79"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77dac26f",
      "metadata": {
        "id": "77dac26f"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7393ba6e",
      "metadata": {
        "id": "7393ba6e"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2a699f0",
      "metadata": {
        "id": "d2a699f0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 21165.436974,
      "end_time": "2023-04-07T17:11:30.816189",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-04-07T11:18:45.379215",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}