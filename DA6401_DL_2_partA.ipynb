{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swapnil7-lab/DA6401_Assignment_2/blob/main/DA6401_DL_2_partA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d1706649",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:18:55.180502Z",
          "iopub.status.busy": "2023-04-07T11:18:55.179687Z",
          "iopub.status.idle": "2023-04-07T11:18:58.147235Z",
          "shell.execute_reply": "2023-04-07T11:18:58.146104Z"
        },
        "papermill": {
          "duration": 2.974913,
          "end_time": "2023-04-07T11:18:58.150711",
          "exception": false,
          "start_time": "2023-04-07T11:18:55.175798",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1706649",
        "outputId": "afd1e48a-4f95-48a3-af22-422b486219ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "2.6.0+cu124\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "print(torch.device('cuda:0'))\n",
        "print(torch.__version__)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bfc3bb19",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:18:58.158540Z",
          "iopub.status.busy": "2023-04-07T11:18:58.158066Z",
          "iopub.status.idle": "2023-04-07T11:19:45.932331Z",
          "shell.execute_reply": "2023-04-07T11:19:45.930839Z"
        },
        "papermill": {
          "duration": 47.781297,
          "end_time": "2023-04-07T11:19:45.935224",
          "exception": false,
          "start_time": "2023-04-07T11:18:58.153927",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfc3bb19",
        "outputId": "1fb6acf3-a5a1-43d7-f2bc-25360a7a1ade"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-04 06:34:59--  https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.207, 142.251.175.207, 74.125.24.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3816687935 (3.6G) [application/zip]\n",
            "Saving to: ‘nature_12K.zip’\n",
            "\n",
            "nature_12K.zip      100%[===================>]   3.55G  21.5MB/s    in 2m 58s  \n",
            "\n",
            "2025-04-04 06:37:57 (20.5 MB/s) - ‘nature_12K.zip’ saved [3816687935/3816687935]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://storage.googleapis.com/wandb_datasets/nature_12K.zip'\n",
        "!unzip -q nature_12K.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "edd29c7e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:19:47.710012Z",
          "iopub.status.busy": "2023-04-07T11:19:47.701577Z",
          "iopub.status.idle": "2023-04-07T11:19:48.137919Z",
          "shell.execute_reply": "2023-04-07T11:19:48.136900Z"
        },
        "papermill": {
          "duration": 0.501656,
          "end_time": "2023-04-07T11:19:48.140529",
          "exception": false,
          "start_time": "2023-04-07T11:19:47.638873",
          "status": "completed"
        },
        "tags": [],
        "id": "edd29c7e"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "# Standard library imports\n",
        "import os\n",
        "import random\n",
        "import pathlib\n",
        "\n",
        "# Third-party library imports\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Torchvision imports\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "# Define the device (GPU if available, otherwise CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "# Data Preparation and Transformation\n",
        "def load_data(bs, augment_data=False):\n",
        "    # Configuration parameters\n",
        "    img_size = (300, 300)\n",
        "    norm_mean = (0.5, 0.5, 0.5)\n",
        "    norm_std = (0.5, 0.5, 0.5)\n",
        "\n",
        "    # Base image transformations\n",
        "    base_transform = [\n",
        "        transforms.Resize(img_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(norm_mean, norm_std)\n",
        "    ]\n",
        "\n",
        "    # Augmentation additions\n",
        "    augmentation_layers = [\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10)\n",
        "    ] if augment_data else []\n",
        "\n",
        "    # Create transformation pipelines\n",
        "    train_transforms = transforms.Compose([*augmentation_layers, *base_transform])\n",
        "    test_transforms = transforms.Compose(base_transform)\n",
        "\n",
        "    # Dataset paths configuration\n",
        "    data_root = \"/content/inaturalist_12K\"\n",
        "    train_dir = os.path.join(data_root, 'train')\n",
        "    eval_dir = os.path.join(data_root, 'val')\n",
        "\n",
        "    # Dataset preparation\n",
        "    train_full = ImageFolder(train_dir, transform=train_transforms)\n",
        "    eval_set = ImageFolder(eval_dir, transform=test_transforms)\n",
        "\n",
        "    # Data partitioning\n",
        "    total_train = len(train_full)\n",
        "    val_portion = 0.2\n",
        "    train_samples = int(total_train * (1 - val_portion))\n",
        "    val_samples = total_train - train_samples\n",
        "\n",
        "    # Dataset splitting\n",
        "    train_subset, val_subset = random_split(train_full, [train_samples, val_samples])\n",
        "\n",
        "    # Data loading configuration\n",
        "    loader_config = {\n",
        "        'batch_size': bs,\n",
        "        'num_workers': 2,\n",
        "        'pin_memory': True\n",
        "    }\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_subset, shuffle=True, **loader_config)\n",
        "    val_loader = DataLoader(val_subset, shuffle=False, **loader_config)\n",
        "    test_loader = DataLoader(eval_set, shuffle=False, **loader_config)\n",
        "\n",
        "    # Class label extraction\n",
        "    class_labels = [item.name for item in pathlib.Path(train_dir).iterdir()]\n",
        "    class_labels.sort()\n",
        "\n",
        "    return train_loader, val_loader, test_loader, class_labels\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7c5f5f5b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:19:48.157834Z",
          "iopub.status.busy": "2023-04-07T11:19:48.157506Z",
          "iopub.status.idle": "2023-04-07T11:19:48.181396Z",
          "shell.execute_reply": "2023-04-07T11:19:48.180429Z"
        },
        "papermill": {
          "duration": 0.0347,
          "end_time": "2023-04-07T11:19:48.183608",
          "exception": false,
          "start_time": "2023-04-07T11:19:48.148908",
          "status": "completed"
        },
        "tags": [],
        "id": "7c5f5f5b"
      },
      "outputs": [],
      "source": [
        "#Simple CNN\n",
        "def flatten(k=[11, 9, 7, 5, 3], w=300, s=1, p=1):\n",
        "    r = w\n",
        "    i = 0  # Initialize the counter for the while loop\n",
        "\n",
        "\n",
        "\n",
        "    while i < len(k):  # Loop until the counter reaches the length of k\n",
        "        print(\"r\", r)\n",
        "        r = (r + 2 * p - k[i]) + 1\n",
        "\n",
        "        r = int(r / 2) + 1\n",
        "        i += 1  # Increment the counter\n",
        "\n",
        "    return r\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_class=10, num_filters=4, kernel_sizes=[11,9,7,5,3],\n",
        "                 fc_neurons=64, batch_norm=True, dropout=0.3, filter_multiplier=2, activation='LeakyRelu'):\n",
        "\n",
        "        super(CNN, self).__init__()\n",
        "        # Preserve original parameter assignments\n",
        "        self.in_channels = in_channels\n",
        "        self.num_class = num_class\n",
        "        self.num_filters = num_filters\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.fc_neurons = fc_neurons\n",
        "        self.activation = activation\n",
        "        self.batch_norm = batch_norm\n",
        "        self.dropout = dropout\n",
        "        self.filter_multiplier = filter_multiplier\n",
        "\n",
        "        # Layer construction through systematic pattern\n",
        "        prev_channels = in_channels\n",
        "        for layer_idx in range(len(kernel_sizes)):\n",
        "            # Calculate output channels using exponential growth\n",
        "            out_channels = num_filters * (filter_multiplier ** layer_idx)\n",
        "\n",
        "            # Convolutional block components\n",
        "            setattr(self, f'conv{layer_idx+1}', nn.Conv2d(\n",
        "                prev_channels, out_channels,\n",
        "                kernel_size=kernel_sizes[layer_idx],\n",
        "                stride=1,\n",
        "                padding=1\n",
        "            ).to(device))\n",
        "\n",
        "            if batch_norm:\n",
        "                setattr(self, f'bn{layer_idx+1}', nn.BatchNorm2d(out_channels))\n",
        "\n",
        "            setattr(self, f'relu{layer_idx+1}', nn.LeakyReLU())\n",
        "            setattr(self, f'pool{layer_idx+1}', nn.MaxPool2d(2, 2, padding=1))\n",
        "\n",
        "            prev_channels = out_channels\n",
        "\n",
        "        # Calculate spatial dimension reduction\n",
        "        self.r = flatten(kernel_sizes)\n",
        "        print(\"ok pool5\")\n",
        "        print(\"ok flatten\")\n",
        "        print(self.r)\n",
        "\n",
        "        # Fully connected section with dynamic sizing\n",
        "        final_channels = num_filters * (filter_multiplier ** (len(kernel_sizes)-1))\n",
        "        self.fc1 = nn.Linear(\n",
        "            final_channels * self.r * self.r,\n",
        "            fc_neurons\n",
        "        )\n",
        "        self.relu6 = nn.LeakyReLU()\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(fc_neurons, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Unified processing loop for convolutional blocks\n",
        "        for block_idx in range(1, 6):\n",
        "            x = getattr(self, f'conv{block_idx}')(x)\n",
        "            if self.batch_norm:\n",
        "                x = getattr(self, f'bn{block_idx}')(x)\n",
        "            x = getattr(self, f'relu{block_idx}')(x)\n",
        "            x = getattr(self, f'pool{block_idx}')(x)\n",
        "\n",
        "        # Flatten and classify\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu6(self.fc1(x))\n",
        "        return self.fc2(self.drop(x))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "173205f4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:19:48.200190Z",
          "iopub.status.busy": "2023-04-07T11:19:48.199914Z",
          "iopub.status.idle": "2023-04-07T11:50:32.615877Z",
          "shell.execute_reply": "2023-04-07T11:50:32.614873Z"
        },
        "papermill": {
          "duration": 1844.430252,
          "end_time": "2023-04-07T11:50:32.621794",
          "exception": false,
          "start_time": "2023-04-07T11:19:48.191542",
          "status": "completed"
        },
        "tags": [],
        "id": "173205f4"
      },
      "outputs": [],
      "source": [
        "# Configure device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define hyperparameters\n",
        "in_channels = 3\n",
        "num_class = 10\n",
        "learning_rate = 0.0005\n",
        "batch_size = 64\n",
        "epochs = 1\n",
        "data_aug = True\n",
        "\n",
        "# Load dataset\n",
        "train_loader, val_loader, test_loader, classes = load_data(batch_size, data_aug)\n",
        "print(classes)\n",
        "\n",
        "# Display a batch of training data\n",
        "trainfeature, trainlabel = next(iter(train_loader))\n",
        "print(f\"Feature Batch Shape: {trainfeature.size()}\")\n",
        "print(f\"Label Batch Shape: {trainlabel.size()}\")\n",
        "\n",
        "# Initialize the model\n",
        "model = CNN(in_channels, num_class, 16, [3, 3, 3, 3, 3], 128, False, 0, 2, 'LeakyRelu').to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.NAdam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "\n",
        "# Training loop using while\n",
        "epoch = 0\n",
        "while epoch < epochs:\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    train_iter = iter(train_loader)\n",
        "    batch_idx = 0\n",
        "\n",
        "    while batch_idx < len(train_loader):\n",
        "        # Get the next batch of data and targets\n",
        "        data, targets = next(train_iter)\n",
        "\n",
        "        # Transfer data to the appropriate device\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "        # Zero out gradients from the previous step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass through the model\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # Backward pass and optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_idx += 1\n",
        "\n",
        "    # Evaluation mode for validation/testing\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    test_iter = iter(test_loader)\n",
        "    test_idx = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        while test_idx < len(test_loader):\n",
        "            # Get the next batch of validation/testing data and targets\n",
        "            data, targets = next(test_iter)\n",
        "\n",
        "            # Transfer data to the appropriate device\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass for validation/testing\n",
        "            scores = model(data)\n",
        "            test_loss += criterion(scores, targets).item()\n",
        "\n",
        "            # Calculate predictions and accuracy\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == targets).sum().item()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "            test_idx += 1\n",
        "\n",
        "    # Compute average loss and accuracy for validation/testing\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = num_correct / num_samples\n",
        "\n",
        "    # Print epoch statistics\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {loss.item():.4f}, '\n",
        "          f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc * 100:.2f}%')\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "# Save the best model to a file\n",
        "best_model_path = 'best_model.pth'\n",
        "torch.save(model.state_dict(), best_model_path)\n",
        "print(f\"Best model saved to {best_model_path}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = 3\n",
        "num_class = 10\n",
        "learning_rate = 0.0001\n",
        "batch_size = 32\n",
        "epochs = 1\n",
        "data_aug = False\n",
        "\n",
        "# Load data\n",
        "train_loader, val_loader, test_loader, classes = load_data(batch_size, data_aug)\n",
        "print(classes)\n",
        "trainfeature, trainlabel = next(iter(train_loader))\n",
        "print(f\"Feature Batch Shape: {trainfeature.size()}\")\n",
        "print(f\"Label Batch Shape: {trainlabel.size()}\")\n",
        "\n",
        "# Initialize network\n",
        "model = CNN(3, 10, 16, [7, 5, 5, 3, 3], 64, True, 0.2, 2, 'Mish').to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.NAdam(model.parameters(), lr=learning_rate, weight_decay=0.0001)\n",
        "\n",
        "# Train Network with while loops\n",
        "epoch = 0\n",
        "while epoch < epochs:\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Training loop\n",
        "    batch_idx = 0\n",
        "    train_iter = iter(train_loader)\n",
        "    while batch_idx < len(train_loader):\n",
        "        data, targets = next(train_iter)\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_idx += 1\n",
        "\n",
        "    # Evaluation phase\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "\n",
        "    # Validation loop\n",
        "    test_iter = iter(test_loader)\n",
        "    test_idx = 0\n",
        "    with torch.no_grad():\n",
        "        while test_idx < len(test_loader):\n",
        "            data, targets = next(test_iter)\n",
        "            data = data.to(device=device)\n",
        "            targets = targets.to(device=device)\n",
        "\n",
        "            scores = model(data)\n",
        "            test_loss += criterion(scores, targets).item()\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == targets).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "            test_idx += 1\n",
        "\n",
        "    # Calculate metrics\n",
        "    test_loss /= len(test_loader)\n",
        "    test_acc = float(num_correct) / num_samples\n",
        "\n",
        "    # Print progress\n",
        "    print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}, Test Acc: {:.2f}%'\n",
        "          .format(epoch+1, epochs, loss.item(), test_loss, test_acc*100))\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "# Save model\n",
        "best_model_path = 'best_model.pth'\n",
        "torch.save(model.state_dict(), best_model_path)\n",
        "print(f\"Best model saved to {best_model_path}\")\n"
      ],
      "metadata": {
        "id": "Uu9Xrbjq55Io",
        "collapsed": true
      },
      "id": "Uu9Xrbjq55Io",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#loading the best model and testing it on Test Data\n",
        "best_model_path = 'best_model.pth'\n",
        "vector = [i**2 for i in range(100)]\n",
        "loaded_model = CNN(3,10,16,[7,5,5,3,3],64,True,0.2,2,'Mish').to(device)\n",
        "loaded_model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "\n",
        "usum = sum(vector) * 0\n",
        "\n",
        "def calculate_accuracy(model, test_loader,criterion):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    cost=0\n",
        "    acc=0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        loader_iter = iter(test_loader)\n",
        "        batch_idx = 0\n",
        "\n",
        "\n",
        "        batch_tracker = []\n",
        "\n",
        "        while batch_idx < len(test_loader):\n",
        "            images, labels = next(loader_iter)\n",
        "\n",
        "\n",
        "            images = images * 1.0\n",
        "\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            cost +=criterion(outputs,labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "            temp_correct = (predicted == labels).sum().item()\n",
        "            correct += temp_correct\n",
        "\n",
        "\n",
        "            batch_tracker.append(batch_idx % 2)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            del images\n",
        "            del labels\n",
        "            batch_idx += 1\n",
        "\n",
        "\n",
        "    useless_norm = sum(batch_tracker) / (len(batch_tracker) + 1e-7)\n",
        "\n",
        "    acc=100 * correct / total\n",
        "    cost/=len(test_loader)\n",
        "\n",
        "    return cost,acc\n",
        "\n",
        "\n",
        "param_copy = [p.clone() for p in loaded_model.parameters()]\n",
        "\n",
        "loss,acc=calculate_accuracy(loaded_model,test_loader,nn.CrossEntropyLoss())\n",
        "\n",
        "\n",
        "debug_str = f\"Loss: {loss} Acc: {acc}\".upper()\n",
        "\n",
        "print(loss,acc)\n",
        "print(loaded_model.state_dict())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DlB9WFER0we3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "75bb8de8-fb9b-45a9-96aa-c2a8e6c3d60b"
      },
      "id": "DlB9WFER0we3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r 300\n",
            "r 149\n",
            "r 74\n",
            "r 37\n",
            "r 19\n",
            "ok pool5\n",
            "ok flatten\n",
            "10\n",
            "2.0312375360065036 28.25\n",
            "OrderedDict([('conv1.weight', tensor([[[[ 0.0489, -0.0046,  0.0249,  ...,  0.0324,  0.0369,  0.0382],\n",
            "          [-0.0174,  0.0136, -0.0417,  ...,  0.0067, -0.0734,  0.0407],\n",
            "          [ 0.0035, -0.0496, -0.0752,  ...,  0.0643, -0.0685, -0.0767],\n",
            "          ...,\n",
            "          [ 0.0439, -0.0659,  0.0008,  ...,  0.0147, -0.0175,  0.0061],\n",
            "          [ 0.0108, -0.0722,  0.0017,  ...,  0.0225,  0.0725, -0.0490],\n",
            "          [-0.0753, -0.0208, -0.0731,  ..., -0.0481, -0.0544,  0.0774]],\n",
            "\n",
            "         [[-0.0225,  0.0588,  0.0021,  ..., -0.0573,  0.0289, -0.0367],\n",
            "          [-0.0752,  0.0487,  0.0812,  ..., -0.0664, -0.0372, -0.0489],\n",
            "          [ 0.0547,  0.0271,  0.0757,  ...,  0.0547, -0.0706, -0.0158],\n",
            "          ...,\n",
            "          [ 0.0416, -0.0558,  0.0416,  ...,  0.0587, -0.0748, -0.0597],\n",
            "          [ 0.0079,  0.0097, -0.0092,  ..., -0.0505, -0.0573,  0.0786],\n",
            "          [-0.0387, -0.0283,  0.0300,  ...,  0.0412,  0.0319,  0.0635]],\n",
            "\n",
            "         [[ 0.0690, -0.0140, -0.0406,  ...,  0.0797,  0.0561, -0.0652],\n",
            "          [-0.0710, -0.0415, -0.0092,  ..., -0.0466, -0.0146, -0.0069],\n",
            "          [ 0.0556, -0.0651, -0.0716,  ..., -0.0137, -0.0732,  0.0599],\n",
            "          ...,\n",
            "          [-0.0158, -0.0314, -0.0174,  ...,  0.0682,  0.0508, -0.0758],\n",
            "          [ 0.0177, -0.0062,  0.0297,  ...,  0.0678,  0.0142,  0.0022],\n",
            "          [ 0.0209,  0.0369, -0.0714,  ..., -0.0629,  0.0590, -0.0066]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0549,  0.0415, -0.0739,  ..., -0.0180, -0.0650,  0.0067],\n",
            "          [-0.0653, -0.0704, -0.0491,  ..., -0.0102,  0.0776, -0.0049],\n",
            "          [ 0.0797, -0.0484,  0.0713,  ..., -0.0087, -0.0358,  0.0349],\n",
            "          ...,\n",
            "          [-0.0099,  0.0512, -0.0756,  ..., -0.0389, -0.0469, -0.0434],\n",
            "          [-0.0035,  0.0398,  0.0546,  ...,  0.0187,  0.0064, -0.0296],\n",
            "          [ 0.0405,  0.0390,  0.0624,  ..., -0.0176, -0.0178,  0.0250]],\n",
            "\n",
            "         [[ 0.0028,  0.0189,  0.0728,  ...,  0.0424,  0.0307, -0.0558],\n",
            "          [-0.0550, -0.0673, -0.0420,  ..., -0.0676,  0.0292, -0.0362],\n",
            "          [-0.0821, -0.0713, -0.0031,  ...,  0.0298,  0.0701,  0.0017],\n",
            "          ...,\n",
            "          [-0.0664, -0.0336, -0.0634,  ...,  0.0251, -0.0602,  0.0193],\n",
            "          [-0.0323,  0.0167, -0.0372,  ...,  0.0237,  0.0430,  0.0768],\n",
            "          [-0.0048, -0.0365,  0.0025,  ..., -0.0819, -0.0512,  0.0040]],\n",
            "\n",
            "         [[ 0.0002,  0.0700,  0.0528,  ...,  0.0710,  0.0675, -0.0232],\n",
            "          [ 0.0022, -0.0225, -0.0611,  ...,  0.0621, -0.0701, -0.0820],\n",
            "          [ 0.0272, -0.0575,  0.0455,  ..., -0.0051,  0.0720, -0.0486],\n",
            "          ...,\n",
            "          [-0.0381,  0.0814, -0.0479,  ..., -0.0266,  0.0155,  0.0187],\n",
            "          [ 0.0713,  0.0469, -0.0819,  ...,  0.0517,  0.0195,  0.0724],\n",
            "          [-0.0678,  0.0198,  0.0419,  ...,  0.0590,  0.0492,  0.0231]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243, -0.0347, -0.0708,  ..., -0.0178, -0.0649,  0.0782],\n",
            "          [ 0.0060, -0.0397,  0.0563,  ...,  0.0596, -0.0422, -0.0114],\n",
            "          [-0.0504,  0.0643, -0.0423,  ...,  0.0247,  0.0775,  0.0522],\n",
            "          ...,\n",
            "          [-0.0803,  0.0778,  0.0602,  ..., -0.0777, -0.0221, -0.0059],\n",
            "          [-0.0819,  0.0586, -0.0027,  ..., -0.0244,  0.0262, -0.0472],\n",
            "          [ 0.0221, -0.0044,  0.0754,  ..., -0.0721,  0.0006, -0.0776]],\n",
            "\n",
            "         [[ 0.0588, -0.0198,  0.0560,  ...,  0.0009, -0.0061, -0.0704],\n",
            "          [ 0.0063,  0.0063, -0.0366,  ..., -0.0382, -0.0784, -0.0360],\n",
            "          [ 0.0193,  0.0517, -0.0104,  ..., -0.0125, -0.0266, -0.0451],\n",
            "          ...,\n",
            "          [-0.0263, -0.0426,  0.0607,  ..., -0.0579, -0.0375, -0.0625],\n",
            "          [ 0.0757, -0.0474,  0.0243,  ..., -0.0457,  0.0792, -0.0343],\n",
            "          [ 0.0228,  0.0554, -0.0098,  ..., -0.0525, -0.0807, -0.0667]],\n",
            "\n",
            "         [[-0.0211,  0.0414, -0.0146,  ...,  0.0023,  0.0042, -0.0493],\n",
            "          [ 0.0595, -0.0651,  0.0132,  ..., -0.0551, -0.0421,  0.0147],\n",
            "          [ 0.0333,  0.0711, -0.0553,  ...,  0.0686,  0.0405, -0.0312],\n",
            "          ...,\n",
            "          [-0.0686, -0.0808,  0.0519,  ...,  0.0184, -0.0809, -0.0834],\n",
            "          [ 0.0757,  0.0385, -0.0065,  ...,  0.0675, -0.0666,  0.0019],\n",
            "          [ 0.0359,  0.0355,  0.0704,  ..., -0.0622,  0.0641,  0.0522]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0629,  0.0661,  0.0760,  ..., -0.0342,  0.0371,  0.0179],\n",
            "          [ 0.0765,  0.0509,  0.0769,  ..., -0.0785, -0.0423, -0.0713],\n",
            "          [ 0.0064, -0.0317,  0.0628,  ..., -0.0419, -0.0787, -0.0608],\n",
            "          ...,\n",
            "          [-0.0461, -0.0610,  0.0634,  ..., -0.0382, -0.0720,  0.0778],\n",
            "          [ 0.0424,  0.0164,  0.0361,  ..., -0.0366,  0.0079,  0.0530],\n",
            "          [ 0.0440, -0.0659,  0.0167,  ...,  0.0320,  0.0674,  0.0410]],\n",
            "\n",
            "         [[-0.0158,  0.0269, -0.0443,  ...,  0.0524, -0.0352, -0.0208],\n",
            "          [-0.0724,  0.0284,  0.0539,  ..., -0.0533,  0.0768,  0.0749],\n",
            "          [-0.0252, -0.0119, -0.0827,  ..., -0.0646, -0.0774, -0.0807],\n",
            "          ...,\n",
            "          [-0.0374, -0.0450, -0.0503,  ...,  0.0005,  0.0464, -0.0579],\n",
            "          [-0.0397,  0.0188,  0.0630,  ..., -0.0178,  0.0551,  0.0036],\n",
            "          [ 0.0766,  0.0731,  0.0040,  ...,  0.0082, -0.0111,  0.0529]],\n",
            "\n",
            "         [[ 0.0680, -0.0073, -0.0807,  ..., -0.0142, -0.0280, -0.0405],\n",
            "          [ 0.0775,  0.0360,  0.0514,  ..., -0.0415,  0.0333, -0.0639],\n",
            "          [ 0.0287, -0.0547,  0.0646,  ...,  0.0484,  0.0612, -0.0566],\n",
            "          ...,\n",
            "          [-0.0602, -0.0409, -0.0341,  ...,  0.0055,  0.0079, -0.0128],\n",
            "          [ 0.0302,  0.0229, -0.0135,  ..., -0.0699, -0.0676, -0.0387],\n",
            "          [-0.0495,  0.0141,  0.0269,  ...,  0.0072,  0.0406,  0.0206]]],\n",
            "\n",
            "\n",
            "        [[[-0.0750,  0.0361,  0.0652,  ..., -0.0503, -0.0576, -0.0099],\n",
            "          [ 0.0483,  0.0432,  0.0135,  ...,  0.0237, -0.0003,  0.0019],\n",
            "          [ 0.0411,  0.0115, -0.0277,  ...,  0.0764,  0.0685, -0.0603],\n",
            "          ...,\n",
            "          [-0.0593, -0.0649,  0.0468,  ..., -0.0209,  0.0423, -0.0297],\n",
            "          [ 0.0359,  0.0815,  0.0082,  ..., -0.0753,  0.0673, -0.0081],\n",
            "          [-0.0139, -0.0541, -0.0189,  ..., -0.0041,  0.0140,  0.0189]],\n",
            "\n",
            "         [[ 0.0220,  0.0202,  0.0670,  ...,  0.0563,  0.0398,  0.0243],\n",
            "          [-0.0518, -0.0144, -0.0219,  ...,  0.0368, -0.0355, -0.0824],\n",
            "          [-0.0195, -0.0501, -0.0472,  ...,  0.0527,  0.0218, -0.0182],\n",
            "          ...,\n",
            "          [-0.0497, -0.0453,  0.0702,  ...,  0.0280,  0.0345,  0.0270],\n",
            "          [-0.0463, -0.0374,  0.0259,  ..., -0.0168, -0.0606,  0.0833],\n",
            "          [ 0.0125, -0.0198,  0.0714,  ..., -0.0504, -0.0767,  0.0459]],\n",
            "\n",
            "         [[ 0.0744,  0.0602,  0.0016,  ...,  0.0194,  0.0505, -0.0262],\n",
            "          [-0.0823, -0.0772, -0.0533,  ...,  0.0371,  0.0246, -0.0272],\n",
            "          [-0.0461, -0.0431,  0.0308,  ..., -0.0232, -0.0797, -0.0733],\n",
            "          ...,\n",
            "          [-0.0773, -0.0340, -0.0294,  ...,  0.0554, -0.0560, -0.0664],\n",
            "          [-0.0607,  0.0735, -0.0791,  ..., -0.0623,  0.0749, -0.0302],\n",
            "          [ 0.0759,  0.0572, -0.0242,  ..., -0.0288,  0.0383,  0.0447]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0482,  0.0644, -0.0615,  ...,  0.0220, -0.0354, -0.0627],\n",
            "          [ 0.0414, -0.0651, -0.0359,  ...,  0.0405,  0.0435,  0.0632],\n",
            "          [-0.0125, -0.0626,  0.0426,  ...,  0.0691, -0.0348, -0.0748],\n",
            "          ...,\n",
            "          [ 0.0048, -0.0713,  0.0424,  ...,  0.0265, -0.0390, -0.0351],\n",
            "          [ 0.0585,  0.0592, -0.0192,  ..., -0.0628,  0.0684,  0.0668],\n",
            "          [ 0.0055, -0.0370, -0.0091,  ..., -0.0453, -0.0434,  0.0061]],\n",
            "\n",
            "         [[ 0.0832, -0.0171,  0.0318,  ...,  0.0663,  0.0402, -0.0739],\n",
            "          [-0.0090, -0.0101,  0.0337,  ...,  0.0097, -0.0305, -0.0240],\n",
            "          [ 0.0169, -0.0091,  0.0496,  ..., -0.0555, -0.0603,  0.0207],\n",
            "          ...,\n",
            "          [ 0.0065, -0.0248,  0.0314,  ..., -0.0364,  0.0335, -0.0612],\n",
            "          [ 0.0056, -0.0760,  0.0012,  ..., -0.0335, -0.0258, -0.0807],\n",
            "          [ 0.0527,  0.0206, -0.0649,  ..., -0.0771, -0.0261,  0.0499]],\n",
            "\n",
            "         [[-0.0320,  0.0457,  0.0686,  ...,  0.0618, -0.0203, -0.0392],\n",
            "          [-0.0560, -0.0582, -0.0255,  ..., -0.0103,  0.0100, -0.0522],\n",
            "          [-0.0494,  0.0626, -0.0293,  ..., -0.0026,  0.0189,  0.0558],\n",
            "          ...,\n",
            "          [ 0.0380,  0.0735,  0.0436,  ...,  0.0291, -0.0564, -0.0620],\n",
            "          [-0.0820,  0.0676,  0.0687,  ...,  0.0402, -0.0609,  0.0228],\n",
            "          [ 0.0671,  0.0668, -0.0036,  ...,  0.0819, -0.0424,  0.0789]]]])), ('conv1.bias', tensor([ 0.0214, -0.0331, -0.0577, -0.0425, -0.0085,  0.0582, -0.0746, -0.0279,\n",
            "         0.0734,  0.0758, -0.0661,  0.0455,  0.0055, -0.0368,  0.0210,  0.0070])), ('bn1.weight', tensor([1.0028, 0.9988, 0.9984, 0.9989, 0.9990, 0.9996, 1.0005, 1.0009, 1.0006,\n",
            "        0.9989, 0.9992, 1.0012, 0.9952, 0.9990, 1.0000, 1.0007])), ('bn1.bias', tensor([ 2.0405e-03,  5.1471e-03, -2.8476e-03,  9.5804e-04, -1.3983e-03,\n",
            "        -1.6831e-03, -3.6626e-04,  1.4747e-03,  8.3031e-05, -2.1136e-03,\n",
            "         1.1154e-04, -7.6685e-04, -1.8637e-03,  7.1525e-05,  6.7159e-03,\n",
            "        -2.2623e-04])), ('bn1.running_mean', tensor([ 0.0258, -0.0804, -0.0272, -0.2079, -0.1531,  0.0999,  0.0371, -0.0768,\n",
            "         0.0432,  0.0056, -0.1872,  0.1500,  0.0118, -0.0440,  0.0208,  0.0803])), ('bn1.running_var', tensor([0.0128, 0.0162, 0.0770, 0.2242, 0.1474, 0.0188, 0.0698, 0.0207, 0.0724,\n",
            "        0.0357, 0.0834, 0.1315, 0.0221, 0.0316, 0.0090, 0.0970])), ('bn1.num_batches_tracked', tensor(250)), ('conv2.weight', tensor([[[[-4.2618e-02, -2.3059e-02,  4.9872e-02, -1.2457e-02,  2.1956e-02],\n",
            "          [ 7.5258e-03,  8.4295e-03, -3.0585e-02, -1.8190e-02,  6.7912e-03],\n",
            "          [ 1.4476e-02, -9.3604e-04, -2.1166e-02, -3.6469e-02,  2.1034e-02],\n",
            "          [ 3.0566e-02, -4.9894e-02, -2.0294e-02,  2.1529e-02,  3.7426e-02],\n",
            "          [ 3.1400e-02, -3.2272e-02, -2.8071e-02,  3.1972e-03, -1.4193e-02]],\n",
            "\n",
            "         [[ 3.4725e-02, -2.0950e-02, -5.1332e-04, -3.5005e-02,  1.7882e-02],\n",
            "          [-4.4090e-02, -2.3251e-02, -3.9170e-02, -8.8106e-03,  4.1212e-02],\n",
            "          [-3.4469e-02, -1.6766e-02, -3.4811e-02, -1.9827e-02, -4.4831e-02],\n",
            "          [ 2.6240e-02,  5.0084e-02,  4.6174e-03, -3.8116e-02, -4.2510e-02],\n",
            "          [-4.2459e-02, -4.5735e-02, -1.4723e-02, -2.8923e-02, -3.6983e-02]],\n",
            "\n",
            "         [[ 3.2243e-02,  1.3482e-02,  4.3298e-02, -4.5800e-02, -1.6879e-02],\n",
            "          [ 2.4598e-02, -3.0296e-02, -4.7753e-02, -1.2383e-04,  4.3035e-02],\n",
            "          [ 1.2790e-02,  2.1897e-02, -8.9338e-03,  2.3654e-02,  2.9396e-02],\n",
            "          [ 7.8113e-03, -2.8560e-03,  1.8202e-02,  6.3493e-03,  8.0041e-03],\n",
            "          [ 2.0998e-02, -4.3994e-02,  2.9918e-02,  2.5535e-02, -2.7966e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.4455e-02,  2.7982e-02,  2.6751e-03, -1.0287e-02,  2.1952e-02],\n",
            "          [ 4.6427e-02,  4.9300e-02, -3.5941e-02,  5.0428e-02,  1.9973e-02],\n",
            "          [ 1.8609e-03,  5.1037e-02, -1.8798e-02, -4.5711e-02,  2.9673e-02],\n",
            "          [ 4.5249e-02, -9.7773e-03,  3.2926e-02, -3.7423e-02,  5.1718e-03],\n",
            "          [ 3.9670e-02,  4.4063e-02,  2.3495e-02,  3.9122e-02, -1.3827e-02]],\n",
            "\n",
            "         [[ 1.0284e-02, -4.3472e-02, -1.6858e-02, -5.5794e-03,  4.5500e-02],\n",
            "          [ 1.6752e-02,  1.1551e-02,  3.9627e-03, -1.2451e-02, -2.3262e-02],\n",
            "          [-3.7961e-02,  2.7163e-02,  4.4298e-02, -1.5831e-02, -8.4541e-03],\n",
            "          [ 1.3220e-02,  1.9218e-02,  2.6734e-02, -1.7724e-02, -3.4203e-03],\n",
            "          [ 2.7247e-02, -3.6802e-02, -3.9497e-02, -9.9944e-03, -4.8242e-02]],\n",
            "\n",
            "         [[-2.5307e-02, -7.7342e-03, -2.0578e-02,  2.9970e-02, -2.8364e-02],\n",
            "          [ 2.9087e-02, -3.8898e-02, -3.4491e-02, -1.4250e-02, -2.7455e-02],\n",
            "          [-1.9630e-02,  1.3569e-02, -1.9036e-02,  2.2928e-02, -2.9968e-02],\n",
            "          [ 1.4561e-02,  4.3782e-02,  3.1171e-02, -2.0890e-02,  3.1840e-02],\n",
            "          [-5.6932e-03,  5.2880e-03,  4.3872e-02, -3.5545e-02, -1.3115e-03]]],\n",
            "\n",
            "\n",
            "        [[[-6.7509e-03,  2.0417e-03, -3.4966e-02,  1.2582e-03,  3.3293e-03],\n",
            "          [-3.9144e-02, -8.5864e-03,  3.9451e-02,  1.2148e-02,  1.5556e-02],\n",
            "          [ 4.5807e-02,  3.7283e-02, -3.3903e-03,  3.0417e-02,  4.4803e-02],\n",
            "          [-3.9666e-02,  4.3300e-02,  9.2531e-03, -1.9921e-02,  1.5023e-02],\n",
            "          [ 1.4549e-03, -7.7105e-04, -6.5370e-03, -2.0288e-02,  2.5611e-02]],\n",
            "\n",
            "         [[ 4.3548e-02,  3.7816e-02,  8.0256e-04,  3.2042e-02,  3.9717e-02],\n",
            "          [ 3.0302e-04,  2.8997e-02, -2.5926e-02, -5.3239e-04,  3.2828e-02],\n",
            "          [-3.3808e-02, -2.6909e-03,  1.1874e-02,  2.0661e-02,  4.8972e-02],\n",
            "          [-2.3511e-02,  3.8609e-02, -2.5226e-02,  2.4631e-02, -2.2000e-02],\n",
            "          [-1.0233e-02,  3.9299e-02, -4.9461e-02,  1.5281e-03, -2.7736e-02]],\n",
            "\n",
            "         [[-1.2741e-02, -4.6292e-02,  4.1954e-02,  4.3206e-02, -3.5635e-02],\n",
            "          [ 2.4268e-02, -2.7121e-02,  3.5715e-02, -2.8556e-02, -5.0063e-02],\n",
            "          [-2.0222e-02, -3.2049e-02, -2.8838e-02, -4.5435e-02,  3.3287e-02],\n",
            "          [ 1.8674e-02,  4.2247e-02,  3.8348e-02,  2.3230e-02,  1.1082e-02],\n",
            "          [-2.6099e-02,  4.3653e-02,  2.0149e-02,  1.2163e-02,  1.5140e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1871e-03, -4.2067e-02, -3.6064e-02,  1.2402e-02, -1.6107e-04],\n",
            "          [ 4.4004e-02, -4.0054e-02, -1.1252e-02,  2.9434e-02,  4.0546e-02],\n",
            "          [ 3.5322e-02, -4.5157e-02, -3.2995e-02,  3.4627e-02,  2.8628e-02],\n",
            "          [-3.4558e-02, -3.7846e-02,  2.9430e-03, -2.5374e-03,  1.8547e-02],\n",
            "          [-3.6991e-02,  2.7211e-02,  1.8964e-02, -3.6807e-02,  9.0426e-03]],\n",
            "\n",
            "         [[ 4.4215e-03, -4.5223e-02, -4.8410e-02, -1.1333e-03,  4.2992e-02],\n",
            "          [ 1.7534e-05,  3.3478e-02, -3.9986e-03, -3.2448e-02,  1.6153e-03],\n",
            "          [ 1.7665e-02,  2.1785e-02,  1.3021e-02, -7.3555e-03, -1.9743e-02],\n",
            "          [ 1.9506e-02, -3.5302e-02, -1.4416e-02,  3.9147e-02,  3.4164e-02],\n",
            "          [-1.5084e-03, -1.4287e-02, -4.2032e-02, -1.1627e-02,  8.4105e-03]],\n",
            "\n",
            "         [[ 1.9318e-02,  9.7388e-04, -1.3423e-02, -4.4914e-02,  2.9148e-02],\n",
            "          [ 2.0076e-02, -2.8541e-02,  2.4721e-02, -2.4118e-02,  3.9041e-02],\n",
            "          [ 2.3152e-02, -4.7936e-03,  4.3734e-02,  9.8670e-04,  3.4655e-02],\n",
            "          [-4.9321e-02, -3.1725e-03,  1.0471e-02, -1.6882e-02,  5.3409e-03],\n",
            "          [ 4.4512e-02,  2.3598e-02, -3.8600e-02,  1.4184e-02, -4.9723e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.1433e-02, -1.8811e-02,  4.1920e-02,  9.9289e-03, -1.7279e-02],\n",
            "          [-1.6193e-02, -2.6662e-02, -3.8975e-02, -2.4919e-02, -2.0568e-02],\n",
            "          [-4.2983e-02,  3.5993e-02, -4.8206e-02, -9.4464e-03,  1.8172e-02],\n",
            "          [ 1.0258e-02, -3.5751e-02,  4.8637e-02,  3.2871e-02,  2.0231e-02],\n",
            "          [ 2.1397e-02,  1.8670e-02,  1.2895e-02,  2.1617e-02,  1.1300e-02]],\n",
            "\n",
            "         [[ 2.3376e-02,  3.7288e-02, -4.3571e-02, -4.1475e-03, -4.5743e-02],\n",
            "          [-4.5896e-02, -1.5252e-03, -1.4408e-02,  2.7918e-02, -1.1564e-02],\n",
            "          [ 1.4587e-02, -1.1029e-02,  2.8435e-02,  1.6602e-03, -2.5486e-02],\n",
            "          [ 3.0560e-02,  1.5100e-02, -1.9908e-02, -4.2836e-02, -3.4300e-02],\n",
            "          [-4.6851e-02, -3.4573e-02,  1.1044e-02, -4.4278e-04, -2.9817e-02]],\n",
            "\n",
            "         [[ 1.9071e-02,  1.5296e-02,  4.5996e-04, -2.2541e-02, -3.9258e-03],\n",
            "          [ 4.8454e-02,  4.1565e-02, -3.7642e-02,  4.5857e-02, -4.2800e-02],\n",
            "          [-2.3355e-02, -5.0781e-02,  1.0063e-02,  1.1836e-02, -4.9082e-03],\n",
            "          [-3.2684e-02,  3.7075e-02,  2.7195e-02,  4.6321e-02, -4.0074e-02],\n",
            "          [ 1.1021e-02,  1.3208e-02, -9.9550e-04, -4.3249e-02, -1.3457e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.3780e-03,  3.3073e-02, -3.5194e-02,  3.2042e-02, -2.9646e-02],\n",
            "          [ 1.7043e-02,  4.6612e-02, -3.0629e-02, -4.2373e-02, -4.1954e-02],\n",
            "          [-3.3956e-02,  1.4160e-02, -1.1489e-02,  7.6496e-03, -4.9052e-02],\n",
            "          [ 1.4157e-02,  2.1423e-02,  4.1297e-02, -3.1897e-02, -3.4079e-02],\n",
            "          [-2.3463e-03, -2.1778e-02, -5.9539e-03, -4.5330e-02, -4.1693e-03]],\n",
            "\n",
            "         [[-2.9977e-02,  1.3910e-03,  2.3248e-02,  1.9236e-05,  4.5678e-02],\n",
            "          [ 2.8501e-02, -7.0847e-03,  6.1370e-03,  1.7608e-02,  2.6192e-03],\n",
            "          [-3.1174e-02, -7.9411e-03, -1.1005e-02, -4.3435e-02, -5.9192e-03],\n",
            "          [ 2.7713e-02,  4.4091e-02, -1.0333e-02, -5.1989e-03,  4.0762e-02],\n",
            "          [ 4.2374e-02,  1.2556e-02, -1.2218e-02, -5.0215e-02,  3.9336e-02]],\n",
            "\n",
            "         [[-3.1339e-02, -3.5364e-02, -4.3821e-02,  4.9297e-02,  1.7363e-02],\n",
            "          [-2.6323e-02, -1.8277e-02,  4.6911e-02, -8.5666e-03, -4.1615e-02],\n",
            "          [ 1.0881e-03,  3.3619e-02,  5.8368e-03,  3.0482e-03, -3.5596e-02],\n",
            "          [-4.1483e-02, -1.7035e-03,  2.8697e-02, -1.1798e-02,  2.0486e-02],\n",
            "          [ 4.0612e-02,  1.7548e-02,  1.3580e-03, -4.2703e-02, -3.6440e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.8112e-03,  5.6649e-03, -6.7366e-03,  1.4884e-02, -1.9933e-02],\n",
            "          [-1.1832e-02, -4.4819e-02, -2.8542e-02,  4.3057e-02,  3.7841e-02],\n",
            "          [ 1.2310e-02,  1.0399e-02, -1.2245e-02, -3.9860e-02, -2.2860e-02],\n",
            "          [ 4.8988e-02,  4.2841e-02,  2.2661e-02,  9.1962e-03,  5.6183e-03],\n",
            "          [ 3.8688e-02, -2.4026e-02, -1.4278e-02,  1.2723e-02,  5.9737e-03]],\n",
            "\n",
            "         [[-3.4330e-02,  2.2702e-02,  1.8186e-02, -5.3370e-04, -4.7916e-02],\n",
            "          [ 4.7260e-02,  1.4745e-02, -2.3757e-02,  7.0759e-04, -1.6010e-03],\n",
            "          [-4.3734e-02, -1.6427e-02,  3.1316e-02, -4.8847e-02,  4.5698e-02],\n",
            "          [ 1.2099e-02,  4.4004e-02,  1.0355e-02, -2.1415e-02,  4.4163e-02],\n",
            "          [-3.1122e-02, -1.0587e-02,  7.8558e-03, -4.3284e-02,  1.2856e-02]],\n",
            "\n",
            "         [[ 1.5140e-02, -4.9503e-02,  2.5570e-02,  3.4332e-02, -5.1244e-02],\n",
            "          [ 3.0984e-03, -6.4436e-03,  5.8948e-03,  1.3516e-02, -1.8425e-02],\n",
            "          [ 4.5272e-02,  9.0093e-04, -2.9329e-02,  1.8264e-02, -2.8174e-02],\n",
            "          [-2.7945e-03, -1.3521e-02,  1.8693e-02, -1.7262e-02, -1.9423e-02],\n",
            "          [ 2.6349e-02,  7.1912e-03,  9.4162e-03, -4.2597e-02, -4.0176e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6418e-03, -1.1895e-03,  1.4344e-02,  4.0380e-02,  3.6489e-02],\n",
            "          [-2.8018e-02, -4.2381e-03, -2.4133e-03,  4.3958e-02, -1.9322e-02],\n",
            "          [-1.8673e-02, -3.1702e-02,  5.9483e-03, -3.3766e-02, -1.7844e-02],\n",
            "          [ 2.5073e-02, -4.9510e-02, -4.8744e-02,  2.1220e-02, -3.3403e-02],\n",
            "          [ 8.3896e-03, -3.8391e-02,  6.9328e-03,  1.8036e-02, -4.6485e-02]],\n",
            "\n",
            "         [[ 3.9534e-02,  4.7834e-02,  4.9635e-02, -3.4989e-02, -1.1742e-02],\n",
            "          [-4.3733e-02,  4.8949e-02,  2.0187e-02, -3.2189e-02,  4.5522e-02],\n",
            "          [ 1.2013e-02, -4.4697e-02,  1.9502e-02, -5.1773e-02,  3.1431e-02],\n",
            "          [ 2.3244e-02, -8.5498e-03, -1.8183e-02,  4.3683e-02,  1.9419e-02],\n",
            "          [-3.3767e-02, -1.1930e-02,  4.5817e-02, -4.0942e-02,  3.8141e-03]],\n",
            "\n",
            "         [[-2.5592e-02,  4.9686e-02, -2.2548e-02,  3.6043e-02,  1.2983e-02],\n",
            "          [-1.0258e-03, -3.4169e-03,  2.5061e-02,  4.1946e-02,  2.3817e-02],\n",
            "          [-2.3964e-02,  3.2052e-02, -1.9861e-02,  1.9342e-02,  3.0232e-02],\n",
            "          [-4.6090e-02, -3.0966e-02, -3.2424e-02, -3.5876e-02, -2.1533e-02],\n",
            "          [-3.0164e-02, -6.1777e-03, -1.6735e-02, -1.0312e-03,  3.3428e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.7299e-03, -4.1017e-02,  4.4425e-02,  5.9827e-03, -1.9055e-02],\n",
            "          [ 1.0633e-02,  2.2495e-02,  2.3710e-02,  3.6159e-02, -6.0451e-03],\n",
            "          [ 2.8543e-02,  4.4016e-02,  4.3940e-02,  4.7294e-02, -1.5584e-02],\n",
            "          [ 2.8229e-02,  4.1082e-02, -3.3345e-03, -3.7515e-02, -4.0577e-02],\n",
            "          [ 2.6995e-02, -1.7869e-02, -2.2219e-02, -1.0541e-02, -3.7117e-02]],\n",
            "\n",
            "         [[-1.6088e-02, -1.4722e-02, -1.8210e-02, -6.3473e-04, -2.3506e-02],\n",
            "          [-3.5786e-03,  2.6715e-02, -1.8299e-02,  4.2491e-02,  4.7786e-02],\n",
            "          [ 1.0821e-03, -1.7475e-02,  4.6150e-02, -3.5925e-02,  1.0691e-02],\n",
            "          [-2.7215e-02,  1.6911e-02, -2.2706e-02,  4.0559e-02,  2.8068e-02],\n",
            "          [ 2.5479e-02,  4.9670e-02, -1.2222e-02,  8.3836e-04,  4.8863e-02]],\n",
            "\n",
            "         [[-1.2723e-02, -3.1355e-02,  3.6669e-03, -2.9929e-02, -1.9387e-02],\n",
            "          [-7.0133e-03, -3.3434e-02,  5.1231e-02,  1.6899e-02, -6.5384e-03],\n",
            "          [ 7.2859e-03,  4.2832e-03,  2.6312e-03, -6.9104e-03, -8.3300e-03],\n",
            "          [-3.9968e-02,  2.6650e-02,  2.7706e-02,  1.5917e-02,  7.5737e-03],\n",
            "          [ 1.4078e-02, -1.9881e-02, -2.4874e-03,  1.0108e-02, -4.7362e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3488e-02, -2.2684e-02, -1.7377e-02, -2.1103e-02, -2.2412e-03],\n",
            "          [-2.0366e-02, -2.5074e-02, -4.3740e-03,  1.2201e-02,  4.1981e-02],\n",
            "          [-2.4092e-02, -4.3028e-03, -3.1420e-02,  4.4005e-02, -5.3489e-03],\n",
            "          [-1.0961e-02, -4.9820e-02,  2.8922e-02,  3.9377e-02,  3.5972e-02],\n",
            "          [-2.1103e-02,  4.1200e-02,  2.1231e-02, -4.2222e-02,  4.3953e-02]],\n",
            "\n",
            "         [[-2.9924e-02,  3.4349e-02, -1.3052e-02, -2.5473e-02, -4.2566e-02],\n",
            "          [ 4.3714e-03,  4.5009e-03,  3.8935e-02, -4.3004e-02, -8.4527e-03],\n",
            "          [-5.9601e-03,  4.8225e-04, -1.1429e-02,  1.3850e-02, -3.9646e-02],\n",
            "          [-3.1403e-02,  4.2690e-02,  1.2816e-02, -4.9773e-02,  4.8991e-02],\n",
            "          [-2.6179e-02, -1.5486e-02, -3.4559e-02, -2.0283e-02, -3.3946e-02]],\n",
            "\n",
            "         [[-7.4517e-03, -2.7185e-02, -2.0139e-02,  2.4101e-02,  3.2706e-02],\n",
            "          [ 5.1018e-03, -4.2957e-02,  3.2750e-02,  4.3245e-03,  3.4929e-02],\n",
            "          [ 4.3859e-02, -7.8730e-03,  5.0479e-02,  3.5315e-02, -1.3709e-02],\n",
            "          [-1.0984e-02,  3.2562e-02,  3.7408e-02, -2.2706e-02,  3.3701e-02],\n",
            "          [ 2.3190e-02,  4.7007e-02, -1.6669e-02,  2.9696e-02,  5.0686e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9157e-03,  4.3031e-02, -3.4475e-02, -1.9263e-02,  2.0602e-02],\n",
            "          [ 3.6221e-02,  1.3958e-02,  1.6218e-02, -4.9578e-02,  2.3364e-02],\n",
            "          [-3.1967e-02,  1.5875e-02, -4.6743e-02, -4.3763e-02, -4.7870e-02],\n",
            "          [ 2.2437e-02,  1.1040e-02,  4.1415e-02,  1.5997e-02,  2.3373e-02],\n",
            "          [ 3.5808e-02,  4.1515e-02, -3.4119e-02,  4.8367e-02, -5.5514e-03]],\n",
            "\n",
            "         [[-5.2843e-03,  7.8741e-03,  3.8169e-02,  1.2891e-02,  3.3591e-02],\n",
            "          [ 2.0920e-02, -4.3652e-03,  2.8676e-02,  1.1536e-02,  4.1900e-02],\n",
            "          [-1.3579e-02,  3.8611e-02, -3.1720e-02,  2.3609e-03, -3.1577e-02],\n",
            "          [-1.5522e-02, -4.0569e-02,  4.9329e-02,  1.4887e-02,  2.9284e-02],\n",
            "          [ 1.1563e-03,  1.2621e-02, -1.5181e-02,  1.3577e-02, -1.2350e-02]],\n",
            "\n",
            "         [[-2.7498e-02,  5.1935e-03, -4.9738e-02, -1.8725e-02,  1.4391e-02],\n",
            "          [ 6.9414e-04,  4.5970e-02, -2.6920e-02, -2.6985e-02, -4.2972e-02],\n",
            "          [ 3.5749e-02, -1.6565e-02, -4.7101e-02,  2.5249e-02, -4.4821e-02],\n",
            "          [-4.5058e-03,  2.4502e-02, -6.1181e-03, -2.7389e-02, -3.1871e-02],\n",
            "          [ 3.0963e-02, -3.0546e-02,  3.3682e-02, -5.7654e-03, -6.1644e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1463e-02,  2.0628e-03, -8.4174e-03,  3.3402e-02, -3.1994e-02],\n",
            "          [ 3.3954e-02,  2.2327e-02, -2.1114e-02, -2.3282e-02, -3.6553e-02],\n",
            "          [ 1.1109e-02, -2.3715e-03,  4.0888e-02,  8.0221e-04,  1.4133e-02],\n",
            "          [ 2.7106e-02,  2.7217e-02, -3.9598e-02, -4.3250e-02,  9.8350e-03],\n",
            "          [ 2.4906e-03, -8.3925e-03,  4.6586e-02, -4.2740e-02,  1.5251e-02]],\n",
            "\n",
            "         [[-4.2056e-03,  1.4596e-02, -3.7226e-02,  4.6981e-03,  2.6542e-03],\n",
            "          [-1.5619e-02, -2.4777e-02,  4.1785e-02, -3.4444e-02,  2.2468e-03],\n",
            "          [ 1.3900e-02, -6.6560e-03, -2.1428e-02, -3.7118e-02,  3.4373e-02],\n",
            "          [-7.3442e-03, -2.3012e-02, -3.0718e-02,  2.3218e-02, -2.1791e-02],\n",
            "          [ 1.5300e-02,  4.8073e-02,  4.3086e-02, -4.7617e-03, -1.6766e-02]],\n",
            "\n",
            "         [[-2.0562e-02, -2.1161e-02,  1.3756e-02, -2.0564e-02,  2.4778e-02],\n",
            "          [ 1.0718e-02,  3.5602e-02,  3.4823e-02, -9.3637e-03, -2.5843e-02],\n",
            "          [-4.3518e-02, -4.1816e-02,  1.7735e-02,  4.3664e-02,  3.0634e-02],\n",
            "          [ 2.8832e-02,  8.2413e-03,  3.8665e-02,  1.8430e-02,  4.4540e-05],\n",
            "          [ 3.5778e-02,  1.6439e-02,  9.2192e-03, -2.1642e-02,  2.2076e-02]]]])), ('conv2.bias', tensor([ 2.7655e-02, -3.8887e-03,  3.6667e-02, -4.7556e-03, -1.8495e-02,\n",
            "        -2.5748e-02, -5.1812e-05,  2.0166e-02,  2.3293e-02, -1.4457e-03,\n",
            "         3.4155e-02,  2.0292e-02, -3.7017e-02, -2.5130e-02,  4.7138e-03,\n",
            "         2.3796e-02, -3.8215e-02, -7.9515e-03,  2.1009e-02, -2.9494e-03,\n",
            "        -6.5255e-03, -3.3265e-03, -1.6355e-02,  3.3111e-02,  3.3398e-02,\n",
            "        -1.8030e-02, -2.4297e-02, -9.0663e-03,  5.3728e-03, -8.9312e-03,\n",
            "        -2.6458e-02,  1.1626e-02])), ('bn2.weight', tensor([0.9996, 0.9986, 1.0004, 1.0025, 0.9975, 0.9984, 0.9982, 1.0015, 0.9977,\n",
            "        0.9984, 1.0008, 0.9999, 0.9965, 0.9968, 0.9992, 1.0035, 0.9998, 0.9983,\n",
            "        1.0011, 0.9987, 1.0001, 0.9984, 0.9997, 1.0005, 0.9990, 1.0038, 1.0009,\n",
            "        0.9997, 0.9979, 1.0021, 0.9989, 0.9984])), ('bn2.bias', tensor([-0.0022,  0.0020,  0.0038,  0.0034, -0.0018, -0.0006, -0.0038, -0.0004,\n",
            "        -0.0001, -0.0030,  0.0018,  0.0041, -0.0033, -0.0025,  0.0011,  0.0004,\n",
            "        -0.0020,  0.0002,  0.0031,  0.0001,  0.0004, -0.0007, -0.0014, -0.0010,\n",
            "         0.0010,  0.0015, -0.0051,  0.0014, -0.0004,  0.0050, -0.0013,  0.0001])), ('bn2.running_mean', tensor([ 0.2426,  0.4115, -0.5472, -0.2299, -0.2331,  0.0993,  0.8899, -0.0401,\n",
            "        -0.1816,  0.5791, -0.1433,  0.0249, -0.2365, -0.3927,  0.0499, -0.2269,\n",
            "        -0.1537, -0.3265, -0.3784, -0.0251, -0.4421, -0.1980, -0.0829,  0.1409,\n",
            "         0.2321, -0.5138,  0.3046,  0.5084, -0.0812, -0.1567,  0.3967,  0.3150])), ('bn2.running_var', tensor([0.1370, 0.1241, 0.1364, 0.1149, 0.1227, 0.0898, 0.4566, 0.1179, 0.1618,\n",
            "        0.2100, 0.1320, 0.1062, 0.1283, 0.1531, 0.2162, 0.1962, 0.1020, 0.1162,\n",
            "        0.1446, 0.1816, 0.1074, 0.2203, 0.4327, 0.2495, 0.0769, 0.1702, 0.1715,\n",
            "        0.1585, 0.0792, 0.0961, 0.3300, 0.2583])), ('bn2.num_batches_tracked', tensor(250)), ('conv3.weight', tensor([[[[-2.9855e-02,  3.1089e-02,  1.7838e-02, -1.9967e-02, -3.3773e-02],\n",
            "          [ 1.3383e-02, -1.9910e-02, -9.4377e-03, -1.8125e-02, -2.4773e-02],\n",
            "          [ 3.2311e-02,  1.7562e-02,  4.3762e-03, -2.3652e-02, -2.2730e-02],\n",
            "          [-1.1877e-02, -1.6682e-02, -3.6024e-03,  1.4486e-02, -2.3414e-02],\n",
            "          [-8.3770e-03, -7.3956e-03, -1.8231e-02, -1.3432e-02,  2.6057e-02]],\n",
            "\n",
            "         [[-3.9186e-03,  1.1307e-02,  8.8575e-03, -8.5696e-03,  2.4273e-03],\n",
            "          [ 2.1720e-02,  2.3751e-02, -2.9653e-02,  1.2428e-02, -1.8034e-02],\n",
            "          [-9.4899e-03, -2.4090e-02,  3.1937e-02,  5.3406e-03, -1.2390e-03],\n",
            "          [ 4.9896e-03, -2.0764e-02, -2.8873e-02, -1.2706e-02,  1.0511e-02],\n",
            "          [-2.1785e-02,  8.5826e-03, -7.6935e-03, -2.9286e-02,  6.2923e-03]],\n",
            "\n",
            "         [[ 1.3709e-02, -1.7991e-02, -1.6213e-02,  1.9915e-02, -8.0299e-03],\n",
            "          [-1.2580e-02,  2.5026e-02, -1.5652e-03,  1.7409e-02, -1.3339e-02],\n",
            "          [-3.4796e-02, -6.9196e-03, -1.1125e-02, -6.2889e-03, -2.9696e-02],\n",
            "          [-1.8221e-02,  2.8921e-02,  2.5108e-02, -3.3151e-02, -1.7197e-02],\n",
            "          [-8.7986e-03,  1.2738e-02, -3.1325e-02, -1.8176e-03,  1.6743e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.7900e-03,  2.7864e-02,  7.8969e-03, -2.2737e-03,  1.7552e-02],\n",
            "          [ 3.3466e-02, -3.1250e-02, -1.9001e-03, -2.5113e-02,  5.0581e-03],\n",
            "          [ 2.0154e-02, -2.1844e-02, -2.4965e-02, -5.7436e-03, -1.1359e-02],\n",
            "          [ 2.2274e-02,  1.6250e-02, -3.0903e-02,  1.1502e-02, -2.6725e-02],\n",
            "          [-1.3424e-02, -3.1432e-02,  2.1169e-02,  1.9446e-02,  2.8704e-02]],\n",
            "\n",
            "         [[ 8.5821e-03, -3.1068e-02, -1.4091e-02, -2.8976e-02,  2.2850e-02],\n",
            "          [ 1.0351e-03, -3.9163e-03,  2.7403e-02, -2.7442e-02, -1.2599e-02],\n",
            "          [ 2.8732e-02, -1.1560e-02, -1.4422e-02,  2.8623e-04, -9.3322e-03],\n",
            "          [-2.7022e-02,  1.8136e-02,  2.9091e-02,  6.1172e-03,  1.5081e-02],\n",
            "          [ 1.9991e-02, -2.9687e-02,  2.8696e-02,  1.4297e-02,  1.5991e-02]],\n",
            "\n",
            "         [[-8.3677e-03, -1.0012e-02, -3.3488e-02, -1.3845e-02, -6.0003e-03],\n",
            "          [-6.8096e-03,  2.8574e-02, -1.0698e-02, -1.2635e-02, -3.2958e-02],\n",
            "          [-1.5393e-02,  2.7656e-02,  1.4974e-02, -1.1676e-02, -8.4849e-04],\n",
            "          [ 1.7521e-02, -1.8668e-02, -3.4558e-02,  2.8274e-02,  1.8764e-02],\n",
            "          [ 4.2166e-03,  1.0107e-02, -2.9580e-02, -2.7874e-02, -3.4818e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.3608e-02,  2.0120e-02, -5.7159e-04, -4.7629e-03,  2.7779e-02],\n",
            "          [-5.4238e-03, -3.0700e-02,  7.5203e-03, -1.4062e-02, -1.7424e-02],\n",
            "          [ 3.2249e-02,  3.0396e-02,  2.6896e-02,  2.6722e-02, -8.0547e-04],\n",
            "          [ 2.5848e-02, -7.5634e-03, -8.0010e-03, -1.7173e-02,  4.6976e-03],\n",
            "          [-2.3173e-02,  3.0721e-02, -2.5839e-03, -8.7357e-03, -3.3568e-02]],\n",
            "\n",
            "         [[ 2.1591e-02,  7.9984e-04,  1.8953e-03,  5.4147e-03,  2.4579e-02],\n",
            "          [ 1.1591e-02,  1.8991e-04, -2.3894e-02, -3.2615e-02, -2.1836e-02],\n",
            "          [-3.5395e-03,  6.8086e-03,  3.0731e-02,  1.7278e-02, -6.5438e-04],\n",
            "          [-3.1689e-02,  2.3228e-02,  2.8098e-02, -1.5841e-03,  3.0136e-02],\n",
            "          [ 6.8443e-03, -2.8327e-02,  4.6374e-03, -2.6386e-02, -2.0056e-02]],\n",
            "\n",
            "         [[-7.0175e-03,  2.7292e-02,  9.1295e-03, -2.6459e-03,  8.7674e-03],\n",
            "          [-3.5463e-02,  3.4803e-02, -9.9019e-03,  1.6818e-02,  7.3714e-03],\n",
            "          [ 1.7607e-02, -3.1063e-02, -3.2581e-02, -1.1548e-02, -1.8205e-02],\n",
            "          [ 1.8764e-02,  1.1899e-03, -1.4520e-02,  3.4233e-02,  4.2871e-03],\n",
            "          [ 7.5075e-03,  1.0202e-02, -8.1919e-03,  8.5827e-04, -3.0466e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2677e-02, -2.9974e-02,  1.7204e-02, -3.0508e-02,  1.1249e-02],\n",
            "          [ 1.1661e-03,  7.9894e-03, -3.2266e-02,  3.1961e-02,  1.5674e-02],\n",
            "          [ 5.4663e-03, -1.4073e-02, -3.0304e-02, -1.7081e-02, -3.4108e-03],\n",
            "          [ 1.6627e-02,  2.8228e-02, -9.8899e-03, -2.5559e-02,  1.9219e-02],\n",
            "          [ 1.1701e-02,  6.6806e-03, -2.9800e-03, -3.4057e-02,  2.3240e-02]],\n",
            "\n",
            "         [[-2.6068e-03, -2.3843e-02, -2.0928e-02, -3.2031e-02,  7.6930e-04],\n",
            "          [-4.7723e-03,  7.8039e-04, -1.9088e-02, -1.3541e-04,  1.4859e-02],\n",
            "          [ 1.2769e-02, -1.6160e-02,  1.5814e-02, -2.4339e-02, -2.2140e-02],\n",
            "          [-1.0024e-02,  1.1297e-02, -1.7740e-02,  3.3402e-03,  2.2207e-02],\n",
            "          [ 3.0107e-02,  1.8548e-02, -2.5180e-02,  3.7327e-04,  7.0524e-04]],\n",
            "\n",
            "         [[ 1.3911e-02,  1.6503e-02,  2.4827e-02, -1.8006e-02,  2.5396e-02],\n",
            "          [-1.6367e-02, -8.3342e-03, -3.4789e-02, -3.1481e-02,  2.5844e-02],\n",
            "          [-1.9753e-03, -1.3402e-02, -4.0775e-03, -2.9955e-02,  3.0140e-02],\n",
            "          [ 1.2078e-02, -1.8197e-02, -1.9153e-02,  1.4261e-02,  3.4460e-03],\n",
            "          [ 1.9531e-02, -9.8070e-03,  1.2482e-02,  8.3465e-03, -6.8820e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6197e-02, -2.7413e-02, -2.5193e-03,  2.2441e-02,  2.1912e-02],\n",
            "          [ 2.2015e-02,  8.7313e-03,  3.3551e-02,  3.3713e-02, -1.9000e-03],\n",
            "          [-4.5663e-03,  8.9563e-03,  3.3625e-02, -2.4730e-02,  8.6951e-03],\n",
            "          [-8.9439e-04,  2.6574e-02, -1.5962e-02,  1.2746e-02,  1.9227e-02],\n",
            "          [ 3.5684e-02, -2.2949e-02, -1.9521e-02,  1.6332e-02,  2.5381e-02]],\n",
            "\n",
            "         [[-3.3371e-02,  2.9862e-02, -1.1447e-02, -1.6817e-03, -1.5988e-02],\n",
            "          [ 1.4242e-03,  3.6372e-02, -4.5758e-03,  1.0625e-02, -1.9779e-02],\n",
            "          [-1.2039e-02,  2.3179e-02,  1.2721e-02, -1.3995e-02,  6.0919e-03],\n",
            "          [ 1.1828e-02,  1.0177e-02,  1.8206e-02, -7.2214e-03,  2.8691e-02],\n",
            "          [-2.9386e-02, -9.0012e-03,  3.6346e-02, -1.7769e-02,  2.5379e-02]],\n",
            "\n",
            "         [[ 1.8256e-02,  5.4356e-03, -7.7341e-03,  6.7200e-03, -3.8456e-03],\n",
            "          [ 6.3934e-03, -8.8791e-03,  3.0944e-02,  8.3509e-03, -2.9840e-03],\n",
            "          [ 3.8846e-03,  2.1266e-03, -1.8324e-02,  2.6741e-02,  2.7001e-02],\n",
            "          [-1.9182e-02,  8.7433e-03,  1.1355e-02, -1.7135e-02, -2.6247e-02],\n",
            "          [-1.8286e-02, -2.6225e-02, -2.2697e-02,  4.4227e-03, -1.6307e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9896e-02,  6.2211e-03,  3.2565e-02,  3.7267e-02,  2.4978e-02],\n",
            "          [ 1.9189e-02, -2.3330e-02,  1.6978e-02, -3.0780e-02, -2.7993e-02],\n",
            "          [ 2.0309e-02,  3.6093e-02, -3.2887e-02, -2.8825e-02,  1.9217e-02],\n",
            "          [-2.7572e-02, -3.0435e-02, -8.6403e-03, -1.6190e-04,  3.4066e-02],\n",
            "          [-2.3407e-02, -3.5957e-03, -7.0488e-03, -3.6807e-03, -2.1391e-02]],\n",
            "\n",
            "         [[-5.4892e-03, -9.4681e-04,  2.8214e-02, -3.2001e-02,  7.7729e-03],\n",
            "          [-1.3027e-02, -3.6126e-02, -2.6626e-02, -1.7804e-02,  9.9023e-03],\n",
            "          [-1.6745e-02, -5.3022e-03,  3.2725e-02, -1.1541e-02, -2.3110e-02],\n",
            "          [-3.5925e-03,  7.9610e-03,  1.1462e-03,  1.2043e-02,  3.2319e-02],\n",
            "          [ 3.5686e-03,  2.6164e-02,  2.2122e-02, -1.0176e-03, -1.3611e-04]],\n",
            "\n",
            "         [[ 1.0813e-02,  1.2402e-02, -2.9616e-03, -3.4090e-02,  1.9419e-02],\n",
            "          [ 2.6177e-02, -2.3241e-02, -3.3997e-02,  3.1106e-02,  1.2954e-02],\n",
            "          [-2.2343e-02,  1.5344e-02, -1.7883e-02,  1.1769e-03, -2.9965e-02],\n",
            "          [-1.4988e-03, -3.5129e-02,  3.0689e-02,  1.3342e-02, -1.6649e-02],\n",
            "          [ 5.8512e-03, -1.9792e-02, -2.9142e-02,  2.8739e-02,  9.0927e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.5156e-02, -1.1432e-02, -1.7756e-02,  1.8177e-02,  3.0552e-02],\n",
            "          [-1.1006e-03, -1.5128e-03,  3.6243e-02,  2.7747e-02,  2.8347e-02],\n",
            "          [-2.2019e-02, -2.1640e-02,  3.2687e-02, -3.3563e-02, -2.1468e-02],\n",
            "          [-2.1665e-02, -1.8447e-02,  1.9106e-02, -2.5326e-02, -3.2559e-02],\n",
            "          [ 3.1378e-02,  1.6324e-02,  1.1546e-02,  1.3426e-02,  2.0621e-02]],\n",
            "\n",
            "         [[-2.2519e-02, -1.6663e-02,  1.8889e-02,  2.3316e-02, -1.2614e-02],\n",
            "          [-1.7992e-02, -1.4160e-03, -3.3915e-02,  2.9400e-02, -3.1667e-02],\n",
            "          [ 1.1404e-02,  2.6829e-02, -2.5795e-02,  2.5709e-03,  5.5959e-03],\n",
            "          [-3.4527e-02,  1.8646e-02, -4.3697e-03, -2.6601e-02, -1.9374e-02],\n",
            "          [-3.4282e-02, -1.4743e-02, -8.8473e-03, -1.5277e-02,  9.8812e-03]],\n",
            "\n",
            "         [[-1.3260e-02,  1.1739e-02, -1.1631e-02, -2.0828e-02,  1.9497e-03],\n",
            "          [-1.2957e-02,  2.4589e-02,  2.2263e-02,  2.2659e-02,  3.4825e-02],\n",
            "          [ 3.4139e-02, -3.3922e-02,  2.2425e-02, -2.6492e-02, -5.4780e-03],\n",
            "          [-1.7955e-02, -3.3770e-02, -1.9605e-02, -9.0898e-03, -1.9092e-02],\n",
            "          [-7.3185e-04,  5.8564e-03, -3.4636e-02, -1.7695e-02, -2.5715e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.5180e-03,  6.4142e-03, -6.3695e-03, -2.7006e-02, -2.0365e-02],\n",
            "          [-2.2379e-02, -2.7767e-02, -1.3324e-02,  3.1553e-02, -3.5108e-02],\n",
            "          [ 1.0146e-02, -3.9937e-03, -2.8449e-03,  1.6595e-04,  2.0550e-02],\n",
            "          [ 3.0411e-02,  3.1393e-02, -2.4157e-02, -1.4833e-03,  7.2230e-03],\n",
            "          [ 2.1447e-02, -2.7054e-02,  5.9545e-03,  2.4117e-02, -2.2748e-02]],\n",
            "\n",
            "         [[ 3.0366e-02, -4.6970e-03,  7.2164e-03,  2.3834e-02,  3.2683e-02],\n",
            "          [ 1.1541e-02,  5.6595e-03,  1.9261e-02,  3.1815e-02, -3.3616e-02],\n",
            "          [ 3.1426e-02, -1.2075e-02, -9.8956e-03,  1.5272e-02, -1.2625e-02],\n",
            "          [ 1.4421e-02, -5.9214e-03, -3.1857e-02,  1.7523e-03, -2.5803e-02],\n",
            "          [ 2.4619e-02, -9.0019e-03, -2.1022e-02,  5.6143e-03, -3.0320e-02]],\n",
            "\n",
            "         [[ 1.9829e-02, -2.0886e-02,  1.0415e-02,  2.3260e-02,  2.6772e-02],\n",
            "          [-1.0564e-02,  3.3461e-02,  7.1700e-03, -3.3858e-02, -3.0947e-02],\n",
            "          [ 8.5494e-03, -2.9904e-02,  7.1307e-03,  7.7378e-03, -2.8712e-02],\n",
            "          [ 3.0527e-02, -1.9460e-02,  1.5594e-02,  1.2297e-02, -3.2792e-03],\n",
            "          [-3.4778e-02,  7.2202e-03, -2.2402e-02, -1.7660e-02, -2.5646e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.2645e-02, -2.9997e-02, -1.2046e-02, -2.1973e-02, -1.1981e-02],\n",
            "          [ 3.6435e-02,  4.0561e-03, -2.8503e-02,  7.9909e-03, -6.4854e-03],\n",
            "          [ 3.7520e-04,  1.8277e-02, -2.8468e-02,  2.2858e-02, -2.7096e-03],\n",
            "          [ 1.7351e-02, -1.9023e-02,  1.5145e-02,  3.4145e-02,  1.1209e-02],\n",
            "          [ 1.5994e-02, -2.9258e-02,  3.3131e-02, -6.0593e-03,  1.5901e-03]],\n",
            "\n",
            "         [[ 2.5136e-02, -1.1113e-02,  1.5017e-02, -2.5428e-02,  2.7563e-05],\n",
            "          [-2.4403e-02,  1.7141e-02, -1.9654e-02, -3.0903e-02, -2.9181e-02],\n",
            "          [ 1.5540e-03, -1.4942e-02,  1.0255e-02, -3.0379e-02, -3.0609e-02],\n",
            "          [ 2.9216e-02, -2.9751e-02,  1.0342e-02,  1.5639e-02,  1.2725e-02],\n",
            "          [ 4.5730e-03,  3.0598e-02, -2.3880e-02, -7.1330e-05,  3.4707e-02]],\n",
            "\n",
            "         [[-2.3339e-04,  2.7713e-02, -3.1001e-02,  8.8707e-03, -1.5169e-02],\n",
            "          [-2.1300e-02, -1.2790e-02, -1.6512e-02,  3.7370e-03,  2.9965e-02],\n",
            "          [-1.9469e-02,  2.6431e-03, -3.3687e-02,  2.4615e-02, -7.8916e-03],\n",
            "          [-1.7623e-02, -8.7593e-03, -6.9510e-03,  4.5044e-03, -1.8048e-02],\n",
            "          [-3.0804e-02, -8.0694e-03, -2.8974e-03, -2.5206e-02,  2.5614e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0453e-02, -1.6722e-02, -2.5836e-03, -2.5600e-02,  1.0732e-02],\n",
            "          [ 7.0204e-03, -1.6776e-02,  7.5661e-03, -2.4839e-02,  7.6926e-05],\n",
            "          [ 6.8413e-03, -1.4192e-02, -3.3534e-02, -9.8150e-03,  2.0026e-03],\n",
            "          [ 1.8999e-02,  1.1637e-03, -2.2666e-03, -1.8908e-02, -2.3936e-02],\n",
            "          [-3.4349e-02, -3.2047e-02, -2.3257e-02, -5.5130e-03,  1.2574e-02]],\n",
            "\n",
            "         [[ 7.0583e-04, -2.1255e-02, -1.5213e-02,  3.3253e-02, -1.3154e-02],\n",
            "          [-1.3707e-03, -2.5910e-02,  7.9211e-03,  7.0863e-03,  8.5483e-03],\n",
            "          [-4.6395e-03,  8.8581e-04, -1.9827e-02, -3.4914e-02, -7.8643e-03],\n",
            "          [ 1.5894e-02, -9.7069e-03,  2.0473e-02, -1.1138e-03,  5.9507e-03],\n",
            "          [ 1.4422e-02,  1.7759e-02, -2.4184e-02, -3.3992e-02, -3.8941e-03]],\n",
            "\n",
            "         [[-2.8166e-02, -1.4206e-02, -1.5132e-02, -2.7105e-02, -1.9986e-02],\n",
            "          [-2.4670e-02, -1.8457e-02, -4.0498e-03,  2.1934e-02, -3.5431e-03],\n",
            "          [ 2.5901e-02,  2.9984e-02,  2.8315e-02, -7.1475e-04,  4.3765e-03],\n",
            "          [-7.8954e-03,  5.6935e-03, -3.2037e-02,  3.2680e-02, -2.6480e-02],\n",
            "          [ 3.0491e-03, -3.1378e-02,  5.6503e-03, -1.4600e-02,  9.6857e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.2119e-03,  9.2195e-03,  2.4299e-02,  1.7809e-02,  5.3903e-03],\n",
            "          [-2.9441e-02, -1.2785e-02,  2.3628e-02,  2.8913e-02,  1.1151e-02],\n",
            "          [-3.3795e-02,  1.7698e-02,  1.7545e-02,  2.5210e-03, -1.1086e-02],\n",
            "          [-8.3506e-03, -2.7879e-02,  2.3869e-02, -2.1449e-02,  5.5640e-03],\n",
            "          [ 5.9370e-03,  1.7158e-02, -1.3811e-02, -1.9186e-02, -2.1170e-03]],\n",
            "\n",
            "         [[ 1.6022e-02, -1.4168e-02, -1.9988e-02, -1.1658e-02, -3.2467e-02],\n",
            "          [-1.9712e-02, -1.8389e-02, -5.3767e-03,  3.2358e-03,  2.4810e-02],\n",
            "          [ 1.0704e-02,  3.5600e-02, -3.0682e-02, -8.6294e-03,  1.4409e-02],\n",
            "          [ 2.1765e-02,  1.3252e-02,  3.1343e-02,  7.9444e-03, -2.0866e-02],\n",
            "          [-2.4891e-02, -2.7514e-02,  8.4562e-03,  7.9898e-03,  1.4841e-02]],\n",
            "\n",
            "         [[-2.9378e-02, -3.4072e-02,  2.3919e-02, -7.3890e-03,  2.1106e-02],\n",
            "          [ 7.3587e-04,  5.6327e-03, -3.4122e-02,  2.5444e-02,  2.7608e-02],\n",
            "          [ 1.7019e-02, -2.7577e-02,  5.6132e-03,  1.5445e-02, -3.6076e-02],\n",
            "          [ 7.0545e-03, -3.5626e-02, -9.0475e-03,  1.8564e-02,  1.7483e-02],\n",
            "          [ 1.1079e-02,  8.3904e-03,  1.1949e-02, -2.5430e-02, -2.5985e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4541e-02,  1.8924e-02,  3.2462e-02,  8.8119e-03,  1.2925e-02],\n",
            "          [ 2.4274e-02, -1.8459e-02, -1.3877e-02,  1.1125e-02, -2.3585e-02],\n",
            "          [ 6.9444e-03, -2.4416e-02, -7.7842e-03,  1.7748e-02, -1.5071e-02],\n",
            "          [-2.4772e-02, -2.2161e-02, -3.3071e-02, -2.3829e-03,  2.2113e-02],\n",
            "          [ 1.5712e-02,  2.9213e-02,  1.1805e-02,  4.5902e-03, -2.0726e-02]],\n",
            "\n",
            "         [[-2.1841e-02, -3.1372e-02,  3.0136e-02,  2.4640e-02, -3.0135e-02],\n",
            "          [-6.0343e-04, -8.1100e-05,  3.1427e-02,  1.0928e-02,  1.7635e-02],\n",
            "          [ 2.6157e-04,  1.2543e-02, -3.3632e-02,  2.8675e-02,  2.1683e-03],\n",
            "          [-9.9653e-03, -1.5747e-02,  2.6279e-02, -1.5614e-02,  3.4263e-03],\n",
            "          [ 1.0202e-02, -3.2335e-02,  1.3963e-02,  1.2319e-02, -6.7192e-03]],\n",
            "\n",
            "         [[-2.4002e-02,  4.3212e-03,  8.8296e-03,  1.2281e-02, -2.7504e-03],\n",
            "          [-1.0891e-02, -2.1785e-02,  3.9312e-03, -2.6566e-02, -2.4213e-02],\n",
            "          [-5.6779e-03,  6.8575e-03,  2.2783e-02, -5.6681e-03, -4.6211e-03],\n",
            "          [-2.4446e-02, -2.2853e-02, -3.3398e-02,  3.3727e-02, -5.3747e-03],\n",
            "          [-2.8172e-02, -1.2598e-02, -3.5815e-02, -1.9853e-02,  1.2568e-02]]]])), ('conv3.bias', tensor([ 5.3777e-04,  1.1333e-03,  3.5576e-03,  8.4045e-03, -1.3809e-02,\n",
            "        -1.0098e-03, -2.2364e-03, -2.4255e-04,  2.8087e-04,  3.0131e-03,\n",
            "         5.1161e-04, -1.2136e-02, -9.0585e-03,  1.6145e-03, -1.4813e-02,\n",
            "        -2.6631e-04,  8.0813e-05,  1.4607e-05,  7.8944e-04, -4.8129e-05,\n",
            "        -5.5193e-04, -9.6533e-03, -1.8674e-03,  4.4742e-03, -8.6613e-05,\n",
            "        -2.1854e-03, -2.5832e-04, -8.0059e-03,  4.9103e-03, -2.7524e-04,\n",
            "         3.4007e-05,  1.1168e-02, -7.0669e-03, -1.0578e-02, -5.5004e-04,\n",
            "         1.0261e-04, -3.0663e-03,  9.3593e-03,  1.0633e-02,  9.1922e-03,\n",
            "        -4.2912e-04, -7.6365e-04, -6.8736e-03, -3.0433e-04, -9.7850e-04,\n",
            "         2.0372e-04, -3.0204e-04, -8.5032e-06, -5.3087e-04,  1.3373e-05,\n",
            "         1.0834e-02,  8.6251e-05, -9.7732e-04, -1.9334e-03, -1.8952e-04,\n",
            "         1.2020e-02,  7.2553e-03, -1.8381e-04,  1.4833e-02,  2.3245e-03,\n",
            "        -1.2485e-02, -5.6969e-04, -8.4917e-03,  1.4633e-02])), ('bn3.weight', tensor([0.9989, 0.9984, 1.0007, 1.0026, 1.0000, 0.9995, 0.9975, 1.0018, 0.9970,\n",
            "        1.0020, 0.9976, 0.9975, 1.0006, 0.9981, 1.0037, 0.9987, 0.9975, 0.9989,\n",
            "        0.9996, 0.9962, 0.9993, 0.9984, 1.0006, 1.0002, 0.9984, 0.9973, 0.9976,\n",
            "        1.0019, 0.9979, 0.9995, 1.0011, 1.0019, 0.9979, 0.9983, 0.9964, 0.9995,\n",
            "        0.9958, 0.9994, 0.9991, 0.9981, 1.0009, 1.0007, 1.0013, 1.0000, 1.0013,\n",
            "        0.9977, 0.9999, 0.9982, 0.9995, 0.9960, 0.9976, 0.9955, 0.9968, 0.9975,\n",
            "        0.9963, 0.9969, 1.0009, 0.9985, 1.0006, 1.0028, 1.0005, 1.0016, 0.9997,\n",
            "        0.9996])), ('bn3.bias', tensor([ 3.9131e-04, -1.5612e-03,  2.5615e-03,  1.1597e-03,  1.2470e-03,\n",
            "         2.5534e-03, -5.3234e-04,  1.9151e-03, -2.7044e-03,  1.5573e-03,\n",
            "         6.2779e-04, -4.8114e-04,  2.8875e-03,  1.1410e-03,  9.8433e-04,\n",
            "        -1.3103e-03, -1.9370e-03,  5.2889e-04,  1.3020e-04,  2.5931e-04,\n",
            "        -8.6755e-04, -8.9049e-04,  2.5176e-03,  1.4612e-03, -1.8828e-03,\n",
            "        -1.0353e-03, -9.4133e-04,  3.0490e-04,  6.9454e-04,  8.5696e-05,\n",
            "         1.1557e-03,  1.5891e-03, -7.8116e-04, -1.0631e-04, -2.5096e-03,\n",
            "         3.8033e-04, -5.1817e-04,  2.2146e-03, -6.3774e-04, -5.9040e-04,\n",
            "         2.7202e-03, -1.6956e-04,  5.5509e-04,  5.6889e-04,  1.5853e-03,\n",
            "         4.5856e-04,  1.2762e-04, -1.2476e-03, -3.0172e-03, -1.8537e-03,\n",
            "        -2.0422e-03, -1.5392e-03, -2.2939e-03, -4.3300e-04, -1.3085e-03,\n",
            "        -1.1928e-03, -8.3790e-04, -1.2240e-03,  1.9561e-03,  1.8174e-03,\n",
            "         1.6008e-03,  2.6491e-03, -2.2004e-04,  1.1589e-03])), ('bn3.running_mean', tensor([ 0.1974,  0.0697,  0.3529, -0.0349, -0.5144,  0.1198, -0.4020,  0.3854,\n",
            "         0.4201,  0.2237,  0.5701,  0.0412,  0.2571,  0.5368,  0.0439, -0.2096,\n",
            "        -0.4874, -0.3237,  0.1578, -0.0057, -0.1570, -0.0127, -0.0879,  0.2203,\n",
            "        -0.0922,  0.1812, -0.0849,  0.4954, -0.1458,  0.0660,  0.2386,  0.4789,\n",
            "        -0.4185,  0.3907, -0.5088,  0.5515, -0.3337, -0.0255,  0.3636,  0.0621,\n",
            "         0.5728, -0.1034, -0.2414,  0.0577, -0.4493, -0.3757,  0.1480, -0.4866,\n",
            "         0.4153, -0.1326, -0.0757, -0.2952,  0.1713,  0.0920, -0.6623,  0.2491,\n",
            "         0.2040,  0.2005, -0.1334,  0.1784, -0.7376, -0.3265, -0.5746, -0.4110])), ('bn3.running_var', tensor([0.3091, 0.1494, 0.2901, 0.1311, 0.4193, 0.4483, 0.1731, 0.2333, 0.1515,\n",
            "        0.2652, 0.1388, 0.4842, 0.1579, 0.1848, 0.2719, 0.2674, 0.1861, 0.1567,\n",
            "        0.2192, 0.2445, 0.3417, 0.1834, 0.2859, 0.2055, 0.1868, 0.1778, 0.2562,\n",
            "        0.5050, 0.1267, 0.1395, 0.3544, 0.2736, 0.1817, 0.1932, 0.2450, 0.3835,\n",
            "        0.1136, 0.1612, 0.3458, 0.3696, 0.1584, 0.2432, 0.1400, 0.3195, 0.3577,\n",
            "        0.2379, 0.1421, 0.1379, 0.1034, 0.1386, 0.3800, 0.3717, 0.2911, 0.1936,\n",
            "        0.3215, 0.1307, 0.1837, 0.2021, 0.2668, 0.4029, 0.2777, 0.3271, 0.2968,\n",
            "        0.2454])), ('bn3.num_batches_tracked', tensor(250)), ('conv4.weight', tensor([[[[-0.0345,  0.0107, -0.0189],\n",
            "          [ 0.0290, -0.0225, -0.0091],\n",
            "          [ 0.0101,  0.0074, -0.0254]],\n",
            "\n",
            "         [[-0.0057,  0.0330, -0.0173],\n",
            "          [-0.0304,  0.0385, -0.0070],\n",
            "          [-0.0245, -0.0337, -0.0235]],\n",
            "\n",
            "         [[ 0.0217, -0.0346,  0.0131],\n",
            "          [-0.0163,  0.0101, -0.0163],\n",
            "          [-0.0017, -0.0075,  0.0078]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0367, -0.0043,  0.0008],\n",
            "          [ 0.0093, -0.0086, -0.0014],\n",
            "          [ 0.0146,  0.0208,  0.0103]],\n",
            "\n",
            "         [[-0.0030,  0.0192,  0.0382],\n",
            "          [ 0.0154, -0.0359, -0.0318],\n",
            "          [ 0.0077, -0.0110, -0.0117]],\n",
            "\n",
            "         [[ 0.0083,  0.0151,  0.0106],\n",
            "          [ 0.0392, -0.0319,  0.0400],\n",
            "          [ 0.0270, -0.0179, -0.0087]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0070, -0.0371,  0.0148],\n",
            "          [ 0.0060, -0.0010,  0.0146],\n",
            "          [-0.0104,  0.0385, -0.0166]],\n",
            "\n",
            "         [[-0.0414, -0.0313,  0.0397],\n",
            "          [-0.0113, -0.0094, -0.0013],\n",
            "          [-0.0335, -0.0106, -0.0213]],\n",
            "\n",
            "         [[-0.0312, -0.0308,  0.0151],\n",
            "          [ 0.0205, -0.0169,  0.0137],\n",
            "          [ 0.0144,  0.0104, -0.0143]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0268, -0.0153,  0.0155],\n",
            "          [-0.0260,  0.0176, -0.0315],\n",
            "          [ 0.0425, -0.0170,  0.0299]],\n",
            "\n",
            "         [[-0.0313,  0.0332,  0.0169],\n",
            "          [-0.0186, -0.0065, -0.0172],\n",
            "          [-0.0351, -0.0221, -0.0034]],\n",
            "\n",
            "         [[-0.0139, -0.0405, -0.0127],\n",
            "          [ 0.0201,  0.0314, -0.0390],\n",
            "          [ 0.0350, -0.0074,  0.0300]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0002,  0.0272,  0.0116],\n",
            "          [ 0.0204,  0.0061, -0.0364],\n",
            "          [ 0.0010, -0.0236,  0.0257]],\n",
            "\n",
            "         [[-0.0062, -0.0062, -0.0279],\n",
            "          [-0.0042,  0.0184,  0.0230],\n",
            "          [-0.0173, -0.0386, -0.0106]],\n",
            "\n",
            "         [[-0.0310, -0.0370,  0.0378],\n",
            "          [-0.0299, -0.0387, -0.0218],\n",
            "          [-0.0214,  0.0282, -0.0313]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0402,  0.0063,  0.0142],\n",
            "          [-0.0073, -0.0057,  0.0313],\n",
            "          [ 0.0395, -0.0326, -0.0157]],\n",
            "\n",
            "         [[ 0.0173, -0.0377, -0.0215],\n",
            "          [-0.0363, -0.0421,  0.0394],\n",
            "          [-0.0261, -0.0135,  0.0359]],\n",
            "\n",
            "         [[ 0.0348,  0.0331, -0.0347],\n",
            "          [-0.0228, -0.0161, -0.0390],\n",
            "          [ 0.0217,  0.0193, -0.0397]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0407, -0.0381, -0.0184],\n",
            "          [ 0.0395, -0.0060,  0.0089],\n",
            "          [-0.0035, -0.0251,  0.0190]],\n",
            "\n",
            "         [[ 0.0288,  0.0190,  0.0234],\n",
            "          [ 0.0317,  0.0302, -0.0224],\n",
            "          [ 0.0137, -0.0154,  0.0189]],\n",
            "\n",
            "         [[ 0.0080, -0.0050, -0.0372],\n",
            "          [ 0.0335, -0.0383,  0.0192],\n",
            "          [-0.0252,  0.0380, -0.0317]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0215, -0.0358, -0.0363],\n",
            "          [-0.0202, -0.0081,  0.0411],\n",
            "          [-0.0254,  0.0172,  0.0059]],\n",
            "\n",
            "         [[-0.0409, -0.0417,  0.0260],\n",
            "          [ 0.0200,  0.0050, -0.0320],\n",
            "          [ 0.0324, -0.0068,  0.0118]],\n",
            "\n",
            "         [[-0.0344, -0.0400,  0.0279],\n",
            "          [ 0.0088,  0.0393, -0.0264],\n",
            "          [-0.0215,  0.0410, -0.0218]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0157,  0.0254, -0.0260],\n",
            "          [-0.0278, -0.0387,  0.0266],\n",
            "          [-0.0361,  0.0230, -0.0339]],\n",
            "\n",
            "         [[ 0.0046, -0.0221, -0.0184],\n",
            "          [-0.0230, -0.0196, -0.0138],\n",
            "          [-0.0387, -0.0297, -0.0083]],\n",
            "\n",
            "         [[ 0.0101,  0.0163, -0.0386],\n",
            "          [-0.0205, -0.0150, -0.0330],\n",
            "          [ 0.0168, -0.0008,  0.0229]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0332,  0.0118,  0.0090],\n",
            "          [-0.0161, -0.0151, -0.0308],\n",
            "          [-0.0043, -0.0313, -0.0186]],\n",
            "\n",
            "         [[ 0.0048, -0.0373, -0.0323],\n",
            "          [-0.0220,  0.0198, -0.0317],\n",
            "          [-0.0406,  0.0005,  0.0144]],\n",
            "\n",
            "         [[-0.0072, -0.0184, -0.0011],\n",
            "          [ 0.0368, -0.0410, -0.0363],\n",
            "          [-0.0140, -0.0295, -0.0021]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0024,  0.0214, -0.0161],\n",
            "          [-0.0336, -0.0271,  0.0329],\n",
            "          [ 0.0017,  0.0253,  0.0266]],\n",
            "\n",
            "         [[ 0.0166,  0.0275, -0.0369],\n",
            "          [-0.0293, -0.0341, -0.0229],\n",
            "          [ 0.0264,  0.0191,  0.0229]],\n",
            "\n",
            "         [[ 0.0328,  0.0367,  0.0309],\n",
            "          [ 0.0257, -0.0162, -0.0279],\n",
            "          [-0.0252, -0.0153,  0.0268]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0181,  0.0058,  0.0333],\n",
            "          [ 0.0092, -0.0300, -0.0262],\n",
            "          [-0.0067, -0.0059,  0.0206]],\n",
            "\n",
            "         [[ 0.0202, -0.0173,  0.0051],\n",
            "          [-0.0340, -0.0420, -0.0021],\n",
            "          [-0.0150,  0.0284, -0.0299]],\n",
            "\n",
            "         [[ 0.0169, -0.0350, -0.0325],\n",
            "          [ 0.0057,  0.0351,  0.0258],\n",
            "          [ 0.0354,  0.0128,  0.0085]]]])), ('conv4.bias', tensor([ 2.7692e-05,  6.3129e-04,  2.0235e-05, -4.4391e-05, -2.2232e-03,\n",
            "        -1.6992e-04, -2.9617e-05, -8.5590e-05,  1.6619e-02,  6.2208e-03,\n",
            "         7.4799e-03, -5.1201e-03, -9.3739e-05,  1.7031e-02, -7.0020e-03,\n",
            "        -5.2953e-04,  1.5242e-02, -2.0976e-05, -1.1461e-02,  3.6919e-04,\n",
            "         5.7971e-03,  3.1561e-03,  7.6880e-05,  9.8370e-03, -1.6974e-02,\n",
            "         1.2239e-05,  1.9736e-02, -6.7061e-03, -2.0485e-05,  1.3111e-03,\n",
            "        -2.3064e-03, -4.3410e-05,  2.9322e-04, -3.6299e-04,  1.7764e-02,\n",
            "         1.6720e-02, -1.2013e-02,  8.2494e-04, -1.3968e-04, -8.6049e-03,\n",
            "        -1.1808e-02, -6.4893e-03, -3.0154e-03,  2.9731e-05,  9.8462e-05,\n",
            "         1.1322e-02,  8.0911e-03, -3.7414e-04, -3.3778e-03, -8.2487e-03,\n",
            "         2.1787e-04, -5.2201e-03,  7.5742e-03,  1.0644e-04, -1.5073e-02,\n",
            "         8.1053e-05, -8.9382e-04,  8.3898e-03,  2.0118e-04,  8.5609e-04,\n",
            "         3.5671e-05, -2.1131e-04, -1.0016e-02, -3.6635e-05, -9.9198e-03,\n",
            "         9.1426e-03, -1.7934e-06,  4.6273e-06,  5.2522e-05, -3.2901e-05,\n",
            "        -9.9549e-06,  1.3457e-05, -3.0888e-03, -4.6644e-03, -1.5272e-03,\n",
            "         3.4812e-06,  1.8898e-02, -7.7902e-05,  1.7400e-04,  1.8537e-02,\n",
            "        -8.7357e-03, -2.9738e-03,  6.0988e-03, -1.2402e-02, -4.2122e-05,\n",
            "         8.8765e-03, -4.6981e-04,  1.7087e-05, -9.4930e-04, -1.1101e-02,\n",
            "        -6.9361e-03,  1.1418e-02,  1.2143e-03,  4.7152e-03,  6.3093e-03,\n",
            "         8.2714e-03, -1.7708e-02, -8.6712e-03, -8.7837e-04, -8.8220e-03,\n",
            "         1.4102e-03,  1.2769e-05,  5.5785e-03, -4.3429e-04, -2.9702e-06,\n",
            "         1.2965e-02, -1.0265e-02, -1.3515e-03, -5.6543e-05, -1.4777e-04,\n",
            "         2.9187e-03, -4.6816e-06,  1.8546e-05, -1.1613e-02,  1.1045e-02,\n",
            "        -5.0049e-03,  3.4366e-05, -1.0407e-03, -1.7981e-05, -2.2771e-04,\n",
            "         6.5552e-05,  1.8743e-04, -1.8188e-02,  1.8582e-03,  2.3781e-06,\n",
            "        -6.6245e-03, -1.9662e-05,  9.7964e-04])), ('bn4.weight', tensor([0.9982, 0.9996, 0.9983, 1.0026, 0.9984, 0.9955, 0.9983, 0.9970, 0.9989,\n",
            "        0.9982, 0.9956, 0.9997, 0.9980, 0.9999, 1.0001, 1.0015, 0.9999, 0.9986,\n",
            "        0.9990, 0.9982, 0.9982, 0.9983, 0.9989, 1.0033, 1.0003, 0.9976, 0.9995,\n",
            "        1.0003, 0.9998, 0.9999, 0.9965, 0.9965, 0.9984, 0.9969, 0.9995, 1.0000,\n",
            "        0.9990, 1.0007, 0.9974, 0.9959, 1.0001, 0.9973, 0.9974, 0.9979, 0.9975,\n",
            "        1.0012, 0.9994, 0.9959, 0.9962, 0.9954, 0.9982, 0.9964, 1.0016, 0.9965,\n",
            "        0.9958, 0.9978, 0.9985, 1.0007, 1.0006, 1.0004, 0.9940, 0.9966, 0.9994,\n",
            "        1.0004, 0.9979, 1.0006, 0.9980, 0.9997, 1.0015, 0.9979, 0.9979, 0.9973,\n",
            "        0.9981, 0.9964, 0.9988, 0.9975, 0.9982, 0.9976, 0.9982, 1.0013, 1.0018,\n",
            "        0.9993, 0.9998, 0.9974, 1.0020, 0.9951, 0.9996, 1.0002, 0.9954, 1.0000,\n",
            "        0.9985, 0.9977, 0.9992, 0.9996, 0.9978, 1.0002, 0.9958, 0.9961, 0.9983,\n",
            "        0.9966, 1.0000, 0.9975, 0.9973, 0.9968, 0.9950, 1.0003, 0.9987, 0.9992,\n",
            "        0.9999, 1.0019, 0.9976, 0.9998, 0.9994, 1.0003, 1.0004, 1.0010, 1.0005,\n",
            "        0.9978, 0.9972, 0.9974, 1.0014, 1.0006, 0.9963, 1.0001, 0.9975, 0.9990,\n",
            "        0.9946, 1.0021])), ('bn4.bias', tensor([-1.4094e-03,  1.8803e-03, -4.2968e-04,  1.6408e-03, -2.2936e-03,\n",
            "        -1.3414e-03, -1.3323e-04, -7.4959e-04,  1.1684e-03,  1.4354e-03,\n",
            "        -2.2065e-03,  2.7037e-03, -7.6270e-04,  3.4841e-03,  1.1846e-03,\n",
            "         1.8602e-03, -8.3893e-04, -1.7305e-04,  2.0012e-03, -1.2932e-03,\n",
            "         1.3319e-03,  2.3539e-03, -6.2351e-04,  1.0044e-03,  1.4963e-03,\n",
            "        -7.0300e-04,  1.7757e-04,  2.4532e-04,  5.3694e-04,  1.0919e-03,\n",
            "        -2.2500e-03, -1.1020e-03, -1.8902e-03, -3.6021e-04,  1.0356e-03,\n",
            "         1.3845e-03, -8.8372e-04,  2.2981e-03, -1.1924e-03, -1.4450e-03,\n",
            "        -1.0278e-04,  3.5413e-04, -8.6696e-04,  1.1427e-03, -1.2478e-03,\n",
            "         2.8528e-03, -2.6298e-03, -7.8708e-04, -2.7324e-03, -1.0977e-03,\n",
            "        -8.2180e-04, -1.7776e-03,  2.2105e-03, -1.7263e-03, -2.0479e-03,\n",
            "        -1.8293e-04,  1.1898e-04,  5.7843e-04,  1.5307e-03, -2.0810e-04,\n",
            "        -1.3862e-03, -1.8340e-03, -3.1763e-03,  1.2415e-03, -2.4956e-03,\n",
            "         9.0332e-04,  5.9424e-05,  2.5207e-03,  1.7620e-03, -2.7930e-03,\n",
            "        -6.2879e-04, -4.1701e-04, -6.2384e-04, -9.6356e-04,  1.4436e-03,\n",
            "         1.2380e-03,  4.9825e-04,  4.5695e-04,  2.3401e-04,  3.6807e-03,\n",
            "         3.0061e-03,  7.5586e-04, -2.0485e-03, -3.3984e-04,  2.9898e-03,\n",
            "        -2.9237e-03,  7.3730e-04,  1.1349e-03, -3.1568e-03,  3.7774e-03,\n",
            "         1.4926e-03,  1.1322e-03,  1.5021e-03,  2.4179e-04, -1.2669e-04,\n",
            "         5.3254e-04, -2.3780e-03,  1.4235e-03, -3.9548e-04, -2.8117e-03,\n",
            "        -1.1315e-03, -3.6986e-05, -2.2747e-03, -1.5748e-04, -3.0777e-03,\n",
            "         1.4839e-03, -3.1574e-05,  8.6622e-04, -2.8320e-04,  1.1953e-03,\n",
            "         1.5181e-03, -4.4681e-04,  5.4943e-03,  1.3453e-03,  1.0984e-03,\n",
            "         9.3263e-04, -3.2536e-03, -9.9353e-04, -8.5723e-05, -3.2100e-04,\n",
            "        -8.5802e-04,  1.9623e-03, -2.8163e-04,  3.7789e-04, -1.7946e-03,\n",
            "         1.6462e-03, -2.9536e-03,  4.0758e-03])), ('bn4.running_mean', tensor([ 0.2031,  0.0429,  0.1765,  0.3363, -0.2346, -0.5445, -0.5494,  0.0200,\n",
            "        -0.6032,  0.0215, -0.6024, -0.3633, -0.5664,  0.3403,  0.0607,  0.5388,\n",
            "         0.1404,  0.5615,  0.1220,  0.7561, -0.2368, -0.3877, -0.1365,  0.0672,\n",
            "         0.3333,  0.3117, -0.2338,  0.5868, -0.5987,  0.0925,  0.6249,  0.0811,\n",
            "         0.5188, -0.2934,  0.3861,  0.2932,  0.5198,  0.5470, -0.0975, -0.2096,\n",
            "        -0.4018,  0.6247,  0.9366, -0.2989,  0.4476,  0.2183, -0.0156,  0.5507,\n",
            "         0.0603, -0.6072,  0.5771,  0.0493,  0.4091, -0.1501, -0.2656, -0.4994,\n",
            "         0.6226, -0.0439, -0.2447,  0.2360, -0.2394, -0.6054, -0.2118, -0.5915,\n",
            "        -0.3721,  0.1952,  0.3150,  0.2110,  0.2807,  0.3069, -0.0685, -0.2537,\n",
            "        -0.1922, -0.1193,  0.2287,  0.7223,  0.7738, -0.3175,  0.2847,  0.1848,\n",
            "         0.3382,  0.0053,  0.2039,  0.3297, -0.0306, -0.0879, -0.0241,  0.5805,\n",
            "         0.0360,  0.0287, -0.0059, -0.0703, -0.1705, -0.2082, -0.2009,  0.3331,\n",
            "         0.4489,  0.1824,  0.7010, -0.1585,  0.3394, -0.2048, -0.1720,  0.3409,\n",
            "        -0.0360,  0.3767,  0.0936,  0.5672, -0.0439,  0.2346,  0.0018, -0.1348,\n",
            "         0.0961,  0.4305,  0.3750,  0.5127, -0.0614, -0.0309,  0.4540, -0.0995,\n",
            "         0.1711, -0.3250, -0.1107,  0.2645,  0.0847,  0.3670, -0.4889, -0.0831])), ('bn4.running_var', tensor([0.1901, 0.2008, 0.3338, 0.1542, 0.2336, 0.3095, 0.2007, 0.1930, 0.3781,\n",
            "        0.1473, 0.2520, 0.3773, 0.2402, 0.1753, 0.1823, 0.1235, 0.3297, 0.1944,\n",
            "        0.2383, 0.2183, 0.1484, 0.1832, 0.3205, 0.3766, 0.1846, 0.1873, 0.1885,\n",
            "        0.3331, 0.3307, 0.2198, 0.2866, 0.1525, 0.2185, 0.1401, 0.2468, 0.1707,\n",
            "        0.2069, 0.4705, 0.1742, 0.2531, 0.1606, 0.2878, 0.2323, 0.1971, 0.1614,\n",
            "        0.2265, 0.1615, 0.1345, 0.1769, 0.2433, 0.2137, 0.3057, 0.2796, 0.2145,\n",
            "        0.2634, 0.2495, 0.4004, 0.3809, 0.1726, 0.3127, 0.1220, 0.3140, 0.1363,\n",
            "        0.3269, 0.2328, 0.3022, 0.3269, 0.2493, 0.1806, 0.2915, 0.2499, 0.1973,\n",
            "        0.1415, 0.1742, 0.2440, 0.2098, 0.3712, 0.2721, 0.1138, 0.2507, 0.1436,\n",
            "        0.1312, 0.2051, 0.2674, 0.2478, 0.1662, 0.2707, 0.3216, 0.1653, 0.1225,\n",
            "        0.4156, 0.2681, 0.2052, 0.2501, 0.1812, 0.2250, 0.1948, 0.1114, 0.2714,\n",
            "        0.2822, 0.1840, 0.1611, 0.2115, 0.3228, 0.1738, 0.2354, 0.4550, 0.2861,\n",
            "        0.2809, 0.4633, 0.1486, 0.1335, 0.3044, 0.3093, 0.2477, 0.2385, 0.4170,\n",
            "        0.3493, 0.1954, 0.2615, 0.2708, 0.2573, 0.2582, 0.1619, 0.2517, 0.2116,\n",
            "        0.1977, 0.2771])), ('bn4.num_batches_tracked', tensor(250)), ('conv5.weight', tensor([[[[ 9.8049e-04, -2.2376e-02, -2.3872e-03],\n",
            "          [-5.5306e-04, -7.7575e-04, -1.5286e-02],\n",
            "          [-2.2724e-02, -2.8767e-02, -2.5284e-02]],\n",
            "\n",
            "         [[ 6.7514e-03, -2.3086e-02,  2.3575e-02],\n",
            "          [-1.9428e-02, -6.6155e-03,  1.8667e-02],\n",
            "          [ 2.7072e-02,  7.5213e-03, -1.8107e-02]],\n",
            "\n",
            "         [[-1.4080e-02, -5.5760e-03,  1.2290e-02],\n",
            "          [-2.6753e-02,  8.7113e-03,  8.2681e-03],\n",
            "          [ 1.5501e-02, -1.9889e-02,  2.6137e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5516e-02, -3.0552e-02, -2.0296e-04],\n",
            "          [ 2.3083e-02, -2.9383e-02,  4.1489e-04],\n",
            "          [-9.1452e-03, -1.5831e-02,  1.4732e-03]],\n",
            "\n",
            "         [[ 6.7390e-03,  1.2931e-02,  8.4053e-03],\n",
            "          [-1.0725e-02,  2.7474e-02,  1.1276e-02],\n",
            "          [-2.5389e-03, -2.7084e-02, -2.2875e-02]],\n",
            "\n",
            "         [[ 8.9898e-03, -1.7282e-02,  9.5057e-04],\n",
            "          [ 1.4333e-02,  2.0862e-02, -1.8044e-03],\n",
            "          [ 5.6140e-03,  3.3851e-03, -1.9844e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8307e-02, -5.0227e-03, -1.0206e-02],\n",
            "          [-1.5072e-02, -2.5751e-02, -1.7509e-02],\n",
            "          [-1.6048e-02, -2.0900e-02,  6.5889e-03]],\n",
            "\n",
            "         [[-5.7851e-03, -2.2657e-02, -2.1300e-02],\n",
            "          [-2.4893e-02,  2.9599e-02,  6.4291e-03],\n",
            "          [-1.1431e-02,  2.0045e-02, -1.5115e-02]],\n",
            "\n",
            "         [[-8.4669e-03, -1.7406e-02,  3.3247e-03],\n",
            "          [ 2.2792e-02,  1.5072e-02,  1.8437e-02],\n",
            "          [ 1.5829e-02,  3.5654e-03, -9.2617e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3528e-02,  1.2471e-02,  2.6156e-02],\n",
            "          [ 5.0628e-03,  2.9798e-03, -6.5201e-03],\n",
            "          [ 2.3640e-02,  1.0155e-02, -2.5764e-03]],\n",
            "\n",
            "         [[-1.5279e-02,  2.3133e-02,  4.2392e-03],\n",
            "          [-7.2119e-03, -2.5009e-02, -8.2094e-04],\n",
            "          [ 1.6579e-02,  8.2379e-03,  2.3200e-02]],\n",
            "\n",
            "         [[-4.3652e-03, -2.3031e-02,  2.3345e-03],\n",
            "          [ 3.0903e-02,  1.0149e-02,  3.3269e-03],\n",
            "          [-9.4867e-03,  2.0180e-02,  1.0364e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9357e-03, -2.1673e-02, -6.2173e-03],\n",
            "          [-1.3519e-02,  7.8085e-03,  6.0055e-03],\n",
            "          [ 8.4977e-03, -2.7390e-02,  2.5665e-02]],\n",
            "\n",
            "         [[ 1.1007e-02,  5.8228e-03,  2.9887e-02],\n",
            "          [-2.3366e-02, -2.4576e-02,  2.3735e-02],\n",
            "          [-8.7860e-03, -1.4077e-02, -5.4844e-03]],\n",
            "\n",
            "         [[-2.1477e-02, -1.5434e-02, -2.4742e-02],\n",
            "          [-3.9659e-03, -3.3305e-03,  2.2562e-02],\n",
            "          [-2.3709e-02, -1.3466e-02,  2.4886e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.6290e-02,  2.1469e-02, -2.6731e-02],\n",
            "          [ 5.6392e-03,  9.5104e-05, -6.9115e-03],\n",
            "          [ 1.2692e-02, -2.5462e-02,  1.3848e-02]],\n",
            "\n",
            "         [[-6.2601e-03,  6.5293e-03,  2.4117e-02],\n",
            "          [-1.5029e-02, -2.2929e-02,  2.8067e-02],\n",
            "          [-2.4405e-02, -1.7794e-02, -2.4397e-02]],\n",
            "\n",
            "         [[ 1.7212e-02, -1.0674e-02, -2.7328e-02],\n",
            "          [-2.2627e-02,  2.4979e-02,  2.8814e-02],\n",
            "          [-2.2155e-02,  2.1282e-02,  3.0453e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.0995e-02,  5.0655e-03,  9.8714e-04],\n",
            "          [-2.1128e-02, -9.0885e-03, -1.7778e-02],\n",
            "          [ 2.3432e-02,  2.2730e-02, -8.6558e-03]],\n",
            "\n",
            "         [[ 3.0327e-02, -1.3083e-02, -3.8129e-03],\n",
            "          [-1.1075e-02,  1.1309e-02, -1.6594e-02],\n",
            "          [-1.1773e-02, -4.9823e-03, -1.1276e-02]],\n",
            "\n",
            "         [[ 3.5241e-03, -2.6479e-02,  1.9661e-02],\n",
            "          [ 2.4395e-02,  1.1658e-02,  1.5673e-02],\n",
            "          [ 1.9148e-02, -2.3572e-02, -1.5757e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1116e-02, -2.6417e-02,  1.1332e-02],\n",
            "          [ 8.2867e-04, -3.0614e-02,  2.3246e-02],\n",
            "          [ 2.1954e-02, -7.9065e-03, -1.9200e-02]],\n",
            "\n",
            "         [[ 1.7398e-02, -1.0083e-03, -5.2842e-03],\n",
            "          [-2.4344e-02,  1.8174e-02, -4.0523e-04],\n",
            "          [-1.4372e-02, -9.4070e-03, -1.8783e-02]],\n",
            "\n",
            "         [[ 1.8241e-02, -2.2119e-02,  1.6801e-02],\n",
            "          [ 8.0399e-03, -1.2787e-02,  8.9585e-03],\n",
            "          [ 2.0039e-03, -1.5775e-02, -1.4868e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8203e-02,  2.4497e-02, -1.7467e-03],\n",
            "          [-2.7107e-02, -1.5722e-02,  1.2588e-02],\n",
            "          [-6.9208e-03,  2.3170e-02,  2.7383e-03]],\n",
            "\n",
            "         [[ 9.6079e-03, -1.4715e-02,  1.2265e-02],\n",
            "          [-2.8963e-02, -2.2877e-02,  4.4653e-03],\n",
            "          [-2.4738e-02, -2.3606e-02, -1.4067e-02]],\n",
            "\n",
            "         [[ 7.0846e-03, -2.6151e-02,  1.8598e-02],\n",
            "          [ 2.3351e-02, -1.5334e-02,  1.2707e-02],\n",
            "          [ 1.6333e-02, -1.3825e-02,  1.0931e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2953e-02, -1.9109e-02,  1.6233e-02],\n",
            "          [ 1.5432e-02,  1.5138e-02,  2.0334e-03],\n",
            "          [-2.6429e-02, -1.9787e-03, -1.2718e-02]],\n",
            "\n",
            "         [[-3.9954e-05,  2.7330e-02,  1.3228e-02],\n",
            "          [-1.8607e-02, -2.7782e-02, -1.0136e-02],\n",
            "          [-5.7770e-04,  9.3960e-03,  2.5989e-02]],\n",
            "\n",
            "         [[ 2.7708e-02,  1.9634e-02, -1.0186e-02],\n",
            "          [-2.8272e-03,  2.1611e-02,  2.7464e-02],\n",
            "          [-1.6908e-02,  1.8537e-02, -2.5848e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4312e-03,  1.0508e-02,  2.4115e-02],\n",
            "          [-4.3091e-03,  9.2171e-03,  1.3419e-02],\n",
            "          [ 2.5369e-02, -1.8934e-02, -8.2891e-04]],\n",
            "\n",
            "         [[-2.5216e-02,  7.0590e-03,  2.7461e-02],\n",
            "          [ 2.1473e-02,  9.3752e-03,  1.0329e-02],\n",
            "          [-1.5866e-02,  8.8066e-03, -5.5407e-03]],\n",
            "\n",
            "         [[-1.7773e-02,  1.8180e-02, -2.8346e-02],\n",
            "          [ 1.2488e-02,  7.9567e-03,  1.0788e-02],\n",
            "          [-4.5004e-03, -1.4792e-02,  2.0067e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.6863e-03, -1.8985e-02,  9.3457e-03],\n",
            "          [ 6.8591e-03, -2.2485e-02, -1.7136e-02],\n",
            "          [-8.5615e-03,  2.4476e-02,  1.7945e-03]],\n",
            "\n",
            "         [[-2.1662e-03, -8.2621e-03,  2.3792e-02],\n",
            "          [ 1.2886e-02,  2.6667e-02, -8.1797e-03],\n",
            "          [-2.6666e-02, -2.8548e-02,  2.3121e-02]],\n",
            "\n",
            "         [[ 6.1534e-03, -5.1435e-03, -1.3251e-02],\n",
            "          [ 2.0142e-02, -6.5056e-04, -2.1359e-02],\n",
            "          [ 6.9320e-04, -1.0906e-03, -2.6522e-02]]]])), ('conv5.bias', tensor([ 1.9107e-06, -9.8446e-03, -2.3622e-03,  2.9792e-03,  1.0926e-03,\n",
            "         1.1911e-03,  2.2979e-05,  8.3281e-06,  5.3589e-03,  1.8996e-03,\n",
            "        -1.1287e-04, -4.9269e-03, -9.1052e-06,  1.0485e-05, -1.0077e-03,\n",
            "         2.5478e-07, -4.2722e-06,  9.4989e-03,  5.5734e-03, -3.6306e-04,\n",
            "        -1.4044e-03, -4.5939e-03,  1.2472e-06,  2.5748e-03, -4.1753e-03,\n",
            "        -1.5442e-06,  4.7103e-03, -4.8057e-04, -9.1341e-03, -3.1514e-03,\n",
            "         5.6205e-03, -4.0953e-06,  2.8721e-03,  2.2552e-05, -7.2508e-04,\n",
            "         1.5142e-04,  2.9065e-03,  3.1697e-04,  4.1649e-06,  3.4461e-03,\n",
            "        -4.7686e-03,  5.9845e-05,  1.2954e-05, -2.4915e-03,  5.6730e-06,\n",
            "         3.9636e-03, -7.9061e-03, -3.4720e-03, -2.2544e-04,  1.4580e-05,\n",
            "        -2.2398e-03,  6.7969e-03,  1.5810e-05, -1.4281e-06, -2.5395e-04,\n",
            "         2.3666e-06,  6.7024e-03, -3.1856e-03,  7.6217e-05, -9.7992e-06,\n",
            "        -9.4821e-04,  1.9198e-03, -6.5796e-03,  4.1837e-04,  6.5535e-07,\n",
            "         7.3582e-06,  8.8264e-03,  2.3536e-05, -2.7656e-03,  1.9488e-05,\n",
            "         2.8492e-03,  4.4689e-05, -7.0392e-03, -1.0700e-06, -3.0395e-03,\n",
            "        -5.1409e-03,  9.1368e-05,  6.1398e-06, -2.8181e-06, -8.3792e-03,\n",
            "        -7.3028e-03,  4.3500e-06, -2.6303e-03, -2.1168e-03, -5.0470e-06,\n",
            "        -8.1290e-03,  4.3287e-04,  8.5663e-04, -1.6309e-04, -2.8291e-03,\n",
            "         6.4471e-06,  7.0560e-06,  3.2061e-06, -7.6356e-03,  4.6305e-04,\n",
            "         1.3192e-03,  2.5165e-04,  7.1707e-03, -1.7955e-06,  8.2303e-03,\n",
            "        -7.1033e-03, -6.4196e-03, -1.0932e-03,  2.0263e-03,  7.0728e-06,\n",
            "        -3.1817e-03, -7.0852e-03, -1.7637e-04,  2.9772e-05, -7.6864e-06,\n",
            "         6.1259e-07,  2.9987e-06,  3.5990e-03, -7.8965e-05, -3.5159e-03,\n",
            "        -2.0230e-03, -2.9453e-04, -6.7535e-03, -5.5194e-05,  5.7152e-03,\n",
            "        -4.3799e-06,  1.0417e-05,  5.4505e-03, -5.1618e-06, -1.2141e-04,\n",
            "        -8.8432e-06, -5.2610e-06,  3.0718e-06,  5.3431e-03,  1.8188e-03,\n",
            "        -1.0312e-05,  2.0882e-03, -2.6570e-03,  6.3425e-04, -2.7099e-03,\n",
            "        -2.9303e-03, -5.0812e-03, -7.4533e-04,  6.6991e-05,  6.7700e-04,\n",
            "         5.4737e-03,  2.3444e-05,  9.9006e-07,  6.8153e-06, -7.2404e-03,\n",
            "         3.0611e-03,  5.7073e-06,  4.0235e-03, -2.7386e-03,  4.4346e-03,\n",
            "        -1.1226e-05,  4.2009e-06, -2.6568e-05,  2.2015e-03,  1.1943e-05,\n",
            "         3.3527e-03,  5.1018e-07,  6.3127e-03,  1.7364e-07, -9.3897e-03,\n",
            "         5.0667e-03,  6.8440e-04, -2.4212e-03, -1.0077e-06, -4.7208e-03,\n",
            "         2.3903e-03, -9.7615e-06,  5.9873e-07,  1.8674e-04,  1.7784e-03,\n",
            "        -5.4031e-03,  8.0627e-03,  2.5401e-03, -5.4772e-03,  3.1733e-05,\n",
            "         9.7013e-03,  2.0922e-06,  5.6026e-03, -4.2405e-03,  5.6335e-05,\n",
            "        -6.7109e-06, -3.4840e-04,  1.5571e-05,  8.4905e-03,  8.5708e-03,\n",
            "        -6.2653e-06,  1.7865e-04,  5.9322e-03, -8.3703e-04,  6.2401e-03,\n",
            "         2.3111e-07,  3.4454e-03,  4.0242e-03, -4.4291e-06,  1.3333e-05,\n",
            "         7.7288e-06, -9.5511e-03, -9.3744e-03,  4.8854e-06, -1.4090e-05,\n",
            "        -7.9869e-03, -9.3871e-06,  6.3063e-04, -2.1392e-05, -5.3651e-06,\n",
            "         7.6599e-03,  1.2292e-03, -6.8662e-06, -6.7890e-03, -4.4915e-06,\n",
            "         3.9820e-03, -1.3650e-03,  9.3111e-03,  2.4221e-03,  9.5185e-04,\n",
            "         2.1100e-07, -3.4328e-04,  6.0425e-03, -1.6962e-05, -2.4247e-05,\n",
            "        -4.9368e-03,  5.9397e-06,  3.1042e-03,  4.2298e-06, -7.3475e-03,\n",
            "         6.8933e-04,  2.7336e-03,  3.7634e-03, -7.7252e-06,  9.1023e-03,\n",
            "        -4.9580e-06,  2.1434e-04, -7.3898e-03, -9.0203e-03, -1.2294e-03,\n",
            "        -9.5004e-03,  1.0191e-02,  2.9939e-05, -3.6432e-06,  5.2959e-06,\n",
            "        -2.2500e-05, -1.5283e-04, -5.1931e-03,  6.4691e-06,  3.4361e-04,\n",
            "         8.4073e-03, -8.2415e-06,  1.5260e-04,  2.8346e-04,  5.0854e-04,\n",
            "        -1.1682e-05,  7.7098e-04, -6.5792e-04, -3.6651e-03, -7.8220e-03,\n",
            "         8.6269e-03])), ('bn5.weight', tensor([0.9964, 0.9977, 0.9971, 0.9980, 0.9976, 0.9965, 1.0002, 0.9976, 0.9996,\n",
            "        0.9945, 0.9983, 0.9976, 0.9968, 1.0012, 0.9978, 0.9961, 0.9971, 0.9965,\n",
            "        1.0006, 0.9991, 0.9970, 0.9984, 0.9986, 0.9968, 0.9998, 0.9949, 0.9987,\n",
            "        0.9977, 0.9971, 0.9948, 0.9987, 0.9965, 0.9972, 0.9987, 0.9957, 0.9957,\n",
            "        0.9965, 0.9954, 0.9948, 0.9975, 0.9973, 0.9983, 0.9976, 0.9960, 0.9968,\n",
            "        0.9961, 0.9975, 0.9955, 0.9980, 0.9965, 0.9961, 0.9980, 0.9973, 0.9987,\n",
            "        0.9954, 1.0003, 0.9983, 0.9966, 0.9988, 0.9979, 0.9965, 0.9966, 0.9955,\n",
            "        0.9961, 0.9978, 0.9974, 0.9957, 0.9977, 0.9981, 0.9990, 0.9982, 0.9941,\n",
            "        0.9971, 0.9941, 0.9970, 0.9954, 0.9971, 0.9997, 0.9972, 0.9976, 0.9952,\n",
            "        0.9948, 0.9973, 0.9970, 0.9969, 0.9957, 0.9960, 0.9954, 0.9941, 0.9975,\n",
            "        0.9974, 0.9992, 0.9977, 0.9969, 0.9985, 0.9977, 0.9980, 0.9965, 0.9969,\n",
            "        0.9974, 0.9967, 0.9980, 0.9970, 0.9966, 0.9974, 0.9969, 0.9983, 0.9971,\n",
            "        0.9991, 0.9964, 0.9964, 0.9950, 0.9966, 0.9987, 0.9972, 0.9989, 0.9988,\n",
            "        0.9976, 0.9970, 0.9986, 0.9946, 0.9981, 0.9951, 0.9972, 0.9987, 0.9976,\n",
            "        0.9974, 0.9964, 0.9948, 0.9966, 0.9975, 0.9990, 0.9991, 0.9966, 0.9976,\n",
            "        0.9972, 0.9970, 0.9966, 0.9991, 0.9957, 0.9944, 0.9985, 0.9981, 0.9966,\n",
            "        0.9952, 0.9977, 0.9979, 0.9994, 0.9966, 0.9979, 0.9971, 0.9947, 0.9979,\n",
            "        0.9984, 0.9990, 0.9988, 0.9969, 0.9965, 0.9982, 0.9967, 0.9961, 0.9978,\n",
            "        0.9962, 0.9965, 0.9962, 0.9980, 0.9957, 0.9938, 0.9958, 0.9957, 0.9962,\n",
            "        0.9985, 0.9974, 0.9996, 0.9988, 0.9961, 0.9969, 0.9978, 0.9955, 0.9954,\n",
            "        0.9954, 0.9961, 0.9959, 0.9976, 0.9976, 0.9981, 0.9951, 0.9971, 0.9991,\n",
            "        0.9980, 0.9986, 0.9985, 0.9977, 0.9978, 0.9976, 0.9962, 0.9979, 0.9966,\n",
            "        0.9965, 0.9963, 0.9972, 0.9979, 0.9962, 0.9964, 0.9962, 0.9991, 0.9982,\n",
            "        0.9953, 0.9956, 0.9977, 0.9966, 0.9968, 0.9956, 0.9967, 0.9951, 0.9996,\n",
            "        0.9989, 0.9979, 0.9973, 0.9995, 0.9978, 0.9974, 0.9975, 0.9979, 0.9981,\n",
            "        0.9989, 0.9968, 0.9969, 0.9962, 1.0000, 0.9956, 0.9984, 0.9973, 0.9957,\n",
            "        0.9981, 0.9984, 0.9949, 0.9954, 0.9978, 0.9976, 0.9973, 0.9954, 0.9975,\n",
            "        0.9990, 0.9965, 0.9980, 0.9957, 0.9964, 0.9959, 0.9982, 0.9956, 1.0003,\n",
            "        0.9962, 0.9971, 0.9948, 1.0004])), ('bn5.bias', tensor([-0.0033, -0.0024, -0.0026, -0.0027, -0.0031, -0.0028, -0.0015, -0.0031,\n",
            "        -0.0016, -0.0044, -0.0018, -0.0027, -0.0016, -0.0005, -0.0029, -0.0021,\n",
            "        -0.0024, -0.0029, -0.0014, -0.0024, -0.0021, -0.0013, -0.0020, -0.0033,\n",
            "        -0.0009, -0.0044, -0.0020, -0.0038, -0.0035, -0.0035, -0.0012, -0.0019,\n",
            "        -0.0024, -0.0015, -0.0046, -0.0040, -0.0032, -0.0032, -0.0045, -0.0023,\n",
            "        -0.0026, -0.0022, -0.0027, -0.0022, -0.0032, -0.0041, -0.0021, -0.0062,\n",
            "        -0.0025, -0.0040, -0.0027, -0.0017, -0.0029, -0.0015, -0.0037, -0.0012,\n",
            "        -0.0025, -0.0034,  0.0002, -0.0028, -0.0021, -0.0044, -0.0029, -0.0033,\n",
            "        -0.0019, -0.0033, -0.0035, -0.0026, -0.0027, -0.0022, -0.0023, -0.0052,\n",
            "        -0.0031, -0.0043, -0.0021, -0.0031, -0.0030, -0.0008, -0.0026, -0.0030,\n",
            "        -0.0034, -0.0034, -0.0016, -0.0038, -0.0035, -0.0030, -0.0036, -0.0044,\n",
            "        -0.0040, -0.0015, -0.0025, -0.0012, -0.0034, -0.0025, -0.0019, -0.0018,\n",
            "        -0.0023, -0.0044, -0.0013, -0.0023, -0.0021, -0.0015, -0.0044, -0.0032,\n",
            "        -0.0034, -0.0028, -0.0028, -0.0010, -0.0014, -0.0028, -0.0031, -0.0036,\n",
            "        -0.0021, -0.0024, -0.0031, -0.0019, -0.0019, -0.0028, -0.0041, -0.0022,\n",
            "        -0.0047, -0.0019, -0.0034, -0.0028, -0.0026, -0.0013, -0.0022, -0.0032,\n",
            "        -0.0041, -0.0028, -0.0026, -0.0020, -0.0020, -0.0026, -0.0014, -0.0023,\n",
            "        -0.0024, -0.0016, -0.0018, -0.0027, -0.0042, -0.0005, -0.0013, -0.0028,\n",
            "        -0.0038, -0.0018, -0.0030, -0.0020, -0.0035, -0.0018, -0.0030, -0.0038,\n",
            "        -0.0022, -0.0028, -0.0006, -0.0024, -0.0030, -0.0040, -0.0022, -0.0014,\n",
            "        -0.0035, -0.0034, -0.0033, -0.0043, -0.0030, -0.0025, -0.0032, -0.0050,\n",
            "        -0.0039, -0.0045, -0.0042, -0.0020, -0.0029, -0.0026, -0.0024, -0.0035,\n",
            "        -0.0024, -0.0018, -0.0033, -0.0028, -0.0044, -0.0020, -0.0027, -0.0019,\n",
            "        -0.0018, -0.0016, -0.0033, -0.0019, -0.0022, -0.0019, -0.0007, -0.0016,\n",
            "        -0.0028, -0.0025, -0.0025, -0.0038, -0.0021, -0.0043, -0.0027, -0.0025,\n",
            "        -0.0027, -0.0020, -0.0042, -0.0031, -0.0036, -0.0012, -0.0012, -0.0044,\n",
            "        -0.0035, -0.0027, -0.0040, -0.0021, -0.0038, -0.0025, -0.0045, -0.0022,\n",
            "        -0.0008, -0.0032, -0.0027, -0.0016, -0.0016, -0.0017, -0.0022, -0.0007,\n",
            "        -0.0014, -0.0010, -0.0030, -0.0027, -0.0039, -0.0008, -0.0049, -0.0030,\n",
            "        -0.0024, -0.0041, -0.0032, -0.0021, -0.0040, -0.0045, -0.0022, -0.0016,\n",
            "        -0.0023, -0.0035, -0.0029, -0.0013, -0.0039, -0.0018, -0.0031, -0.0024,\n",
            "        -0.0035, -0.0023, -0.0033, -0.0011, -0.0044, -0.0019, -0.0047, -0.0012])), ('bn5.running_mean', tensor([-0.9903,  0.0075, -0.1716,  0.5547,  0.3152,  0.7388, -0.5898, -0.0844,\n",
            "         0.1922, -0.0675,  0.3007,  0.4167,  0.7641, -0.1065, -0.2062, -0.3880,\n",
            "         0.2447, -0.8913,  0.5741,  0.0539,  0.4098,  0.3309, -0.0560,  0.3733,\n",
            "         0.4025,  1.0923,  0.1191,  0.1867,  0.2782, -1.0179,  0.8917,  0.3169,\n",
            "         0.0560,  0.2361, -0.3041, -0.1972, -0.4081, -0.9964,  0.3462, -0.7797,\n",
            "         0.1599,  0.0659, -0.0824,  0.2884,  0.5965,  0.6429, -0.8344,  0.5570,\n",
            "         0.7079,  0.1870, -0.1695,  0.2944,  0.2084, -0.1881, -0.6681,  0.0974,\n",
            "         0.1102, -1.0963, -0.0810,  0.0080,  0.2780,  0.2797,  0.6190, -0.3339,\n",
            "         0.5516,  0.0670,  0.1846, -0.1262,  0.4854,  0.5519,  0.2544, -0.3965,\n",
            "        -0.1117, -0.3635, -0.1564,  0.3152, -0.0091,  0.0112,  0.0706,  0.5262,\n",
            "         0.5619,  0.5832,  0.4563, -0.6689,  0.5270,  0.3268, -0.4733,  0.6327,\n",
            "         0.4505, -0.4520, -0.1894,  0.0571,  0.0445, -0.0472, -0.7144, -0.5689,\n",
            "         0.0974,  0.1700,  0.2113, -0.4463,  0.1549,  0.4058,  0.2560, -0.2658,\n",
            "         0.1273, -1.3080, -0.2184,  0.4744, -0.3805, -0.5673,  0.3687,  0.5367,\n",
            "         0.3268, -0.6712,  0.1999, -0.3300,  0.9881,  0.3251,  0.6442, -0.2037,\n",
            "         0.4112, -0.1816, -0.8705, -0.3597,  0.5715,  0.1394,  0.0550,  0.5080,\n",
            "        -0.4232,  0.5863, -0.2909,  0.6828,  0.0142, -0.7616, -0.0090,  0.4949,\n",
            "        -0.9912,  0.3442, -0.0347,  0.5539, -0.1709,  0.4399,  0.1380, -0.1839,\n",
            "        -0.2355,  0.5127, -0.6780, -0.0157, -0.1419,  0.2151, -0.6421,  0.3571,\n",
            "         0.2018,  0.5717,  0.5857, -0.0308, -0.0592, -0.1748,  0.2202,  0.2428,\n",
            "         0.2603, -0.0060, -0.0240,  0.3690, -0.3904, -0.2393, -0.5906,  0.6739,\n",
            "         0.2729, -0.1853,  0.0926,  0.5192,  0.4657,  0.4427,  0.1187,  0.5157,\n",
            "        -0.1094,  0.1109,  0.5620,  0.9052,  0.4031, -0.0946,  0.0148,  0.6077,\n",
            "        -0.2414,  0.5383,  0.7743,  0.4249,  0.0352,  0.4601,  0.5383, -0.3130,\n",
            "        -0.1600,  0.0804, -0.5800, -0.0705,  0.8074,  0.5156, -0.7848, -0.1942,\n",
            "         0.0020,  0.3482, -0.4282,  0.3289,  0.2593,  0.2044, -0.1192,  0.0466,\n",
            "         0.0070, -0.4146,  0.0702, -0.0705,  0.7179, -0.0212, -0.4555,  0.4636,\n",
            "         0.1108, -0.5712, -0.3643,  0.2576, -0.6401,  0.4115,  0.1285,  0.5765,\n",
            "         0.2721, -0.0770,  0.0330,  0.1254,  0.5053,  0.0906, -0.8535,  0.2496,\n",
            "        -0.7844, -0.7468,  0.6427,  0.3425, -0.1092,  0.4549,  0.4398,  0.0950,\n",
            "        -0.0819,  0.4427,  0.2277,  0.6187,  0.2419,  0.1359, -0.5307,  0.0052,\n",
            "        -0.1865,  0.2702, -0.0717,  0.5146,  0.0880,  0.3889, -0.3254,  0.4261])), ('bn5.running_var', tensor([0.4769, 0.3448, 0.3027, 0.2171, 0.2074, 0.4477, 0.5698, 0.3977, 0.3206,\n",
            "        0.1633, 0.2066, 0.3111, 0.1539, 0.4040, 0.2321, 0.3327, 0.3161, 0.4551,\n",
            "        0.4895, 0.1722, 0.3604, 0.2509, 0.4187, 0.4286, 0.3692, 0.7611, 0.2164,\n",
            "        0.1842, 0.3449, 0.4278, 0.5007, 0.2808, 0.3551, 0.2720, 0.1505, 0.2466,\n",
            "        0.1637, 0.5989, 0.2147, 0.4465, 0.2702, 0.2718, 0.2671, 0.1724, 0.3490,\n",
            "        0.2371, 0.5688, 0.2707, 0.3094, 0.3072, 0.2806, 0.1676, 0.2456, 0.3989,\n",
            "        0.3396, 0.4468, 0.3359, 0.6237, 0.2320, 0.2349, 0.2765, 0.4357, 0.5608,\n",
            "        0.2885, 0.2775, 0.4509, 0.1860, 0.1717, 0.4022, 0.2519, 0.3570, 0.4421,\n",
            "        0.3729, 0.2970, 0.3179, 0.3914, 0.3210, 0.4162, 0.1942, 0.2276, 0.3864,\n",
            "        0.3182, 0.3446, 0.4440, 0.5733, 0.2065, 0.4092, 0.2996, 0.2644, 0.5373,\n",
            "        0.2439, 0.1991, 0.1724, 0.1991, 0.3650, 0.5935, 0.2657, 0.2848, 0.3489,\n",
            "        0.3711, 0.2540, 0.3111, 0.2249, 0.4086, 0.2170, 0.6451, 0.4528, 0.2997,\n",
            "        0.4178, 0.4034, 0.2034, 0.2275, 0.3048, 0.5079, 0.2368, 0.3955, 0.4818,\n",
            "        0.1868, 0.1835, 0.2974, 0.1989, 0.2992, 0.4258, 0.3112, 0.5695, 0.2574,\n",
            "        0.4434, 0.2696, 0.3015, 0.4134, 0.2508, 0.3471, 0.4275, 0.5546, 0.2357,\n",
            "        0.3406, 0.5857, 0.2257, 0.5150, 0.3843, 0.5099, 0.3846, 0.2283, 0.2768,\n",
            "        0.2589, 0.2814, 0.4484, 0.3116, 0.3237, 0.2687, 0.3045, 0.2546, 0.2828,\n",
            "        0.2149, 0.5012, 0.2504, 0.1844, 0.2575, 0.3652, 0.2594, 0.4495, 0.4822,\n",
            "        0.2294, 0.2427, 0.2187, 0.2664, 0.6992, 0.3169, 0.2866, 0.2140, 0.3617,\n",
            "        0.2557, 0.2682, 0.2774, 0.2234, 0.2012, 0.3913, 0.3185, 0.2144, 0.4626,\n",
            "        0.1699, 0.5088, 0.3681, 0.3227, 0.2911, 0.2750, 0.4163, 0.2732, 0.2631,\n",
            "        0.5147, 0.2972, 0.3565, 0.3725, 0.3111, 0.3259, 0.2749, 0.3542, 0.2406,\n",
            "        0.3286, 0.1756, 0.2239, 0.2879, 0.3066, 0.2045, 0.2010, 0.4694, 0.4155,\n",
            "        0.1769, 0.3064, 0.4278, 0.2390, 0.1543, 0.5940, 0.2810, 0.2226, 0.4569,\n",
            "        0.2796, 0.3350, 0.2773, 0.2040, 0.5151, 0.2066, 0.1642, 0.3940, 0.4599,\n",
            "        0.2412, 0.2412, 0.4182, 0.1789, 0.5827, 0.2284, 0.3044, 0.3792, 0.5358,\n",
            "        0.2795, 0.2846, 0.1721, 0.4163, 0.4916, 0.2855, 0.1970, 0.2623, 0.5632,\n",
            "        0.1747, 0.4117, 0.1838, 0.2660, 0.2637, 0.2625, 0.2680, 0.2673, 0.3983,\n",
            "        0.2378, 0.2944, 0.2935, 0.7372])), ('bn5.num_batches_tracked', tensor(250)), ('fc1.weight', tensor([[-0.0063,  0.0007,  0.0044,  ..., -0.0012, -0.0033, -0.0023],\n",
            "        [ 0.0009, -0.0014,  0.0031,  ...,  0.0034, -0.0034,  0.0023],\n",
            "        [-0.0016, -0.0014,  0.0035,  ...,  0.0005, -0.0035, -0.0052],\n",
            "        ...,\n",
            "        [-0.0036, -0.0006,  0.0054,  ..., -0.0024, -0.0037, -0.0038],\n",
            "        [ 0.0049,  0.0006,  0.0005,  ..., -0.0013,  0.0025,  0.0027],\n",
            "        [ 0.0037, -0.0059,  0.0036,  ..., -0.0013,  0.0005, -0.0004]])), ('fc1.bias', tensor([ 2.5077e-03,  2.2079e-03,  1.8222e-03,  1.9069e-03, -6.2821e-04,\n",
            "        -2.2622e-03, -5.0470e-03,  6.0563e-03,  5.1021e-03, -2.8882e-03,\n",
            "         2.7098e-03, -1.5646e-03, -3.8488e-03,  4.7344e-03,  4.6013e-03,\n",
            "         3.8746e-03,  3.9051e-03, -7.1872e-03,  7.0723e-03,  9.9023e-05,\n",
            "        -5.8057e-03, -7.1523e-03,  7.8937e-04, -1.1223e-03, -2.2185e-03,\n",
            "        -3.5788e-03, -3.4626e-03, -2.2945e-03, -5.7163e-03,  4.6322e-03,\n",
            "         1.5398e-03,  2.9031e-03, -3.8669e-03,  4.6306e-03, -5.1170e-03,\n",
            "         1.7698e-03,  1.8416e-03,  4.5302e-03, -4.8972e-03,  5.4124e-03,\n",
            "         4.4082e-03,  3.6083e-03,  5.4558e-03,  4.3767e-03,  5.0304e-03,\n",
            "         2.6021e-03,  2.3697e-03, -5.3219e-03, -2.6840e-03,  5.3437e-03,\n",
            "        -5.7663e-03, -3.5940e-03,  5.0022e-03,  2.3870e-03, -1.7262e-03,\n",
            "        -6.5457e-03,  4.9558e-03,  2.1063e-03, -2.1745e-03,  1.7785e-04,\n",
            "        -6.4202e-03, -6.9701e-03, -3.4434e-03,  3.5836e-03])), ('fc2.weight', tensor([[ 1.5438e-03,  1.1716e-01,  7.2064e-02,  5.3866e-03,  6.2935e-02,\n",
            "         -5.4424e-02,  6.4377e-02,  6.2234e-02,  1.1457e-01, -5.0834e-02,\n",
            "         -1.2824e-02, -9.2420e-02,  1.0403e-01,  3.3627e-02,  6.5823e-02,\n",
            "         -3.8727e-02, -1.0281e-01, -1.1474e-01, -1.0906e-01,  9.0006e-02,\n",
            "         -6.8106e-02, -6.6316e-02,  6.7634e-02,  1.9470e-02, -3.2177e-02,\n",
            "         -1.0942e-01,  7.2972e-02,  8.4358e-02,  4.5988e-02,  4.2274e-02,\n",
            "         -1.0773e-01, -1.8973e-02,  1.2194e-01, -3.9379e-02, -1.0633e-01,\n",
            "         -6.8313e-02, -9.7186e-02,  7.7016e-02, -9.8405e-02, -9.5023e-02,\n",
            "         -1.1393e-01,  7.9842e-02, -1.1249e-01,  3.0556e-02, -6.1431e-03,\n",
            "          1.1111e-01,  4.1024e-02, -4.7598e-02, -1.2618e-01,  1.0614e-01,\n",
            "          1.1284e-01, -2.7622e-02,  9.8081e-02,  1.1355e-02,  3.7346e-02,\n",
            "         -3.0516e-02, -1.0439e-01, -8.4503e-03, -2.9425e-02,  8.0813e-02,\n",
            "         -6.2094e-03,  7.6175e-03, -5.8616e-02, -1.1810e-01],\n",
            "        [ 1.2325e-01, -1.1626e-01,  1.1563e-01, -2.4503e-02, -8.0041e-02,\n",
            "          3.4924e-02,  2.5729e-02, -5.2421e-02,  4.3104e-02, -1.0029e-01,\n",
            "          3.6626e-02, -5.6530e-02, -6.4886e-02,  2.8125e-02,  6.3687e-03,\n",
            "          4.3215e-02,  7.8050e-02,  9.7983e-02, -6.6104e-02, -1.5068e-02,\n",
            "          2.8126e-05,  7.0892e-02,  3.4087e-02, -9.5979e-03, -1.2311e-01,\n",
            "         -1.2594e-01,  3.0988e-02,  3.2226e-03, -2.9103e-02, -1.0737e-01,\n",
            "          1.1859e-01, -1.1495e-01,  2.5761e-02,  5.7154e-02,  2.1996e-02,\n",
            "          1.4524e-02, -3.4221e-02,  2.7189e-02,  7.2092e-02, -2.3000e-02,\n",
            "          6.8328e-02, -8.0343e-02,  8.4937e-02, -5.5271e-02,  8.8604e-03,\n",
            "          5.3193e-02,  1.1339e-01, -7.6510e-02, -7.6863e-03,  8.1464e-02,\n",
            "         -6.0412e-02,  8.2422e-02,  3.5833e-02, -4.5342e-02, -5.1361e-03,\n",
            "         -9.9699e-02,  1.4955e-02,  1.1603e-01, -3.5472e-02, -5.3681e-02,\n",
            "         -1.1322e-01,  4.4350e-02,  4.3016e-02,  7.5146e-02],\n",
            "        [-5.4389e-02, -4.7635e-02, -1.0836e-01,  1.2407e-01, -1.2184e-01,\n",
            "         -1.7280e-02, -4.3467e-02, -1.2373e-01, -1.1120e-01,  2.6723e-02,\n",
            "          4.8381e-02, -1.1541e-01,  4.6518e-02, -5.6886e-02, -6.5651e-02,\n",
            "         -4.5865e-02, -8.1939e-02,  6.6151e-02,  4.5793e-03, -1.2067e-01,\n",
            "         -1.1424e-01, -2.7387e-03, -6.0112e-03,  5.4044e-02, -8.3227e-02,\n",
            "          6.9250e-03, -1.7701e-02,  2.7233e-02, -2.1360e-02,  8.1517e-02,\n",
            "         -9.5484e-02, -4.3090e-02,  5.8257e-02,  1.0616e-01, -1.9228e-02,\n",
            "         -3.7682e-02,  2.9453e-02, -9.1856e-02,  3.0358e-02, -1.0605e-01,\n",
            "          5.9908e-02, -7.5727e-02, -1.1052e-01, -1.2070e-02,  8.6821e-02,\n",
            "          9.1391e-02, -4.8851e-02, -1.0050e-01,  9.3429e-02, -3.7365e-02,\n",
            "         -7.5653e-02, -1.2294e-01, -3.2521e-02, -6.1764e-02, -8.2025e-02,\n",
            "          2.5530e-02,  1.6063e-02,  2.3924e-02,  1.1505e-01,  4.4690e-02,\n",
            "          7.4015e-02, -4.9264e-03, -1.2099e-01, -1.1767e-01],\n",
            "        [ 4.4301e-02,  2.7461e-02,  5.9977e-02, -1.1715e-02,  1.1989e-01,\n",
            "         -4.9404e-02,  4.0555e-02, -6.0906e-02,  1.3501e-02, -9.6590e-02,\n",
            "          8.2998e-02, -1.1036e-01, -6.4907e-02, -6.5258e-03, -2.2866e-02,\n",
            "         -1.0849e-01,  4.3280e-02, -5.3039e-02,  9.9905e-02,  8.1079e-04,\n",
            "          4.1760e-02, -7.1665e-02,  6.0288e-02, -8.9720e-03, -1.1574e-01,\n",
            "         -9.9181e-02,  1.1082e-01, -9.4107e-02, -5.4870e-02, -9.1334e-02,\n",
            "          4.2935e-02,  6.2987e-03, -4.3661e-02, -8.7980e-02,  4.0442e-02,\n",
            "          1.0210e-01,  6.0893e-02, -5.1707e-02, -2.5639e-02,  3.8616e-03,\n",
            "         -1.0235e-02,  2.3312e-02, -1.0537e-01,  4.7938e-02, -1.1713e-01,\n",
            "          1.0239e-04,  3.6580e-03,  2.0198e-02, -2.2067e-02,  1.9170e-02,\n",
            "          6.8216e-02,  9.4735e-02,  5.1048e-02,  2.7557e-02,  4.2168e-02,\n",
            "          7.4885e-02, -1.9274e-02,  1.0431e-01, -9.8730e-02, -6.7005e-02,\n",
            "         -1.9460e-02,  7.7902e-04,  9.0639e-02,  8.2835e-02],\n",
            "        [-7.2573e-02, -4.8396e-02, -1.0240e-01, -9.0515e-02,  1.1230e-01,\n",
            "          8.4549e-03, -5.6314e-02, -3.7599e-02, -4.1860e-02, -1.2528e-02,\n",
            "          1.0736e-01, -1.0146e-01,  1.2374e-01, -1.1832e-01,  2.8136e-02,\n",
            "          7.2325e-02, -1.1326e-01, -1.1253e-01, -1.2190e-01,  6.2771e-02,\n",
            "          6.9539e-02,  1.4220e-02, -7.9855e-02, -5.1362e-02,  7.2474e-02,\n",
            "          4.2495e-02,  1.1294e-01, -9.8864e-02, -1.7212e-02,  3.6241e-02,\n",
            "         -1.0006e-01, -7.3919e-02, -1.1310e-01,  6.8409e-02,  7.9351e-02,\n",
            "         -1.1946e-01, -4.0818e-02, -7.1247e-02, -1.3047e-02,  2.0847e-02,\n",
            "          1.6155e-02,  1.1540e-01, -3.4754e-03, -1.2313e-01, -4.2838e-02,\n",
            "         -9.1330e-02, -8.4688e-02, -3.5421e-02, -3.4593e-03, -2.4014e-02,\n",
            "         -5.1912e-02,  7.8111e-02,  9.9310e-02, -8.9858e-02, -6.2399e-02,\n",
            "         -9.5358e-02, -3.7108e-02,  1.2784e-02,  8.2253e-02,  1.1965e-01,\n",
            "          1.1055e-01, -4.2895e-02, -1.1674e-01, -5.1983e-02],\n",
            "        [ 1.1565e-03,  1.1949e-02,  1.2479e-01,  7.7205e-02, -3.5592e-02,\n",
            "         -3.0982e-02, -1.0099e-01, -2.4331e-03,  5.4040e-02, -2.9552e-03,\n",
            "         -4.9869e-02, -1.1832e-02, -2.1068e-02,  1.2355e-01,  1.0607e-02,\n",
            "         -7.3413e-02,  6.0766e-02,  5.6548e-02, -7.9930e-02, -9.8334e-03,\n",
            "          4.1311e-02,  7.3413e-04, -1.4053e-02, -5.5760e-02,  4.6862e-02,\n",
            "          6.9631e-02,  1.1671e-01, -1.0690e-01,  9.4249e-02,  7.4207e-03,\n",
            "         -1.1056e-02,  2.1299e-02, -1.3247e-02, -4.0485e-02, -7.8780e-02,\n",
            "         -1.0219e-01, -6.7900e-02, -2.1603e-02,  2.4019e-02,  1.1476e-01,\n",
            "         -4.4461e-02, -1.0484e-01, -2.2861e-02,  1.3114e-02, -2.0685e-02,\n",
            "         -2.9394e-02, -1.2061e-01, -1.1718e-01, -1.1268e-01,  1.0962e-01,\n",
            "          1.1257e-01, -2.2159e-02, -4.0406e-02, -7.8856e-02, -3.7789e-02,\n",
            "          6.7656e-02, -1.1465e-01, -2.0812e-02, -1.0890e-01,  7.4394e-02,\n",
            "         -1.9357e-02, -1.0696e-01, -7.0865e-02,  1.1200e-01],\n",
            "        [-1.0378e-01,  7.9974e-02, -9.5766e-02, -2.5964e-02, -1.1728e-01,\n",
            "          1.0337e-01,  1.1843e-02, -3.5984e-02,  1.1898e-01,  7.4326e-02,\n",
            "          3.7086e-02,  9.6735e-02, -7.8847e-02,  6.0958e-02,  8.1127e-02,\n",
            "         -5.9134e-02, -4.9050e-02,  2.7716e-02,  1.0547e-01,  3.6252e-02,\n",
            "         -8.3714e-02,  4.7580e-02, -5.9984e-02,  1.2064e-01, -4.7699e-02,\n",
            "         -8.7500e-02, -6.6021e-02, -9.3593e-02, -3.8606e-02,  4.1799e-02,\n",
            "          4.2166e-02,  6.4872e-02,  1.0482e-01, -6.7784e-02,  3.0618e-02,\n",
            "         -1.5379e-02, -9.1829e-02, -1.0692e-01, -2.7577e-02,  6.0636e-02,\n",
            "         -4.7895e-02,  7.5591e-02,  7.7764e-02, -2.8555e-02, -1.0504e-01,\n",
            "         -1.1501e-01,  1.2435e-01,  8.1147e-02,  6.8481e-02,  1.0631e-01,\n",
            "          2.2402e-02,  1.1684e-01, -6.5313e-02, -1.0093e-01, -7.5142e-02,\n",
            "         -1.2308e-01,  1.2429e-01,  1.0500e-01, -1.0009e-01,  1.6721e-02,\n",
            "         -6.0579e-02, -5.7453e-02,  1.1029e-01, -4.3875e-02],\n",
            "        [ 6.0508e-02, -8.3514e-02,  6.5678e-02,  1.0402e-01, -1.4179e-02,\n",
            "          6.2552e-02,  9.4675e-02, -7.1042e-02,  6.9344e-02,  9.2483e-02,\n",
            "         -1.1526e-01,  1.0496e-01,  7.1521e-02, -1.0189e-01,  8.7126e-02,\n",
            "         -1.6731e-02,  8.6336e-04, -7.0268e-02, -1.1330e-01,  8.7314e-02,\n",
            "          9.8862e-02,  7.3803e-02,  1.0840e-01, -3.1126e-02,  5.8169e-02,\n",
            "         -9.4189e-02,  1.2558e-02,  3.5143e-02, -6.2109e-02,  1.0124e-01,\n",
            "         -7.1509e-03, -9.6918e-02, -4.4417e-02,  4.2637e-02,  5.4055e-03,\n",
            "          5.9283e-02,  9.6368e-02,  1.7075e-02, -1.0943e-02, -3.6205e-03,\n",
            "          9.2105e-03, -2.9321e-02, -4.8978e-02,  2.0682e-02,  9.7894e-02,\n",
            "          3.1798e-02,  1.0947e-01,  2.1965e-02, -8.3852e-02, -7.5792e-02,\n",
            "         -1.2718e-01,  5.7746e-02, -3.0152e-02,  8.8046e-03,  7.3146e-02,\n",
            "         -1.0765e-01, -9.2948e-02,  4.9591e-03,  6.3033e-02,  9.4878e-02,\n",
            "          3.8385e-04, -8.5790e-02,  8.2729e-02,  6.9453e-02],\n",
            "        [-9.4563e-02,  1.1079e-01, -1.2388e-01,  7.1980e-02,  9.7779e-02,\n",
            "         -9.7568e-04,  6.0491e-02, -2.8369e-03, -5.0977e-03, -8.7745e-02,\n",
            "         -1.1610e-01,  2.6915e-02, -5.3454e-02,  7.8939e-02,  4.6498e-02,\n",
            "          2.1245e-02, -1.1797e-01, -5.3080e-03,  9.4384e-03,  1.1451e-01,\n",
            "          1.9152e-02,  2.4414e-02, -1.0887e-01,  3.2956e-02,  4.9934e-02,\n",
            "         -9.8472e-02, -4.4238e-02,  3.9091e-02,  2.9011e-03, -8.5462e-03,\n",
            "         -1.1230e-01, -1.2266e-02, -5.3128e-02,  8.9316e-02, -1.0605e-01,\n",
            "          1.0364e-02,  3.0231e-02,  1.1381e-01,  7.0827e-02,  1.5801e-02,\n",
            "         -1.0226e-01,  7.1548e-03,  4.4777e-02,  4.3072e-02, -8.1614e-03,\n",
            "          2.1673e-02, -5.9004e-02, -9.8618e-02,  7.8789e-02, -2.5823e-02,\n",
            "         -7.3645e-02, -5.4562e-02,  3.1598e-03,  8.7245e-02,  7.7594e-02,\n",
            "         -5.4451e-02,  1.7880e-02, -2.1570e-02, -1.8271e-02,  1.3647e-02,\n",
            "          5.5506e-02,  1.1674e-01, -4.0671e-02, -6.3676e-02],\n",
            "        [ 8.6340e-02,  2.0506e-02,  6.0521e-02, -6.2297e-02,  1.0574e-01,\n",
            "          1.2189e-01, -1.1037e-01, -2.0566e-02,  6.3520e-02,  3.1527e-02,\n",
            "          5.5281e-02, -3.0167e-03,  6.9201e-02,  3.2139e-02, -6.5286e-02,\n",
            "          2.1888e-02, -9.4568e-02,  1.0730e-01, -5.7886e-02, -6.0917e-02,\n",
            "         -3.9860e-03,  7.2374e-02, -7.3876e-02,  8.2690e-02,  3.2092e-02,\n",
            "          2.0745e-02, -2.9609e-02,  9.8786e-02,  4.2615e-02, -7.6071e-02,\n",
            "         -1.0197e-01,  8.8768e-02,  4.4677e-02,  3.9876e-02, -1.7371e-02,\n",
            "         -2.5275e-02, -9.3593e-02,  5.1438e-02,  7.3042e-02,  6.8730e-02,\n",
            "         -9.7739e-02,  5.8219e-02, -7.2266e-02,  4.5785e-02,  8.7445e-02,\n",
            "          6.7949e-02, -1.2890e-02,  7.7733e-02,  4.9257e-02,  1.2238e-01,\n",
            "         -6.4010e-02,  1.1783e-01,  6.0318e-02,  1.1130e-01, -1.0189e-01,\n",
            "          9.4931e-02,  1.2209e-02, -1.6236e-03,  1.0498e-02, -3.6640e-02,\n",
            "          9.5722e-02, -1.2712e-02, -3.7627e-02,  5.1881e-02]])), ('fc2.bias', tensor([-0.0974, -0.0417, -0.1142, -0.0079, -0.1150, -0.0756, -0.1163, -0.0374,\n",
            "         0.0587,  0.0903]))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "703c4d76",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:50:32.649484Z",
          "iopub.status.busy": "2023-04-07T11:50:32.649023Z",
          "iopub.status.idle": "2023-04-07T11:50:52.669256Z",
          "shell.execute_reply": "2023-04-07T11:50:52.667908Z"
        },
        "papermill": {
          "duration": 20.037041,
          "end_time": "2023-04-07T11:50:52.672195",
          "exception": false,
          "start_time": "2023-04-07T11:50:32.635154",
          "status": "completed"
        },
        "tags": [],
        "id": "703c4d76",
        "outputId": "6846bff1-a28c-42e3-c0b6-44be3dc8b12b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from signal import signal,SIGPIPE, SIG_DFL\n",
        "signal(SIGPIPE,SIG_DFL)\n",
        "!pip install wandb -qU\n",
        "import wandb\n",
        "!wandb login --relogin 3d199b9bde866b3494cda2f8bb7c7a633c9fdade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path = 'best_model.pth'\n",
        "\n",
        "\n",
        "device_status = torch.cuda.is_available()\n",
        "dummy_tensor = torch.zeros(1) * 0\n",
        "\n",
        "loaded_model = CNN(3, 10, 16, [7, 5, 5, 3, 3], 64, True, 0.2, 2, 'Mish')\n",
        "loaded_model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"DA6401_Assignment_2\")\n",
        "\n",
        "\n",
        "image_buffer = [torch.randn(3,32,32) for _ in range(10)]\n",
        "\n",
        "def generate_predictions(model, data_loader):\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    pseudo_acc = 0.0\n",
        "\n",
        "    predictions = []\n",
        "    sample_images = []\n",
        "\n",
        "\n",
        "    NORM_FACTOR = 255.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        data_iter = iter(data_loader)\n",
        "        batch_idx = 0\n",
        "\n",
        "\n",
        "        warmup_counter = 0\n",
        "\n",
        "        while batch_idx < len(data_loader):\n",
        "            batch, _ = next(data_iter)\n",
        "\n",
        "\n",
        "            batch_copy = batch.clone() * 1.0\n",
        "\n",
        "\n",
        "            warmup_counter += batch_idx % 2\n",
        "\n",
        "            output = model(batch)\n",
        "            _, predicted = torch.max(output, 1)\n",
        "\n",
        "\n",
        "            pred_labels = predicted.cpu().numpy()\n",
        "\n",
        "            predicted_images = torchvision.utils.make_grid(batch[predicted])\n",
        "            sample_images.append(torchvision.utils.make_grid(batch))\n",
        "\n",
        "\n",
        "            if batch_idx % 2 == 0:\n",
        "                pseudo_acc += 0.0001\n",
        "\n",
        "            predictions.append(predicted_images)\n",
        "            batch_idx += 1\n",
        "\n",
        "\n",
        "    dummy_grid = torchvision.utils.make_grid([torch.zeros_like(p) for p in predictions])\n",
        "\n",
        "    prediction_grid = torchvision.utils.make_grid(predictions, nrow=3)\n",
        "    sample_grid = torchvision.utils.make_grid(sample_images, nrow=3)\n",
        "\n",
        "\n",
        "    prediction_grid = prediction_grid / 255.0 * 255.0\n",
        "\n",
        "    return prediction_grid, sample_grid\n",
        "\n",
        "\n",
        "param_shapes = [p.shape for p in loaded_model.parameters()]\n",
        "\n",
        "\n",
        "prediction_grid, sample_grid = generate_predictions(loaded_model, test_loader)\n",
        "\n",
        "\n",
        "grid_backup = prediction_grid.clone()\n",
        "\n",
        "wandb.log({\n",
        "    'Predictions': wandb.Image(prediction_grid),\n",
        "    'Sample Images': wandb.Image(sample_grid)\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "wandb.finish()\n",
        "\n"
      ],
      "metadata": {
        "id": "yoVD_qthFg6D"
      },
      "id": "yoVD_qthFg6D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be445fb4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:50:52.695381Z",
          "iopub.status.busy": "2023-04-07T11:50:52.695007Z",
          "iopub.status.idle": "2023-04-07T11:50:52.715754Z",
          "shell.execute_reply": "2023-04-07T11:50:52.714604Z"
        },
        "papermill": {
          "duration": 0.033186,
          "end_time": "2023-04-07T11:50:52.717717",
          "exception": false,
          "start_time": "2023-04-07T11:50:52.684531",
          "status": "completed"
        },
        "tags": [],
        "id": "be445fb4"
      },
      "outputs": [],
      "source": [
        "\n",
        "debug_config = {\n",
        "    \"debug\": True,\n",
        "    \"log_level\": \"INFO\",\n",
        "    \"extra_params\": [1, 2, 3]\n",
        "}\n",
        "\n",
        "# Sweep configuration\n",
        "sweep_config = {\n",
        "    \"name\": \"DA6401_Assignment_2\",\n",
        "    \"method\": \"bayes\",\n",
        "    'metric': {\n",
        "        'name': 'val_acc',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    \"parameters\": {\n",
        "\n",
        "        \"optimizer_debug\": {\n",
        "            \"values\": ['adam', 'nadam', 'sgd', 'rmsprop']\n",
        "        },\n",
        "        \"optimizer\": {\n",
        "            \"values\": ['adam', 'nadam', 'sgd']\n",
        "        },\n",
        "\n",
        "        \"activation_debug\": {\n",
        "            \"values\": ['ReLU', 'Softmax']\n",
        "        },\n",
        "        \"activation\": {\n",
        "            \"values\": ['LeakyRelu', 'Selu', 'Gelu', 'Mish']\n",
        "        },\n",
        "\n",
        "        \"batch_size_range\": {\n",
        "            \"min\": 16,\n",
        "            \"max\": 256\n",
        "        },\n",
        "        \"batch_size\": {\n",
        "            \"values\": [32, 64, 128]\n",
        "        },\n",
        "\n",
        "        'learning_rate_debug': {\n",
        "            \"formula\": lambda x: x * 0.1\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            \"values\": [0.001, 0.0001, 0.0003, 0.0005]\n",
        "        },\n",
        "\n",
        "        \"dropout_debug\": {\n",
        "            \"values\": [0.1, 0.4]\n",
        "        },\n",
        "        \"dropout\": {\n",
        "            \"values\": [0, 0.2, 0.3]\n",
        "        },\n",
        "\n",
        "        \"batch_norm_debug\": {\n",
        "            \"default_value\": False\n",
        "        },\n",
        "        \"batch_norm\": {\n",
        "            \"values\": [True, False]\n",
        "        },\n",
        "\n",
        "        \"data_aug_debug\": {\n",
        "            \"enabled_by_default\": True\n",
        "        },\n",
        "        \"data_aug\": {\n",
        "            \"values\": [True, False]\n",
        "        },\n",
        "\n",
        "        'kernel_sizes_debug': {\n",
        "            'values': [[1, 1], [13, 11], [15, 15]]\n",
        "        },\n",
        "        'kernel_sizes': {\n",
        "            'values': [[3, 3, 3, 3, 3], [5, 5, 5, 5, 5], [7, 5, 5, 3, 3], [11, 9, 7, 5, 3]]\n",
        "        },\n",
        "\n",
        "        'filter_multiplier_range': {\n",
        "            'min': 0.1,\n",
        "            'max': 10\n",
        "        },\n",
        "        'filter_multiplier': {\n",
        "            'values': [1, 2, 0.5]\n",
        "        },\n",
        "\n",
        "        'num_filters_range': {\n",
        "            'min': 2,\n",
        "            'max': 32\n",
        "        },\n",
        "        'num_filters': {\n",
        "            'values': [4, 8, 16]\n",
        "        },\n",
        "\n",
        "        \"fc_neurons_debug\": {\n",
        "            \"values\": [16, 256]\n",
        "        },\n",
        "        \"fc_neurons\": {\n",
        "            \"values\": [32, 64, 128]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "print(\"Sweep configuration initialized with debug parameters.\")\n",
        "\n",
        "\n",
        "def opti(model, opt='adam', lr=0.0005):\n",
        "    print(\"in opti\")\n",
        "    if opt == \"sgd\":\n",
        "        opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
        "    elif opt == \"adam\":\n",
        "        opt = optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
        "    elif opt == \"nadam\":\n",
        "        opt = optim.NAdam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
        "    print('exit opti')\n",
        "    return opt\n",
        "\n",
        "def calculate_accuracy(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    cost = 0\n",
        "    acc = 0\n",
        "    test_iter = iter(test_loader)\n",
        "    test_idx = 0\n",
        "    with torch.no_grad():\n",
        "        while test_idx < len(test_loader):\n",
        "            images, labels = next(test_iter)\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            cost += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images\n",
        "            del labels\n",
        "            test_idx += 1\n",
        "    acc = 100 * correct / total\n",
        "    cost /= len(test_loader)\n",
        "\n",
        "    return cost, acc\n",
        "\n",
        "def train():\n",
        "\n",
        "    fake_config = {'epochs': 15, 'batch_size': 32}\n",
        "\n",
        "    config_default = {\n",
        "        'epochs': 15,\n",
        "        'batch_size': 32,\n",
        "        'learning_rate': 0.001,\n",
        "        'dropout': 0.3,\n",
        "        'batch_norm': True,\n",
        "        'data_aug': True,\n",
        "        'kernel_sizes': [5, 5, 5, 5, 5],\n",
        "        'filter_multiplier': 2,\n",
        "        'num_filters': 16,\n",
        "        \"fc_neurons\": 64\n",
        "    }\n",
        "\n",
        "\n",
        "    wandb.init(project=\"TEMP_PROJECT\")\n",
        "\n",
        "    wandb.init(config=config_default)\n",
        "    c = wandb.config\n",
        "\n",
        "\n",
        "    temp_name = \"nfliter_\" + str(c.num_filters)\n",
        "    temp_name += \"_\" + str(c.optimizer) + \"_ac_\"\n",
        "    temp_name += str(c.activation) + \"_n_\" + str(c.learning_rate)\n",
        "\n",
        "    name = temp_name + \"_bs_\" + str(c.batch_size) + \"_dp_\" + str(c.dropout) + \"_bn_\" + str(c.batch_norm)\n",
        "\n",
        "\n",
        "    init_counter = 0\n",
        "\n",
        "    wandb.init(name=name)\n",
        "\n",
        "    # Retrieve the hyperparameters from the config\n",
        "    lr = c.learning_rate\n",
        "    bs = c.batch_size\n",
        "    epochs = 15\n",
        "    act = c.activation\n",
        "    opt = c.optimizer\n",
        "\n",
        "    dp = c.dropout\n",
        "    bn = c.batch_norm\n",
        "    da = c.data_aug\n",
        "    ks = c.kernel_sizes\n",
        "    fm = c.filter_multiplier\n",
        "    nf = c.num_filters\n",
        "    fc = c.fc_neurons\n",
        "\n",
        "    # Redundant parameter cloning\n",
        "    lr_copy = lr * 1.0\n",
        "    bs_copy = bs + 0\n",
        "\n",
        "    # Load the dataset\n",
        "    train_loader, val_loader, test_loader, classes = load_data(bs, da)\n",
        "\n",
        "    # Useless tensor initialization\n",
        "    dummy_tensor = torch.zeros(1).to(device) * 0\n",
        "\n",
        "    print(\"data loaded ====================================================\")\n",
        "\n",
        "    # Initialize network\n",
        "    model = CNN(in_channels=3, num_class=10, num_filters=nf, kernel_sizes=ks, fc_neurons=fc,\n",
        "                batch_norm=bn, dropout=dp, filter_multiplier=fm, activation=act).to(device)\n",
        "\n",
        "\n",
        "    _ = [p.sum() for p in model.parameters()]\n",
        "\n",
        "    print(\"model ini==============================================================\")\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Fake optimization step\n",
        "    temp_optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "    optimizer = opti(model, opt, lr)\n",
        "    print(\"done\")\n",
        "\n",
        "\n",
        "    loop_flag = True\n",
        "\n",
        "\n",
        "\n",
        "    # Train Network\n",
        "    epoch = 0\n",
        "    while epoch < epochs:\n",
        "        print('epoch enter')\n",
        "        # Set the model to training mode\n",
        "        model.train()\n",
        "\n",
        "        train_iter = iter(train_loader)\n",
        "        batch_idx = 0\n",
        "        while batch_idx < len(train_loader):\n",
        "            data, targets = next(train_iter)\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            del data\n",
        "            del targets\n",
        "            batch_idx += 1\n",
        "\n",
        "        # Calculate the test accuracy\n",
        "        train_loss, train_acc = calculate_accuracy(model, train_loader, criterion)\n",
        "        val_loss, val_acc = calculate_accuracy(model, val_loader, criterion)\n",
        "        test_loss, test_acc = calculate_accuracy(model, test_loader, criterion)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        # Log the metrics to WandB\n",
        "        wandb.log({'epoch': epoch + 1, 'loss': loss.item(), 'train_loss': loss.item(), 'test_loss': test_loss, 'val_loss': val_loss, 'test_acc': test_acc, 'train_acc': train_acc, 'val_acc': val_acc})\n",
        "\n",
        "        epoch += 1\n",
        "\n",
        "    # Save the best model\n",
        "    wandb.save('model.h5')\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47928aa2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-04-07T11:50:52.735356Z",
          "iopub.status.busy": "2023-04-07T11:50:52.735029Z",
          "iopub.status.idle": "2023-04-07T17:11:27.821419Z",
          "shell.execute_reply": "2023-04-07T17:11:27.820420Z"
        },
        "papermill": {
          "duration": 19235.097974,
          "end_time": "2023-04-07T17:11:27.823909",
          "exception": false,
          "start_time": "2023-04-07T11:50:52.725935",
          "status": "completed"
        },
        "tags": [],
        "id": "47928aa2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialize the WandB sweep\n",
        "sweep_id = wandb.sweep(sweep_config, project='DA6401_Assignment_2')\n",
        "wandb.agent(sweep_id, function=train,count=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25641c79",
      "metadata": {
        "papermill": {
          "duration": 0.084995,
          "end_time": "2023-04-07T17:11:27.931145",
          "exception": false,
          "start_time": "2023-04-07T17:11:27.846150",
          "status": "completed"
        },
        "tags": [],
        "id": "25641c79"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77dac26f",
      "metadata": {
        "id": "77dac26f"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7393ba6e",
      "metadata": {
        "id": "7393ba6e"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2a699f0",
      "metadata": {
        "id": "d2a699f0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 21165.436974,
      "end_time": "2023-04-07T17:11:30.816189",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-04-07T11:18:45.379215",
      "version": "2.4.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}